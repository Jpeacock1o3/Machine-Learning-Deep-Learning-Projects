{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e97faed6",
   "metadata": {},
   "source": [
    "## Added some code from part 1 for the model, the start of part 2 is lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f166fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8a2b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available()\n",
    "                      else \"cuda\" if torch.cuda.is_available()\n",
    "                      else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e096059",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"datasets/dataset.csv\")\n",
    "df = pd.DataFrame(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff92e04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  1.  8.  0.  5.  3. 10.  2.  4.  7.  9. 11. 13. 15. 17. 12. 14.]\n",
      "766\n"
     ]
    }
   ],
   "source": [
    "cat = ['f1', 'f2', 'f4', 'f5', 'f6', 'f7']\n",
    "for i in cat:\n",
    "    df[i] = df[i].replace(r'[A-Za-z]', np.nan, regex=True) #remove any non numbers, and turn them into nans\n",
    "    df[i] = pd.to_numeric(df[i], errors='coerce') #turn objects to ints\n",
    "    df[i] = df[i].fillna(df[i].median())  # replace the NaN with median\n",
    "#checking to make sure the type is right, and no values were lost\n",
    "print(df['f1'].unique())\n",
    "print(df['f1'].value_counts().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9367b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(\"target\", axis=1)\n",
    "target = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "338993f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial train test split to create training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.15, random_state=42\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ecd9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second train test split to create validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    #makes the split 70:15:15\n",
    "    X_train, y_train, test_size=0.1764, random_state=42, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e94589a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_val   = np.asarray(X_val)\n",
    "X_test  = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_val   = np.asarray(y_val)\n",
    "y_test  = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e41a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "train_ds = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.float32)\n",
    ")\n",
    "val_ds = TensorDataset(\n",
    "    torch.tensor(X_val, dtype=torch.float32),\n",
    "    torch.tensor(y_val, dtype=torch.float32)\n",
    ")\n",
    "test_ds = TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d6c5220",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if device.type == \"mps\":\n",
    "    dl_gen = torch.Generator(device=\"mps\").manual_seed(SEED)\n",
    "    X_train_dl = DataLoader(train_ds, batch_size=64, shuffle=True,  generator=dl_gen)\n",
    "else:\n",
    "    X_train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "X_val_dl  = DataLoader(val_ds,  batch_size=64, shuffle=False)\n",
    "X_test_dl = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "test_ds = TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.float32)\n",
    ")\n",
    "X_test_dl = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3913dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # No flatten layer needed (we already have 7 features, not an image)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(7, 64),   # Input → Hidden layer 1\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 64),  # Hidden layer 2\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 64),  # Hidden layer 3\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 1)    # Output layer (linear for regression)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward pass through the stack\n",
    "        output = self.linear_relu_stack(x)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a53325c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "gpu_idx = 0\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(f\"cuda:{gpu_idx}\")\n",
    "    print(f\"Using CUDA @ device {gpu_idx}\")\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using Apple MPS\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f55f6dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=7, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.2, inplace=False)\n",
      "    (9): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "# 1) Build model\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# 2) Move to device BEFORE creating optimizer\n",
    "model = model.to(device)\n",
    "\n",
    "# 3) Now create the optimizer (AFTER .to(device))\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76e4dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_step(dataloader, model, loss_fn, optimizer=None):\n",
    "    \n",
    "    train_mode = optimizer is not None\n",
    "    model.train(train_mode)                     \n",
    "    running_loss, running_mae, n = 0.0, 0.0, 0\n",
    "\n",
    "    context = torch.enable_grad() if train_mode else torch.no_grad()\n",
    "\n",
    "    total_loss, total_correct, total_n = 0.0, 0, 0\n",
    "    with context:\n",
    "        for xb, yb in dataloader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            if train_mode:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            logits = model(xb)                        # (B,) or (B,1)\n",
    "            loss = loss_fn(logits.view(-1), yb.view(-1))\n",
    "\n",
    "            if train_mode:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "            preds = (torch.sigmoid(logits.view(-1)) >= 0.5).long()\n",
    "            total_correct += (preds == yb.long().view(-1)).sum().item()\n",
    "            total_n += xb.size(0)\n",
    "\n",
    "    return total_loss/total_n, total_correct/total_n\n",
    "\n",
    "\n",
    "# training loop\n",
    "def train_model(model, train_dl, val_dl, epochs=500):\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_mae\": [], \"val_mae\": [], \"epoch_time_sec\": []}\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        t0 = time.time()\n",
    " \n",
    "        # a–f) TRAIN\n",
    "        train_loss, train_mae = epoch_step(train_dl, model, loss, optimizer=optimizer)\n",
    "\n",
    "        # g) VALIDATION (no grad, no optimizer.step)\n",
    "        val_loss, val_mae = epoch_step(val_dl, model, loss, optimizer=None)\n",
    "\n",
    "        \n",
    "\n",
    "        epoch_time = time.time() - t0\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"train_mae\"].append(train_mae)\n",
    "        history[\"val_mae\"].append(val_mae)\n",
    "        history[\"epoch_time_sec\"].append(epoch_time)\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | \"\n",
    "              f\"train_loss={train_loss:.5f}  val_loss={val_loss:.5f} | \"\n",
    "              f\"train_MAE={train_mae:.4f}  val_MAE={val_mae:.4f} | \"\n",
    "              f\"lr={optimizer.param_groups[0]['lr']:.5g} | \"\n",
    "              f\"time={epoch_time:.2f}s\")\n",
    "\n",
    "        # simple early stopping on val loss\n",
    "        if val_loss < best_val - 1e-8:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        \n",
    "\n",
    "    # load best weights (by validation loss)\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
    "\n",
    "    print(f\"Total training time: {sum(history['epoch_time_sec']):.2f}s\")\n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9ce405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss=1.12645  val_loss=0.75237 | train_MAE=0.5653  val_MAE=0.6609 | lr=0.001 | time=0.15s\n",
      "Epoch 002 | train_loss=1.13469  val_loss=0.64107 | train_MAE=0.5373  val_MAE=0.6261 | lr=0.001 | time=0.08s\n",
      "Epoch 003 | train_loss=0.83193  val_loss=0.68865 | train_MAE=0.5765  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 004 | train_loss=0.79357  val_loss=0.63983 | train_MAE=0.5989  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 005 | train_loss=0.74124  val_loss=0.64959 | train_MAE=0.5896  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 006 | train_loss=0.73168  val_loss=0.64831 | train_MAE=0.6082  val_MAE=0.6870 | lr=0.001 | time=0.09s\n",
      "Epoch 007 | train_loss=0.72130  val_loss=0.65398 | train_MAE=0.6045  val_MAE=0.6348 | lr=0.001 | time=0.08s\n",
      "Epoch 008 | train_loss=0.68481  val_loss=0.65460 | train_MAE=0.6119  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 009 | train_loss=0.67586  val_loss=0.63748 | train_MAE=0.6250  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 010 | train_loss=0.69565  val_loss=0.63822 | train_MAE=0.6343  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 011 | train_loss=0.68920  val_loss=0.64491 | train_MAE=0.6063  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 012 | train_loss=0.69170  val_loss=0.64816 | train_MAE=0.6138  val_MAE=0.7043 | lr=0.001 | time=0.11s\n",
      "Epoch 013 | train_loss=0.67930  val_loss=0.64406 | train_MAE=0.6250  val_MAE=0.7043 | lr=0.001 | time=0.14s\n",
      "Epoch 014 | train_loss=0.67226  val_loss=0.62991 | train_MAE=0.6511  val_MAE=0.7130 | lr=0.001 | time=0.14s\n",
      "Epoch 015 | train_loss=0.67275  val_loss=0.61056 | train_MAE=0.6101  val_MAE=0.7043 | lr=0.001 | time=0.14s\n",
      "Epoch 016 | train_loss=0.68472  val_loss=0.60861 | train_MAE=0.6343  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 017 | train_loss=0.64249  val_loss=0.61986 | train_MAE=0.6716  val_MAE=0.6957 | lr=0.001 | time=0.07s\n",
      "Epoch 018 | train_loss=0.65962  val_loss=0.62193 | train_MAE=0.6138  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 019 | train_loss=0.66764  val_loss=0.61799 | train_MAE=0.6418  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 020 | train_loss=0.65770  val_loss=0.62405 | train_MAE=0.6474  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 021 | train_loss=0.63356  val_loss=0.62158 | train_MAE=0.6549  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 022 | train_loss=0.66534  val_loss=0.61382 | train_MAE=0.6455  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 023 | train_loss=0.66079  val_loss=0.61230 | train_MAE=0.6231  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 024 | train_loss=0.63487  val_loss=0.60829 | train_MAE=0.6437  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 025 | train_loss=0.63317  val_loss=0.59996 | train_MAE=0.6828  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 026 | train_loss=0.62809  val_loss=0.59295 | train_MAE=0.6660  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 027 | train_loss=0.61756  val_loss=0.59272 | train_MAE=0.6754  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 028 | train_loss=0.62502  val_loss=0.59189 | train_MAE=0.6735  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 029 | train_loss=0.64328  val_loss=0.58957 | train_MAE=0.6679  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 030 | train_loss=0.62166  val_loss=0.58773 | train_MAE=0.6810  val_MAE=0.6696 | lr=0.001 | time=0.10s\n",
      "Epoch 031 | train_loss=0.63958  val_loss=0.58792 | train_MAE=0.6325  val_MAE=0.6957 | lr=0.001 | time=0.13s\n",
      "Epoch 032 | train_loss=0.61491  val_loss=0.58825 | train_MAE=0.6698  val_MAE=0.7043 | lr=0.001 | time=0.09s\n",
      "Epoch 033 | train_loss=0.60491  val_loss=0.58667 | train_MAE=0.6810  val_MAE=0.6870 | lr=0.001 | time=0.09s\n",
      "Epoch 034 | train_loss=0.63960  val_loss=0.58677 | train_MAE=0.6549  val_MAE=0.6957 | lr=0.001 | time=0.10s\n",
      "Epoch 035 | train_loss=0.60784  val_loss=0.59100 | train_MAE=0.6660  val_MAE=0.6957 | lr=0.001 | time=0.09s\n",
      "Epoch 036 | train_loss=0.63701  val_loss=0.59321 | train_MAE=0.6399  val_MAE=0.6870 | lr=0.001 | time=0.09s\n",
      "Epoch 037 | train_loss=0.63196  val_loss=0.59177 | train_MAE=0.6455  val_MAE=0.6783 | lr=0.001 | time=0.09s\n",
      "Epoch 038 | train_loss=0.62367  val_loss=0.59171 | train_MAE=0.6772  val_MAE=0.6957 | lr=0.001 | time=0.10s\n",
      "Epoch 039 | train_loss=0.61047  val_loss=0.58636 | train_MAE=0.6623  val_MAE=0.6957 | lr=0.001 | time=0.09s\n",
      "Epoch 040 | train_loss=0.63883  val_loss=0.58462 | train_MAE=0.6604  val_MAE=0.6783 | lr=0.001 | time=0.09s\n",
      "Epoch 041 | train_loss=0.60630  val_loss=0.58225 | train_MAE=0.6698  val_MAE=0.6870 | lr=0.001 | time=0.09s\n",
      "Epoch 042 | train_loss=0.61096  val_loss=0.58130 | train_MAE=0.6810  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 043 | train_loss=0.61285  val_loss=0.58854 | train_MAE=0.6567  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 044 | train_loss=0.61184  val_loss=0.59210 | train_MAE=0.6679  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 045 | train_loss=0.61348  val_loss=0.59174 | train_MAE=0.6698  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 046 | train_loss=0.60351  val_loss=0.58419 | train_MAE=0.6791  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 047 | train_loss=0.61132  val_loss=0.58357 | train_MAE=0.6754  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 048 | train_loss=0.61990  val_loss=0.58464 | train_MAE=0.6679  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 049 | train_loss=0.60647  val_loss=0.58514 | train_MAE=0.6884  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 050 | train_loss=0.60150  val_loss=0.58427 | train_MAE=0.6903  val_MAE=0.6957 | lr=0.001 | time=0.07s\n",
      "Epoch 051 | train_loss=0.59504  val_loss=0.58145 | train_MAE=0.6847  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 052 | train_loss=0.59550  val_loss=0.57945 | train_MAE=0.6847  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 053 | train_loss=0.60072  val_loss=0.57677 | train_MAE=0.6679  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 054 | train_loss=0.61692  val_loss=0.57653 | train_MAE=0.6754  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 055 | train_loss=0.59991  val_loss=0.58321 | train_MAE=0.6884  val_MAE=0.6870 | lr=0.001 | time=0.07s\n",
      "Epoch 056 | train_loss=0.59529  val_loss=0.58481 | train_MAE=0.6567  val_MAE=0.6957 | lr=0.001 | time=0.07s\n",
      "Epoch 057 | train_loss=0.62146  val_loss=0.58522 | train_MAE=0.6698  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 058 | train_loss=0.59085  val_loss=0.58410 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.001 | time=0.07s\n",
      "Epoch 059 | train_loss=0.59426  val_loss=0.57912 | train_MAE=0.6810  val_MAE=0.6957 | lr=0.001 | time=0.07s\n",
      "Epoch 060 | train_loss=0.60652  val_loss=0.57406 | train_MAE=0.6810  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 061 | train_loss=0.57175  val_loss=0.57920 | train_MAE=0.6772  val_MAE=0.7043 | lr=0.001 | time=0.07s\n",
      "Epoch 062 | train_loss=0.60537  val_loss=0.57630 | train_MAE=0.6847  val_MAE=0.7130 | lr=0.001 | time=0.07s\n",
      "Epoch 063 | train_loss=0.59613  val_loss=0.57668 | train_MAE=0.6735  val_MAE=0.6870 | lr=0.001 | time=0.07s\n",
      "Epoch 064 | train_loss=0.60183  val_loss=0.57435 | train_MAE=0.6791  val_MAE=0.6870 | lr=0.001 | time=0.07s\n",
      "Epoch 065 | train_loss=0.57765  val_loss=0.57966 | train_MAE=0.7108  val_MAE=0.6957 | lr=0.001 | time=0.07s\n",
      "Epoch 066 | train_loss=0.58538  val_loss=0.57613 | train_MAE=0.7052  val_MAE=0.6870 | lr=0.001 | time=0.07s\n",
      "Epoch 067 | train_loss=0.57839  val_loss=0.57277 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 068 | train_loss=0.57558  val_loss=0.57498 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 069 | train_loss=0.58537  val_loss=0.56901 | train_MAE=0.6716  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 070 | train_loss=0.59182  val_loss=0.57834 | train_MAE=0.6791  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 071 | train_loss=0.58301  val_loss=0.58301 | train_MAE=0.6642  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 072 | train_loss=0.58779  val_loss=0.57915 | train_MAE=0.6828  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 073 | train_loss=0.59313  val_loss=0.57858 | train_MAE=0.6716  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 074 | train_loss=0.58379  val_loss=0.58028 | train_MAE=0.7071  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 075 | train_loss=0.59058  val_loss=0.57964 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 076 | train_loss=0.58296  val_loss=0.57720 | train_MAE=0.7015  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 077 | train_loss=0.57069  val_loss=0.57708 | train_MAE=0.6959  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 078 | train_loss=0.57631  val_loss=0.57617 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 079 | train_loss=0.59108  val_loss=0.57276 | train_MAE=0.6772  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 080 | train_loss=0.57518  val_loss=0.57570 | train_MAE=0.6922  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 081 | train_loss=0.59054  val_loss=0.57166 | train_MAE=0.6903  val_MAE=0.7217 | lr=0.001 | time=0.09s\n",
      "Epoch 082 | train_loss=0.58126  val_loss=0.57729 | train_MAE=0.6791  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 083 | train_loss=0.57156  val_loss=0.57685 | train_MAE=0.6791  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 084 | train_loss=0.57760  val_loss=0.57563 | train_MAE=0.6940  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 085 | train_loss=0.57932  val_loss=0.57893 | train_MAE=0.6679  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 086 | train_loss=0.57667  val_loss=0.57472 | train_MAE=0.7015  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 087 | train_loss=0.57199  val_loss=0.57605 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 088 | train_loss=0.57316  val_loss=0.57787 | train_MAE=0.6922  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 089 | train_loss=0.55766  val_loss=0.58424 | train_MAE=0.7034  val_MAE=0.6957 | lr=0.001 | time=0.15s\n",
      "Epoch 090 | train_loss=0.57354  val_loss=0.57795 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 091 | train_loss=0.57733  val_loss=0.57762 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 092 | train_loss=0.56387  val_loss=0.59264 | train_MAE=0.7108  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 093 | train_loss=0.56214  val_loss=0.58376 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 094 | train_loss=0.56809  val_loss=0.57512 | train_MAE=0.6922  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 095 | train_loss=0.58648  val_loss=0.57408 | train_MAE=0.6549  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 096 | train_loss=0.57790  val_loss=0.57865 | train_MAE=0.6791  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 097 | train_loss=0.57842  val_loss=0.58218 | train_MAE=0.6847  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 098 | train_loss=0.59185  val_loss=0.58468 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 099 | train_loss=0.57335  val_loss=0.57751 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 100 | train_loss=0.57766  val_loss=0.57176 | train_MAE=0.6810  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 101 | train_loss=0.57337  val_loss=0.57738 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 102 | train_loss=0.57388  val_loss=0.57200 | train_MAE=0.6866  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 103 | train_loss=0.56023  val_loss=0.57374 | train_MAE=0.6884  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 104 | train_loss=0.56662  val_loss=0.57056 | train_MAE=0.7090  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 105 | train_loss=0.54816  val_loss=0.57001 | train_MAE=0.7146  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 106 | train_loss=0.54603  val_loss=0.57776 | train_MAE=0.6996  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 107 | train_loss=0.56151  val_loss=0.57975 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 108 | train_loss=0.56246  val_loss=0.57169 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 109 | train_loss=0.54878  val_loss=0.56628 | train_MAE=0.7015  val_MAE=0.7478 | lr=0.001 | time=0.09s\n",
      "Epoch 110 | train_loss=0.57311  val_loss=0.57672 | train_MAE=0.6922  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 111 | train_loss=0.56658  val_loss=0.56963 | train_MAE=0.7052  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 112 | train_loss=0.56113  val_loss=0.56875 | train_MAE=0.7108  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 113 | train_loss=0.55430  val_loss=0.57526 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 114 | train_loss=0.57717  val_loss=0.58104 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 115 | train_loss=0.56997  val_loss=0.56997 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 116 | train_loss=0.57631  val_loss=0.56812 | train_MAE=0.6978  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 117 | train_loss=0.56074  val_loss=0.57141 | train_MAE=0.6996  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 118 | train_loss=0.55157  val_loss=0.57601 | train_MAE=0.6978  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 119 | train_loss=0.56745  val_loss=0.57084 | train_MAE=0.6922  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 120 | train_loss=0.57185  val_loss=0.57726 | train_MAE=0.7146  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 121 | train_loss=0.56347  val_loss=0.57257 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 122 | train_loss=0.54418  val_loss=0.57226 | train_MAE=0.7313  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 123 | train_loss=0.54619  val_loss=0.57217 | train_MAE=0.7127  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 124 | train_loss=0.56877  val_loss=0.57326 | train_MAE=0.6922  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 125 | train_loss=0.55491  val_loss=0.57479 | train_MAE=0.7034  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 126 | train_loss=0.56593  val_loss=0.57315 | train_MAE=0.6996  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 127 | train_loss=0.55676  val_loss=0.57973 | train_MAE=0.6847  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 128 | train_loss=0.56371  val_loss=0.58594 | train_MAE=0.7052  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 129 | train_loss=0.55706  val_loss=0.56700 | train_MAE=0.6922  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 130 | train_loss=0.55622  val_loss=0.57149 | train_MAE=0.7071  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 131 | train_loss=0.56256  val_loss=0.57591 | train_MAE=0.6959  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 132 | train_loss=0.57169  val_loss=0.57200 | train_MAE=0.7015  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 133 | train_loss=0.54949  val_loss=0.57664 | train_MAE=0.6959  val_MAE=0.7391 | lr=0.001 | time=0.07s\n",
      "Epoch 134 | train_loss=0.54910  val_loss=0.58382 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 135 | train_loss=0.55112  val_loss=0.57439 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 136 | train_loss=0.56252  val_loss=0.58070 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 137 | train_loss=0.55517  val_loss=0.57529 | train_MAE=0.7108  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 138 | train_loss=0.56356  val_loss=0.56998 | train_MAE=0.7034  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 139 | train_loss=0.55285  val_loss=0.57200 | train_MAE=0.7164  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 140 | train_loss=0.54363  val_loss=0.57787 | train_MAE=0.7146  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 141 | train_loss=0.54782  val_loss=0.58183 | train_MAE=0.7146  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 142 | train_loss=0.55242  val_loss=0.57614 | train_MAE=0.7220  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 143 | train_loss=0.53995  val_loss=0.58158 | train_MAE=0.7425  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 144 | train_loss=0.56016  val_loss=0.57256 | train_MAE=0.6940  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 145 | train_loss=0.55238  val_loss=0.58260 | train_MAE=0.6959  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 146 | train_loss=0.54380  val_loss=0.58586 | train_MAE=0.6996  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 147 | train_loss=0.52645  val_loss=0.58874 | train_MAE=0.7052  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 148 | train_loss=0.54644  val_loss=0.57731 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.001 | time=0.09s\n",
      "Epoch 149 | train_loss=0.56338  val_loss=0.58628 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 150 | train_loss=0.54630  val_loss=0.57260 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 151 | train_loss=0.53907  val_loss=0.57533 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 152 | train_loss=0.54559  val_loss=0.57786 | train_MAE=0.6996  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 153 | train_loss=0.52817  val_loss=0.57771 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 154 | train_loss=0.55177  val_loss=0.57945 | train_MAE=0.7034  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 155 | train_loss=0.53862  val_loss=0.58059 | train_MAE=0.7388  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 156 | train_loss=0.54215  val_loss=0.57529 | train_MAE=0.7164  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 157 | train_loss=0.54057  val_loss=0.57939 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 158 | train_loss=0.52182  val_loss=0.56983 | train_MAE=0.7388  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 159 | train_loss=0.56148  val_loss=0.58258 | train_MAE=0.6716  val_MAE=0.7217 | lr=0.001 | time=0.09s\n",
      "Epoch 160 | train_loss=0.53813  val_loss=0.58831 | train_MAE=0.7369  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 161 | train_loss=0.54222  val_loss=0.58287 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 162 | train_loss=0.54134  val_loss=0.57224 | train_MAE=0.7313  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 163 | train_loss=0.54099  val_loss=0.57247 | train_MAE=0.7108  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 164 | train_loss=0.54186  val_loss=0.57677 | train_MAE=0.7295  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 165 | train_loss=0.53251  val_loss=0.56836 | train_MAE=0.7369  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 166 | train_loss=0.54628  val_loss=0.57525 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 167 | train_loss=0.53400  val_loss=0.58501 | train_MAE=0.7369  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 168 | train_loss=0.54149  val_loss=0.56965 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 169 | train_loss=0.53496  val_loss=0.57057 | train_MAE=0.7444  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 170 | train_loss=0.53843  val_loss=0.56631 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 171 | train_loss=0.52641  val_loss=0.57078 | train_MAE=0.7444  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 172 | train_loss=0.55163  val_loss=0.57559 | train_MAE=0.7034  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 173 | train_loss=0.54601  val_loss=0.58146 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 174 | train_loss=0.54251  val_loss=0.58394 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 175 | train_loss=0.53074  val_loss=0.57684 | train_MAE=0.7407  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 176 | train_loss=0.52911  val_loss=0.57325 | train_MAE=0.7369  val_MAE=0.7478 | lr=0.001 | time=0.09s\n",
      "Epoch 177 | train_loss=0.52720  val_loss=0.58423 | train_MAE=0.7257  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 178 | train_loss=0.51578  val_loss=0.57528 | train_MAE=0.7575  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 179 | train_loss=0.53632  val_loss=0.57765 | train_MAE=0.7332  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 180 | train_loss=0.52866  val_loss=0.57884 | train_MAE=0.7444  val_MAE=0.7652 | lr=0.001 | time=0.09s\n",
      "Epoch 181 | train_loss=0.53774  val_loss=0.57428 | train_MAE=0.7220  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 182 | train_loss=0.53371  val_loss=0.57890 | train_MAE=0.7108  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 183 | train_loss=0.52291  val_loss=0.58283 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 184 | train_loss=0.52936  val_loss=0.58732 | train_MAE=0.7164  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 185 | train_loss=0.53134  val_loss=0.57704 | train_MAE=0.7313  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 186 | train_loss=0.53683  val_loss=0.57516 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 187 | train_loss=0.53684  val_loss=0.56992 | train_MAE=0.7351  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 188 | train_loss=0.52586  val_loss=0.56825 | train_MAE=0.7332  val_MAE=0.7217 | lr=0.001 | time=0.11s\n",
      "Epoch 189 | train_loss=0.53180  val_loss=0.58081 | train_MAE=0.7407  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 190 | train_loss=0.51865  val_loss=0.57062 | train_MAE=0.7332  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 191 | train_loss=0.53558  val_loss=0.57196 | train_MAE=0.7332  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 192 | train_loss=0.53016  val_loss=0.57547 | train_MAE=0.7425  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 193 | train_loss=0.51692  val_loss=0.56811 | train_MAE=0.7351  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 194 | train_loss=0.52600  val_loss=0.57995 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 195 | train_loss=0.51960  val_loss=0.57720 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 196 | train_loss=0.53602  val_loss=0.58357 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 197 | train_loss=0.52022  val_loss=0.58784 | train_MAE=0.7332  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 198 | train_loss=0.53618  val_loss=0.57869 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 199 | train_loss=0.53073  val_loss=0.57598 | train_MAE=0.7388  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 200 | train_loss=0.54475  val_loss=0.56403 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Total training time: 16.55s\n"
     ]
    }
   ],
   "source": [
    "# call my training function with dataloaders\n",
    "history = train_model(model, X_train_dl, X_val_dl, epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a182bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6754\n",
      "Accuracy:  0.617\n",
      "Precision: 0.435  Recall: 0.244  F1: 0.312\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_loss, total_n = 0.0, 0\n",
    "all_logits, all_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in X_test_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        batch_loss = loss(logits, yb).item()\n",
    "        total_loss += batch_loss * xb.size(0)\n",
    "        total_n += xb.size(0)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_true.append(yb.cpu())\n",
    "\n",
    "test_loss = total_loss / total_n\n",
    "logits = torch.cat(all_logits).numpy().ravel()\n",
    "y_true = torch.cat(all_true).numpy().astype(int)\n",
    "probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "y_pred = (probs >= 0.5).astype(int)\n",
    "\n",
    "test_acc = accuracy_score(y_true, y_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Accuracy:  {test_acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}  Recall: {rec:.3f}  F1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30390ed",
   "metadata": {},
   "source": [
    "## Start of Part 2 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eef98c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recreating my neural net so the parameters can be inserted and not set alreayd\n",
    "class NeuralNetworkFlexible(nn.Module):\n",
    "    def __init__(self, input_size=7, hidden_size=64, num_layers=3, dropout=0.2, use_batchnorm=False):\n",
    "        super(NeuralNetworkFlexible, self).__init__()\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        # First hidden layer\n",
    "        layers.append(nn.Linear(input_size, hidden_size))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "        \n",
    "        # Additional hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            if use_batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(hidden_size, 1))\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.linear_relu_stack(x)\n",
    "        return output.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97979769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUNING DROPOUT RATE\n",
      "\n",
      "Training with dropout=0.0\n",
      "Epoch 001 | train_loss=1.30367  val_loss=0.86944 | train_MAE=0.5205  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 002 | train_loss=0.74964  val_loss=0.68134 | train_MAE=0.5597  val_MAE=0.4696 | lr=0.001 | time=0.07s\n",
      "Epoch 003 | train_loss=0.65475  val_loss=0.64589 | train_MAE=0.6418  val_MAE=0.6783 | lr=0.001 | time=0.07s\n",
      "Epoch 004 | train_loss=0.62828  val_loss=0.60066 | train_MAE=0.6642  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 005 | train_loss=0.61543  val_loss=0.59335 | train_MAE=0.6810  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 006 | train_loss=0.59722  val_loss=0.58479 | train_MAE=0.6884  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 007 | train_loss=0.59475  val_loss=0.60169 | train_MAE=0.7071  val_MAE=0.7043 | lr=0.001 | time=0.07s\n",
      "Epoch 008 | train_loss=0.60032  val_loss=0.58689 | train_MAE=0.6884  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 009 | train_loss=0.58970  val_loss=0.57785 | train_MAE=0.7034  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 010 | train_loss=0.58529  val_loss=0.58160 | train_MAE=0.7052  val_MAE=0.7043 | lr=0.001 | time=0.09s\n",
      "Epoch 011 | train_loss=0.58690  val_loss=0.61486 | train_MAE=0.6959  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 012 | train_loss=0.58676  val_loss=0.58625 | train_MAE=0.6940  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 013 | train_loss=0.57299  val_loss=0.58353 | train_MAE=0.7034  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 014 | train_loss=0.56506  val_loss=0.58625 | train_MAE=0.7220  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 015 | train_loss=0.57132  val_loss=0.60537 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.001 | time=0.07s\n",
      "Epoch 016 | train_loss=0.56156  val_loss=0.59502 | train_MAE=0.7090  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 017 | train_loss=0.57043  val_loss=0.57952 | train_MAE=0.7071  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 018 | train_loss=0.56149  val_loss=0.58224 | train_MAE=0.7220  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 019 | train_loss=0.56095  val_loss=0.59481 | train_MAE=0.7146  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 020 | train_loss=0.55654  val_loss=0.58111 | train_MAE=0.7183  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 021 | train_loss=0.55403  val_loss=0.58717 | train_MAE=0.7183  val_MAE=0.7043 | lr=0.001 | time=0.07s\n",
      "Epoch 022 | train_loss=0.55801  val_loss=0.62843 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.001 | time=0.07s\n",
      "Epoch 023 | train_loss=0.58150  val_loss=0.60078 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.07s\n",
      "Epoch 024 | train_loss=0.56011  val_loss=0.60020 | train_MAE=0.6959  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 025 | train_loss=0.55161  val_loss=0.59000 | train_MAE=0.7164  val_MAE=0.6609 | lr=0.001 | time=0.07s\n",
      "Epoch 026 | train_loss=0.54951  val_loss=0.59114 | train_MAE=0.7276  val_MAE=0.6957 | lr=0.001 | time=0.07s\n",
      "Epoch 027 | train_loss=0.54718  val_loss=0.60524 | train_MAE=0.7201  val_MAE=0.7043 | lr=0.001 | time=0.07s\n",
      "Epoch 028 | train_loss=0.54390  val_loss=0.59744 | train_MAE=0.7257  val_MAE=0.6783 | lr=0.001 | time=0.09s\n",
      "Epoch 029 | train_loss=0.54124  val_loss=0.58993 | train_MAE=0.7351  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 030 | train_loss=0.57292  val_loss=0.60451 | train_MAE=0.7034  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 031 | train_loss=0.54994  val_loss=0.60640 | train_MAE=0.7164  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 032 | train_loss=0.55732  val_loss=0.59816 | train_MAE=0.7220  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 033 | train_loss=0.56151  val_loss=0.58766 | train_MAE=0.7146  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 034 | train_loss=0.55201  val_loss=0.59040 | train_MAE=0.7146  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 035 | train_loss=0.53868  val_loss=0.59091 | train_MAE=0.7239  val_MAE=0.7130 | lr=0.001 | time=0.07s\n",
      "Epoch 036 | train_loss=0.53760  val_loss=0.58125 | train_MAE=0.7257  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 037 | train_loss=0.53434  val_loss=0.59385 | train_MAE=0.7239  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 038 | train_loss=0.53306  val_loss=0.59878 | train_MAE=0.7351  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 039 | train_loss=0.54268  val_loss=0.62642 | train_MAE=0.7127  val_MAE=0.6174 | lr=0.001 | time=0.08s\n",
      "Epoch 040 | train_loss=0.56652  val_loss=0.59982 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 041 | train_loss=0.54915  val_loss=0.60132 | train_MAE=0.7239  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 042 | train_loss=0.54028  val_loss=0.59643 | train_MAE=0.7239  val_MAE=0.6957 | lr=0.001 | time=0.07s\n",
      "Epoch 043 | train_loss=0.53153  val_loss=0.58602 | train_MAE=0.7351  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 044 | train_loss=0.52727  val_loss=0.59841 | train_MAE=0.7313  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 045 | train_loss=0.54836  val_loss=0.61730 | train_MAE=0.7015  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 046 | train_loss=0.54047  val_loss=0.61527 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 047 | train_loss=0.52768  val_loss=0.59302 | train_MAE=0.7295  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 048 | train_loss=0.52906  val_loss=0.64233 | train_MAE=0.7164  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 049 | train_loss=0.54673  val_loss=0.60343 | train_MAE=0.7108  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 050 | train_loss=0.53407  val_loss=0.60201 | train_MAE=0.7220  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 051 | train_loss=0.52856  val_loss=0.61079 | train_MAE=0.7295  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 052 | train_loss=0.52255  val_loss=0.60716 | train_MAE=0.7332  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 053 | train_loss=0.55937  val_loss=0.61336 | train_MAE=0.6959  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 054 | train_loss=0.56929  val_loss=0.62126 | train_MAE=0.7090  val_MAE=0.6261 | lr=0.001 | time=0.08s\n",
      "Epoch 055 | train_loss=0.52908  val_loss=0.59745 | train_MAE=0.7351  val_MAE=0.7130 | lr=0.001 | time=0.07s\n",
      "Epoch 056 | train_loss=0.53532  val_loss=0.60686 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 057 | train_loss=0.51963  val_loss=0.60284 | train_MAE=0.7481  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 058 | train_loss=0.52282  val_loss=0.60403 | train_MAE=0.7295  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 059 | train_loss=0.52380  val_loss=0.60795 | train_MAE=0.7239  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 060 | train_loss=0.51567  val_loss=0.61323 | train_MAE=0.7444  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 061 | train_loss=0.52047  val_loss=0.60340 | train_MAE=0.7351  val_MAE=0.6870 | lr=0.001 | time=0.16s\n",
      "Epoch 062 | train_loss=0.51409  val_loss=0.61866 | train_MAE=0.7332  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 063 | train_loss=0.52350  val_loss=0.62070 | train_MAE=0.7257  val_MAE=0.7043 | lr=0.001 | time=0.07s\n",
      "Epoch 064 | train_loss=0.50920  val_loss=0.62391 | train_MAE=0.7425  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 065 | train_loss=0.51183  val_loss=0.67111 | train_MAE=0.7444  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 066 | train_loss=0.55002  val_loss=0.61574 | train_MAE=0.7276  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 067 | train_loss=0.52219  val_loss=0.61380 | train_MAE=0.7332  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 068 | train_loss=0.51266  val_loss=0.61146 | train_MAE=0.7425  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 069 | train_loss=0.51194  val_loss=0.61580 | train_MAE=0.7351  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 070 | train_loss=0.52376  val_loss=0.61355 | train_MAE=0.7369  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 071 | train_loss=0.52845  val_loss=0.61419 | train_MAE=0.7351  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 072 | train_loss=0.51411  val_loss=0.63317 | train_MAE=0.7369  val_MAE=0.7478 | lr=0.001 | time=0.13s\n",
      "Epoch 073 | train_loss=0.51002  val_loss=0.61930 | train_MAE=0.7351  val_MAE=0.6957 | lr=0.001 | time=0.15s\n",
      "Epoch 074 | train_loss=0.50344  val_loss=0.62379 | train_MAE=0.7407  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 075 | train_loss=0.50243  val_loss=0.61310 | train_MAE=0.7463  val_MAE=0.6696 | lr=0.001 | time=0.09s\n",
      "Epoch 076 | train_loss=0.50053  val_loss=0.61774 | train_MAE=0.7556  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 077 | train_loss=0.49597  val_loss=0.63217 | train_MAE=0.7388  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 078 | train_loss=0.51312  val_loss=0.62649 | train_MAE=0.7369  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 079 | train_loss=0.51660  val_loss=0.64735 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 080 | train_loss=0.52076  val_loss=0.61976 | train_MAE=0.7369  val_MAE=0.6696 | lr=0.001 | time=0.09s\n",
      "Epoch 081 | train_loss=0.50334  val_loss=0.62800 | train_MAE=0.7519  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 082 | train_loss=0.49855  val_loss=0.61004 | train_MAE=0.7463  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 083 | train_loss=0.50711  val_loss=0.64982 | train_MAE=0.7519  val_MAE=0.7304 | lr=0.001 | time=0.09s\n",
      "Epoch 084 | train_loss=0.51514  val_loss=0.64084 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 085 | train_loss=0.50295  val_loss=0.63734 | train_MAE=0.7295  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 086 | train_loss=0.51814  val_loss=0.64175 | train_MAE=0.7332  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 087 | train_loss=0.52047  val_loss=0.64935 | train_MAE=0.7313  val_MAE=0.7304 | lr=0.001 | time=0.07s\n",
      "Epoch 088 | train_loss=0.52804  val_loss=0.61437 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.001 | time=0.07s\n",
      "Epoch 089 | train_loss=0.51265  val_loss=0.66680 | train_MAE=0.7481  val_MAE=0.6609 | lr=0.001 | time=0.07s\n",
      "Epoch 090 | train_loss=0.50040  val_loss=0.65437 | train_MAE=0.7425  val_MAE=0.7391 | lr=0.001 | time=0.07s\n",
      "Epoch 091 | train_loss=0.49669  val_loss=0.64342 | train_MAE=0.7425  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 092 | train_loss=0.52278  val_loss=0.64697 | train_MAE=0.7127  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 093 | train_loss=0.50935  val_loss=0.63970 | train_MAE=0.7575  val_MAE=0.7130 | lr=0.001 | time=0.07s\n",
      "Epoch 094 | train_loss=0.50046  val_loss=0.63639 | train_MAE=0.7220  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 095 | train_loss=0.51182  val_loss=0.62479 | train_MAE=0.7388  val_MAE=0.6696 | lr=0.001 | time=0.07s\n",
      "Epoch 096 | train_loss=0.49940  val_loss=0.65123 | train_MAE=0.7351  val_MAE=0.7217 | lr=0.001 | time=0.07s\n",
      "Epoch 097 | train_loss=0.50227  val_loss=0.63696 | train_MAE=0.7351  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 098 | train_loss=0.53109  val_loss=0.65251 | train_MAE=0.7220  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 099 | train_loss=0.52803  val_loss=0.65975 | train_MAE=0.7276  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 100 | train_loss=0.50357  val_loss=0.60980 | train_MAE=0.7463  val_MAE=0.6696 | lr=0.001 | time=0.07s\n",
      "Epoch 101 | train_loss=0.50148  val_loss=0.61328 | train_MAE=0.7444  val_MAE=0.7130 | lr=0.001 | time=0.09s\n",
      "Epoch 102 | train_loss=0.48628  val_loss=0.62802 | train_MAE=0.7593  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 103 | train_loss=0.47993  val_loss=0.64095 | train_MAE=0.7668  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 104 | train_loss=0.47748  val_loss=0.65415 | train_MAE=0.7537  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 105 | train_loss=0.47835  val_loss=0.65339 | train_MAE=0.7631  val_MAE=0.6174 | lr=0.001 | time=0.07s\n",
      "Epoch 106 | train_loss=0.50501  val_loss=0.67419 | train_MAE=0.7164  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 107 | train_loss=0.49539  val_loss=0.63469 | train_MAE=0.7537  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 108 | train_loss=0.48177  val_loss=0.66096 | train_MAE=0.7705  val_MAE=0.7130 | lr=0.001 | time=0.07s\n",
      "Epoch 109 | train_loss=0.48528  val_loss=0.63290 | train_MAE=0.7593  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 110 | train_loss=0.47865  val_loss=0.65251 | train_MAE=0.7463  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 111 | train_loss=0.47104  val_loss=0.66234 | train_MAE=0.7668  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 112 | train_loss=0.46868  val_loss=0.66043 | train_MAE=0.7612  val_MAE=0.7043 | lr=0.001 | time=0.07s\n",
      "Epoch 113 | train_loss=0.46577  val_loss=0.68231 | train_MAE=0.7668  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 114 | train_loss=0.46510  val_loss=0.68993 | train_MAE=0.7593  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 115 | train_loss=0.46399  val_loss=0.68097 | train_MAE=0.7612  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 116 | train_loss=0.45988  val_loss=0.70139 | train_MAE=0.7761  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 117 | train_loss=0.46236  val_loss=0.68103 | train_MAE=0.7649  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 118 | train_loss=0.46538  val_loss=0.70764 | train_MAE=0.7761  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 119 | train_loss=0.46997  val_loss=0.66439 | train_MAE=0.7631  val_MAE=0.6435 | lr=0.001 | time=0.08s\n",
      "Epoch 120 | train_loss=0.47875  val_loss=0.65726 | train_MAE=0.7575  val_MAE=0.6957 | lr=0.001 | time=0.07s\n",
      "Epoch 121 | train_loss=0.47240  val_loss=0.73883 | train_MAE=0.7649  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 122 | train_loss=0.48671  val_loss=0.66743 | train_MAE=0.7724  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 123 | train_loss=0.46955  val_loss=0.67117 | train_MAE=0.7817  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 124 | train_loss=0.45823  val_loss=0.65820 | train_MAE=0.7705  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 125 | train_loss=0.45974  val_loss=0.69646 | train_MAE=0.7724  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 126 | train_loss=0.46042  val_loss=0.65846 | train_MAE=0.7631  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 127 | train_loss=0.45589  val_loss=0.69460 | train_MAE=0.7649  val_MAE=0.6870 | lr=0.001 | time=0.07s\n",
      "Epoch 128 | train_loss=0.45379  val_loss=0.69556 | train_MAE=0.7836  val_MAE=0.6870 | lr=0.001 | time=0.14s\n",
      "Epoch 129 | train_loss=0.45427  val_loss=0.67615 | train_MAE=0.7631  val_MAE=0.6957 | lr=0.001 | time=0.07s\n",
      "Epoch 130 | train_loss=0.45231  val_loss=0.66887 | train_MAE=0.7761  val_MAE=0.6783 | lr=0.001 | time=0.07s\n",
      "Epoch 131 | train_loss=0.45853  val_loss=0.69227 | train_MAE=0.7892  val_MAE=0.6783 | lr=0.001 | time=0.07s\n",
      "Epoch 132 | train_loss=0.45272  val_loss=0.73457 | train_MAE=0.7705  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 133 | train_loss=0.45950  val_loss=0.72585 | train_MAE=0.7687  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 134 | train_loss=0.44992  val_loss=0.68765 | train_MAE=0.7743  val_MAE=0.7130 | lr=0.001 | time=0.07s\n",
      "Epoch 135 | train_loss=0.44570  val_loss=0.68713 | train_MAE=0.7631  val_MAE=0.6696 | lr=0.001 | time=0.07s\n",
      "Epoch 136 | train_loss=0.44923  val_loss=0.69845 | train_MAE=0.7780  val_MAE=0.6870 | lr=0.001 | time=0.07s\n",
      "Epoch 137 | train_loss=0.43959  val_loss=0.73631 | train_MAE=0.7854  val_MAE=0.6783 | lr=0.001 | time=0.07s\n",
      "Epoch 138 | train_loss=0.44059  val_loss=0.79824 | train_MAE=0.7780  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 139 | train_loss=0.46530  val_loss=0.71401 | train_MAE=0.7649  val_MAE=0.6609 | lr=0.001 | time=0.07s\n",
      "Epoch 140 | train_loss=0.44642  val_loss=0.73629 | train_MAE=0.7705  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 141 | train_loss=0.42633  val_loss=0.88041 | train_MAE=0.8060  val_MAE=0.6696 | lr=0.001 | time=0.07s\n",
      "Epoch 142 | train_loss=0.46816  val_loss=0.67582 | train_MAE=0.7593  val_MAE=0.6870 | lr=0.001 | time=0.07s\n",
      "Epoch 143 | train_loss=0.44222  val_loss=0.73916 | train_MAE=0.7799  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 144 | train_loss=0.44567  val_loss=0.68855 | train_MAE=0.7836  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 145 | train_loss=0.43691  val_loss=0.69588 | train_MAE=0.7761  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 146 | train_loss=0.43170  val_loss=0.68758 | train_MAE=0.7836  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 147 | train_loss=0.44316  val_loss=0.73613 | train_MAE=0.7836  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 148 | train_loss=0.44421  val_loss=0.72378 | train_MAE=0.7836  val_MAE=0.6348 | lr=0.001 | time=0.07s\n",
      "Epoch 149 | train_loss=0.44259  val_loss=0.71709 | train_MAE=0.7761  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 150 | train_loss=0.44293  val_loss=0.71744 | train_MAE=0.7649  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 151 | train_loss=0.43725  val_loss=0.70481 | train_MAE=0.7761  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 152 | train_loss=0.42917  val_loss=0.70807 | train_MAE=0.7929  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 153 | train_loss=0.42835  val_loss=0.71578 | train_MAE=0.7910  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 154 | train_loss=0.42678  val_loss=0.74898 | train_MAE=0.7836  val_MAE=0.7043 | lr=0.001 | time=0.07s\n",
      "Epoch 155 | train_loss=0.43164  val_loss=0.74905 | train_MAE=0.7929  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 156 | train_loss=0.41663  val_loss=0.75813 | train_MAE=0.7836  val_MAE=0.6957 | lr=0.001 | time=0.09s\n",
      "Epoch 157 | train_loss=0.41429  val_loss=0.73596 | train_MAE=0.7929  val_MAE=0.6348 | lr=0.001 | time=0.08s\n",
      "Epoch 158 | train_loss=0.45280  val_loss=0.76529 | train_MAE=0.7799  val_MAE=0.6957 | lr=0.001 | time=0.07s\n",
      "Epoch 159 | train_loss=0.45493  val_loss=0.77058 | train_MAE=0.7817  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 160 | train_loss=0.42747  val_loss=0.76695 | train_MAE=0.7836  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 161 | train_loss=0.42069  val_loss=0.77391 | train_MAE=0.7892  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 162 | train_loss=0.41395  val_loss=0.74138 | train_MAE=0.7985  val_MAE=0.6696 | lr=0.001 | time=0.09s\n",
      "Epoch 163 | train_loss=0.41319  val_loss=0.74850 | train_MAE=0.7836  val_MAE=0.6522 | lr=0.001 | time=0.17s\n",
      "Epoch 164 | train_loss=0.40916  val_loss=0.78362 | train_MAE=0.8022  val_MAE=0.7043 | lr=0.001 | time=0.21s\n",
      "Epoch 165 | train_loss=0.41401  val_loss=0.79563 | train_MAE=0.8022  val_MAE=0.6609 | lr=0.001 | time=0.13s\n",
      "Epoch 166 | train_loss=0.40723  val_loss=0.78640 | train_MAE=0.8041  val_MAE=0.6696 | lr=0.001 | time=0.09s\n",
      "Epoch 167 | train_loss=0.42730  val_loss=0.74155 | train_MAE=0.7761  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 168 | train_loss=0.43047  val_loss=0.77696 | train_MAE=0.7892  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 169 | train_loss=0.44831  val_loss=0.77728 | train_MAE=0.7836  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 170 | train_loss=0.41710  val_loss=0.75238 | train_MAE=0.7799  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 171 | train_loss=0.41887  val_loss=0.76598 | train_MAE=0.7948  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 172 | train_loss=0.42480  val_loss=0.80214 | train_MAE=0.7985  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 173 | train_loss=0.41926  val_loss=0.81535 | train_MAE=0.8172  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 174 | train_loss=0.40937  val_loss=0.78560 | train_MAE=0.8041  val_MAE=0.6870 | lr=0.001 | time=0.09s\n",
      "Epoch 175 | train_loss=0.41435  val_loss=0.81742 | train_MAE=0.8078  val_MAE=0.6696 | lr=0.001 | time=0.10s\n",
      "Epoch 176 | train_loss=0.39305  val_loss=0.79280 | train_MAE=0.8097  val_MAE=0.6261 | lr=0.001 | time=0.08s\n",
      "Epoch 177 | train_loss=0.41474  val_loss=0.79381 | train_MAE=0.7873  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 178 | train_loss=0.45597  val_loss=0.78057 | train_MAE=0.7743  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 179 | train_loss=0.44364  val_loss=0.80002 | train_MAE=0.7836  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 180 | train_loss=0.42685  val_loss=0.81491 | train_MAE=0.7854  val_MAE=0.6435 | lr=0.001 | time=0.08s\n",
      "Epoch 181 | train_loss=0.43308  val_loss=0.81507 | train_MAE=0.7799  val_MAE=0.6783 | lr=0.001 | time=0.12s\n",
      "Epoch 182 | train_loss=0.40813  val_loss=0.80012 | train_MAE=0.8022  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 183 | train_loss=0.42850  val_loss=0.80248 | train_MAE=0.7724  val_MAE=0.6261 | lr=0.001 | time=0.08s\n",
      "Epoch 184 | train_loss=0.40865  val_loss=0.78541 | train_MAE=0.7985  val_MAE=0.6783 | lr=0.001 | time=0.13s\n",
      "Epoch 185 | train_loss=0.40971  val_loss=0.93049 | train_MAE=0.8116  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 186 | train_loss=0.46644  val_loss=0.75467 | train_MAE=0.7724  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 187 | train_loss=0.39652  val_loss=0.79968 | train_MAE=0.8134  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 188 | train_loss=0.40849  val_loss=0.83963 | train_MAE=0.8004  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 189 | train_loss=0.40545  val_loss=0.78139 | train_MAE=0.8022  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 190 | train_loss=0.40043  val_loss=0.83004 | train_MAE=0.7966  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 191 | train_loss=0.39344  val_loss=0.77779 | train_MAE=0.8116  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 192 | train_loss=0.40200  val_loss=0.79239 | train_MAE=0.7985  val_MAE=0.6261 | lr=0.001 | time=0.07s\n",
      "Epoch 193 | train_loss=0.42370  val_loss=0.83647 | train_MAE=0.7799  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 194 | train_loss=0.39549  val_loss=0.85775 | train_MAE=0.8022  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 195 | train_loss=0.39817  val_loss=0.82229 | train_MAE=0.8041  val_MAE=0.6522 | lr=0.001 | time=0.15s\n",
      "Epoch 196 | train_loss=0.39240  val_loss=0.84191 | train_MAE=0.8116  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 197 | train_loss=0.37496  val_loss=0.83331 | train_MAE=0.8153  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 198 | train_loss=0.38217  val_loss=0.85426 | train_MAE=0.8097  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 199 | train_loss=0.37993  val_loss=0.84667 | train_MAE=0.8097  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 200 | train_loss=0.38078  val_loss=0.85101 | train_MAE=0.8022  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Total training time: 16.28s\n",
      "Test Accuracy: 0.6087\n",
      "\n",
      "Training with dropout=0.1\n",
      "Epoch 001 | train_loss=0.91580  val_loss=0.63044 | train_MAE=0.5261  val_MAE=0.6609 | lr=0.001 | time=0.11s\n",
      "Epoch 002 | train_loss=0.73145  val_loss=0.62450 | train_MAE=0.5989  val_MAE=0.6435 | lr=0.001 | time=0.08s\n",
      "Epoch 003 | train_loss=0.72839  val_loss=0.60893 | train_MAE=0.6119  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 004 | train_loss=0.69845  val_loss=0.60730 | train_MAE=0.5951  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 005 | train_loss=0.68655  val_loss=0.61890 | train_MAE=0.6530  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 006 | train_loss=0.66229  val_loss=0.61834 | train_MAE=0.6250  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 007 | train_loss=0.67086  val_loss=0.62259 | train_MAE=0.6343  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 008 | train_loss=0.64124  val_loss=0.61015 | train_MAE=0.6549  val_MAE=0.6435 | lr=0.001 | time=0.08s\n",
      "Epoch 009 | train_loss=0.64140  val_loss=0.59436 | train_MAE=0.6623  val_MAE=0.6783 | lr=0.001 | time=0.18s\n",
      "Epoch 010 | train_loss=0.62742  val_loss=0.60175 | train_MAE=0.6604  val_MAE=0.6696 | lr=0.001 | time=0.13s\n",
      "Epoch 011 | train_loss=0.61703  val_loss=0.59034 | train_MAE=0.6791  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 012 | train_loss=0.63590  val_loss=0.59305 | train_MAE=0.6549  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 013 | train_loss=0.63952  val_loss=0.58933 | train_MAE=0.6287  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 014 | train_loss=0.62483  val_loss=0.58735 | train_MAE=0.6716  val_MAE=0.7130 | lr=0.001 | time=0.11s\n",
      "Epoch 015 | train_loss=0.62724  val_loss=0.59882 | train_MAE=0.6604  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 016 | train_loss=0.63004  val_loss=0.58950 | train_MAE=0.6623  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 017 | train_loss=0.61924  val_loss=0.58137 | train_MAE=0.6772  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 018 | train_loss=0.61958  val_loss=0.58015 | train_MAE=0.6772  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 019 | train_loss=0.61801  val_loss=0.57587 | train_MAE=0.6772  val_MAE=0.7130 | lr=0.001 | time=0.09s\n",
      "Epoch 020 | train_loss=0.60637  val_loss=0.59026 | train_MAE=0.6828  val_MAE=0.6957 | lr=0.001 | time=0.13s\n",
      "Epoch 021 | train_loss=0.60895  val_loss=0.60206 | train_MAE=0.6772  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 022 | train_loss=0.60306  val_loss=0.59619 | train_MAE=0.6474  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 023 | train_loss=0.60318  val_loss=0.59444 | train_MAE=0.6754  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 024 | train_loss=0.59891  val_loss=0.59107 | train_MAE=0.6754  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 025 | train_loss=0.60942  val_loss=0.58625 | train_MAE=0.6660  val_MAE=0.6348 | lr=0.001 | time=0.08s\n",
      "Epoch 026 | train_loss=0.60897  val_loss=0.58766 | train_MAE=0.6325  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 027 | train_loss=0.59230  val_loss=0.59812 | train_MAE=0.7146  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 028 | train_loss=0.60031  val_loss=0.59044 | train_MAE=0.6679  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 029 | train_loss=0.59087  val_loss=0.58995 | train_MAE=0.6959  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 030 | train_loss=0.59410  val_loss=0.59122 | train_MAE=0.6791  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 031 | train_loss=0.60993  val_loss=0.58526 | train_MAE=0.6623  val_MAE=0.6696 | lr=0.001 | time=0.13s\n",
      "Epoch 032 | train_loss=0.59306  val_loss=0.59099 | train_MAE=0.6716  val_MAE=0.7217 | lr=0.001 | time=0.10s\n",
      "Epoch 033 | train_loss=0.58208  val_loss=0.58701 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 034 | train_loss=0.60391  val_loss=0.58016 | train_MAE=0.6642  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 035 | train_loss=0.60255  val_loss=0.58344 | train_MAE=0.6660  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 036 | train_loss=0.59019  val_loss=0.58408 | train_MAE=0.6940  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 037 | train_loss=0.57306  val_loss=0.58409 | train_MAE=0.6959  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 038 | train_loss=0.57449  val_loss=0.58759 | train_MAE=0.6791  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 039 | train_loss=0.60046  val_loss=0.58509 | train_MAE=0.6922  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 040 | train_loss=0.59660  val_loss=0.59228 | train_MAE=0.6642  val_MAE=0.6435 | lr=0.001 | time=0.08s\n",
      "Epoch 041 | train_loss=0.57917  val_loss=0.59087 | train_MAE=0.6642  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 042 | train_loss=0.58404  val_loss=0.58206 | train_MAE=0.6903  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 043 | train_loss=0.58141  val_loss=0.58187 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 044 | train_loss=0.57492  val_loss=0.58165 | train_MAE=0.7146  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 045 | train_loss=0.56944  val_loss=0.58121 | train_MAE=0.7108  val_MAE=0.7043 | lr=0.001 | time=0.09s\n",
      "Epoch 046 | train_loss=0.56458  val_loss=0.58116 | train_MAE=0.7220  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 047 | train_loss=0.57212  val_loss=0.58276 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 048 | train_loss=0.57871  val_loss=0.58558 | train_MAE=0.6978  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 049 | train_loss=0.57260  val_loss=0.58545 | train_MAE=0.7034  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 050 | train_loss=0.57053  val_loss=0.58527 | train_MAE=0.6884  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 051 | train_loss=0.57076  val_loss=0.58187 | train_MAE=0.6978  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 052 | train_loss=0.57691  val_loss=0.58166 | train_MAE=0.6754  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 053 | train_loss=0.57983  val_loss=0.57918 | train_MAE=0.7015  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 054 | train_loss=0.57391  val_loss=0.58564 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 055 | train_loss=0.57620  val_loss=0.58049 | train_MAE=0.7034  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 056 | train_loss=0.56233  val_loss=0.59506 | train_MAE=0.6996  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 057 | train_loss=0.57558  val_loss=0.58294 | train_MAE=0.6884  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 058 | train_loss=0.56797  val_loss=0.57940 | train_MAE=0.7183  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 059 | train_loss=0.56190  val_loss=0.59109 | train_MAE=0.7090  val_MAE=0.7130 | lr=0.001 | time=0.09s\n",
      "Epoch 060 | train_loss=0.57051  val_loss=0.59032 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 061 | train_loss=0.57558  val_loss=0.58471 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 062 | train_loss=0.56966  val_loss=0.58350 | train_MAE=0.6940  val_MAE=0.6957 | lr=0.001 | time=0.09s\n",
      "Epoch 063 | train_loss=0.56088  val_loss=0.58392 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 064 | train_loss=0.56445  val_loss=0.58024 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 065 | train_loss=0.55952  val_loss=0.58204 | train_MAE=0.7183  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 066 | train_loss=0.56561  val_loss=0.59063 | train_MAE=0.7090  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 067 | train_loss=0.56506  val_loss=0.58566 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 068 | train_loss=0.55894  val_loss=0.58921 | train_MAE=0.7108  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 069 | train_loss=0.57500  val_loss=0.58082 | train_MAE=0.7164  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 070 | train_loss=0.57608  val_loss=0.58556 | train_MAE=0.6940  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 071 | train_loss=0.57406  val_loss=0.58773 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.001 | time=0.09s\n",
      "Epoch 072 | train_loss=0.55272  val_loss=0.57945 | train_MAE=0.7407  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 073 | train_loss=0.56360  val_loss=0.58084 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 074 | train_loss=0.56797  val_loss=0.57994 | train_MAE=0.6978  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 075 | train_loss=0.55782  val_loss=0.57346 | train_MAE=0.7090  val_MAE=0.6870 | lr=0.001 | time=0.11s\n",
      "Epoch 076 | train_loss=0.55972  val_loss=0.57422 | train_MAE=0.7034  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 077 | train_loss=0.56642  val_loss=0.58745 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 078 | train_loss=0.55972  val_loss=0.57972 | train_MAE=0.7071  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 079 | train_loss=0.53206  val_loss=0.58425 | train_MAE=0.7276  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 080 | train_loss=0.56172  val_loss=0.57553 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 081 | train_loss=0.55256  val_loss=0.57440 | train_MAE=0.7388  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 082 | train_loss=0.55453  val_loss=0.57448 | train_MAE=0.7220  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 083 | train_loss=0.55625  val_loss=0.57308 | train_MAE=0.7201  val_MAE=0.6957 | lr=0.001 | time=0.13s\n",
      "Epoch 084 | train_loss=0.55025  val_loss=0.58003 | train_MAE=0.7146  val_MAE=0.6783 | lr=0.001 | time=0.14s\n",
      "Epoch 085 | train_loss=0.53172  val_loss=0.58084 | train_MAE=0.7537  val_MAE=0.7043 | lr=0.001 | time=0.10s\n",
      "Epoch 086 | train_loss=0.55015  val_loss=0.58409 | train_MAE=0.7071  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 087 | train_loss=0.53213  val_loss=0.59280 | train_MAE=0.7146  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 088 | train_loss=0.54372  val_loss=0.58493 | train_MAE=0.7313  val_MAE=0.6957 | lr=0.001 | time=0.09s\n",
      "Epoch 089 | train_loss=0.54912  val_loss=0.58332 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.001 | time=0.16s\n",
      "Epoch 090 | train_loss=0.55613  val_loss=0.58378 | train_MAE=0.7201  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 091 | train_loss=0.54921  val_loss=0.57512 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.001 | time=0.09s\n",
      "Epoch 092 | train_loss=0.54262  val_loss=0.57333 | train_MAE=0.7239  val_MAE=0.7043 | lr=0.001 | time=0.09s\n",
      "Epoch 093 | train_loss=0.54928  val_loss=0.58094 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.001 | time=0.09s\n",
      "Epoch 094 | train_loss=0.53684  val_loss=0.57993 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 095 | train_loss=0.53429  val_loss=0.58225 | train_MAE=0.7407  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 096 | train_loss=0.54204  val_loss=0.58231 | train_MAE=0.7146  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 097 | train_loss=0.55041  val_loss=0.57318 | train_MAE=0.7201  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 098 | train_loss=0.54107  val_loss=0.58148 | train_MAE=0.7276  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 099 | train_loss=0.53107  val_loss=0.57382 | train_MAE=0.7146  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 100 | train_loss=0.55632  val_loss=0.58102 | train_MAE=0.7239  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 101 | train_loss=0.52838  val_loss=0.58933 | train_MAE=0.7332  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 102 | train_loss=0.54934  val_loss=0.58245 | train_MAE=0.7425  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 103 | train_loss=0.54893  val_loss=0.58197 | train_MAE=0.7201  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 104 | train_loss=0.53087  val_loss=0.58216 | train_MAE=0.7146  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 105 | train_loss=0.53364  val_loss=0.58080 | train_MAE=0.7201  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 106 | train_loss=0.53482  val_loss=0.58773 | train_MAE=0.7257  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 107 | train_loss=0.52172  val_loss=0.59397 | train_MAE=0.7220  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 108 | train_loss=0.52937  val_loss=0.58902 | train_MAE=0.7351  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 109 | train_loss=0.53333  val_loss=0.59022 | train_MAE=0.7444  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 110 | train_loss=0.53392  val_loss=0.59103 | train_MAE=0.7276  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 111 | train_loss=0.53324  val_loss=0.58137 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 112 | train_loss=0.52008  val_loss=0.58446 | train_MAE=0.7388  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 113 | train_loss=0.54632  val_loss=0.58079 | train_MAE=0.7239  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 114 | train_loss=0.52541  val_loss=0.58856 | train_MAE=0.7463  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 115 | train_loss=0.53367  val_loss=0.57871 | train_MAE=0.7220  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 116 | train_loss=0.53131  val_loss=0.57605 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 117 | train_loss=0.54643  val_loss=0.58234 | train_MAE=0.7295  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 118 | train_loss=0.53000  val_loss=0.57993 | train_MAE=0.7276  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 119 | train_loss=0.52277  val_loss=0.58044 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 120 | train_loss=0.52855  val_loss=0.58119 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 121 | train_loss=0.52551  val_loss=0.59049 | train_MAE=0.7332  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 122 | train_loss=0.54052  val_loss=0.57795 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 123 | train_loss=0.52657  val_loss=0.58991 | train_MAE=0.7444  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 124 | train_loss=0.54123  val_loss=0.59735 | train_MAE=0.7183  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 125 | train_loss=0.52479  val_loss=0.59741 | train_MAE=0.7276  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 126 | train_loss=0.54851  val_loss=0.58896 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 127 | train_loss=0.53226  val_loss=0.58301 | train_MAE=0.7239  val_MAE=0.7043 | lr=0.001 | time=0.09s\n",
      "Epoch 128 | train_loss=0.53756  val_loss=0.57694 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 129 | train_loss=0.53117  val_loss=0.58289 | train_MAE=0.7351  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 130 | train_loss=0.54395  val_loss=0.58710 | train_MAE=0.7164  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 131 | train_loss=0.52730  val_loss=0.59345 | train_MAE=0.7257  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 132 | train_loss=0.53010  val_loss=0.59375 | train_MAE=0.7220  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 133 | train_loss=0.52629  val_loss=0.60250 | train_MAE=0.7295  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 134 | train_loss=0.50775  val_loss=0.59933 | train_MAE=0.7481  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 135 | train_loss=0.53290  val_loss=0.59503 | train_MAE=0.7220  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 136 | train_loss=0.52197  val_loss=0.59472 | train_MAE=0.7332  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 137 | train_loss=0.52616  val_loss=0.60432 | train_MAE=0.7313  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 138 | train_loss=0.52356  val_loss=0.59503 | train_MAE=0.7481  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 139 | train_loss=0.53083  val_loss=0.58807 | train_MAE=0.7071  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 140 | train_loss=0.52871  val_loss=0.58899 | train_MAE=0.7295  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 141 | train_loss=0.51796  val_loss=0.59241 | train_MAE=0.7463  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 142 | train_loss=0.51576  val_loss=0.59610 | train_MAE=0.7276  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 143 | train_loss=0.52075  val_loss=0.59778 | train_MAE=0.7276  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 144 | train_loss=0.52686  val_loss=0.60225 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 145 | train_loss=0.52134  val_loss=0.59340 | train_MAE=0.7313  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 146 | train_loss=0.51959  val_loss=0.58972 | train_MAE=0.7276  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 147 | train_loss=0.52214  val_loss=0.60195 | train_MAE=0.7369  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 148 | train_loss=0.51092  val_loss=0.59450 | train_MAE=0.7369  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 149 | train_loss=0.52845  val_loss=0.59031 | train_MAE=0.7276  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 150 | train_loss=0.51829  val_loss=0.59239 | train_MAE=0.7388  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 151 | train_loss=0.50975  val_loss=0.59493 | train_MAE=0.7425  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 152 | train_loss=0.50858  val_loss=0.59347 | train_MAE=0.7407  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 153 | train_loss=0.52498  val_loss=0.58746 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 154 | train_loss=0.51381  val_loss=0.60976 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 155 | train_loss=0.52179  val_loss=0.59262 | train_MAE=0.7444  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 156 | train_loss=0.51617  val_loss=0.58698 | train_MAE=0.7407  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 157 | train_loss=0.51619  val_loss=0.58593 | train_MAE=0.7519  val_MAE=0.6957 | lr=0.001 | time=0.09s\n",
      "Epoch 158 | train_loss=0.52187  val_loss=0.58551 | train_MAE=0.7351  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 159 | train_loss=0.51847  val_loss=0.59289 | train_MAE=0.7444  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 160 | train_loss=0.51489  val_loss=0.58576 | train_MAE=0.7463  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 161 | train_loss=0.49862  val_loss=0.59419 | train_MAE=0.7481  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 162 | train_loss=0.50662  val_loss=0.58989 | train_MAE=0.7332  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 163 | train_loss=0.49818  val_loss=0.60391 | train_MAE=0.7463  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 164 | train_loss=0.51937  val_loss=0.59665 | train_MAE=0.7313  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 165 | train_loss=0.50371  val_loss=0.58563 | train_MAE=0.7407  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 166 | train_loss=0.50927  val_loss=0.59016 | train_MAE=0.7388  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 167 | train_loss=0.51669  val_loss=0.58859 | train_MAE=0.7332  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 168 | train_loss=0.51183  val_loss=0.61449 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 169 | train_loss=0.50821  val_loss=0.58962 | train_MAE=0.7444  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 170 | train_loss=0.53481  val_loss=0.58921 | train_MAE=0.7183  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 171 | train_loss=0.49668  val_loss=0.60425 | train_MAE=0.7500  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 172 | train_loss=0.49311  val_loss=0.61404 | train_MAE=0.7500  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 173 | train_loss=0.50334  val_loss=0.59873 | train_MAE=0.7407  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 174 | train_loss=0.49471  val_loss=0.60271 | train_MAE=0.7425  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 175 | train_loss=0.50329  val_loss=0.60338 | train_MAE=0.7556  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 176 | train_loss=0.49944  val_loss=0.60229 | train_MAE=0.7612  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 177 | train_loss=0.50205  val_loss=0.60280 | train_MAE=0.7425  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 178 | train_loss=0.50388  val_loss=0.59618 | train_MAE=0.7313  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 179 | train_loss=0.50413  val_loss=0.59898 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 180 | train_loss=0.49895  val_loss=0.60609 | train_MAE=0.7407  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 181 | train_loss=0.49631  val_loss=0.61066 | train_MAE=0.7575  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 182 | train_loss=0.50179  val_loss=0.60362 | train_MAE=0.7556  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 183 | train_loss=0.48697  val_loss=0.62043 | train_MAE=0.7668  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 184 | train_loss=0.50242  val_loss=0.62861 | train_MAE=0.7444  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 185 | train_loss=0.51728  val_loss=0.60516 | train_MAE=0.7388  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 186 | train_loss=0.49309  val_loss=0.61383 | train_MAE=0.7575  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 187 | train_loss=0.50881  val_loss=0.63896 | train_MAE=0.7519  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 188 | train_loss=0.49889  val_loss=0.61361 | train_MAE=0.7425  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 189 | train_loss=0.49666  val_loss=0.59627 | train_MAE=0.7369  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 190 | train_loss=0.49230  val_loss=0.61573 | train_MAE=0.7612  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 191 | train_loss=0.49846  val_loss=0.60437 | train_MAE=0.7612  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 192 | train_loss=0.49495  val_loss=0.61982 | train_MAE=0.7407  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 193 | train_loss=0.49445  val_loss=0.60757 | train_MAE=0.7351  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 194 | train_loss=0.50462  val_loss=0.60821 | train_MAE=0.7519  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 195 | train_loss=0.49703  val_loss=0.61489 | train_MAE=0.7444  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 196 | train_loss=0.49852  val_loss=0.62610 | train_MAE=0.7425  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 197 | train_loss=0.48015  val_loss=0.63170 | train_MAE=0.7668  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 198 | train_loss=0.50286  val_loss=0.62338 | train_MAE=0.7481  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 199 | train_loss=0.50271  val_loss=0.61554 | train_MAE=0.7556  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 200 | train_loss=0.49495  val_loss=0.63227 | train_MAE=0.7463  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Total training time: 16.79s\n",
      "Test Accuracy: 0.6174\n",
      "\n",
      "Training with dropout=0.2\n",
      "Epoch 001 | train_loss=1.12758  val_loss=0.71755 | train_MAE=0.5541  val_MAE=0.6000 | lr=0.001 | time=0.08s\n",
      "Epoch 002 | train_loss=0.92065  val_loss=0.66445 | train_MAE=0.5448  val_MAE=0.5913 | lr=0.001 | time=0.08s\n",
      "Epoch 003 | train_loss=0.83799  val_loss=0.64373 | train_MAE=0.5243  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 004 | train_loss=0.75056  val_loss=0.64139 | train_MAE=0.5989  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 005 | train_loss=0.72804  val_loss=0.65438 | train_MAE=0.6119  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 006 | train_loss=0.73181  val_loss=0.63918 | train_MAE=0.5970  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 007 | train_loss=0.68371  val_loss=0.63289 | train_MAE=0.5989  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 008 | train_loss=0.68155  val_loss=0.61891 | train_MAE=0.6381  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 009 | train_loss=0.67176  val_loss=0.60427 | train_MAE=0.6325  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 010 | train_loss=0.67355  val_loss=0.60269 | train_MAE=0.6119  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 011 | train_loss=0.67350  val_loss=0.60848 | train_MAE=0.6231  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 012 | train_loss=0.66915  val_loss=0.60673 | train_MAE=0.6250  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 013 | train_loss=0.66232  val_loss=0.60945 | train_MAE=0.6549  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 014 | train_loss=0.65755  val_loss=0.61573 | train_MAE=0.6381  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 015 | train_loss=0.65526  val_loss=0.61210 | train_MAE=0.6343  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 016 | train_loss=0.63887  val_loss=0.60295 | train_MAE=0.6623  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 017 | train_loss=0.63806  val_loss=0.59201 | train_MAE=0.6549  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 018 | train_loss=0.62942  val_loss=0.59126 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 019 | train_loss=0.63264  val_loss=0.59241 | train_MAE=0.6511  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 020 | train_loss=0.63679  val_loss=0.58456 | train_MAE=0.6586  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 021 | train_loss=0.61262  val_loss=0.58097 | train_MAE=0.6530  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 022 | train_loss=0.63247  val_loss=0.58852 | train_MAE=0.6847  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 023 | train_loss=0.64282  val_loss=0.59485 | train_MAE=0.6586  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 024 | train_loss=0.61854  val_loss=0.59312 | train_MAE=0.6623  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 025 | train_loss=0.62521  val_loss=0.58719 | train_MAE=0.6623  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 026 | train_loss=0.62109  val_loss=0.58363 | train_MAE=0.6511  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 027 | train_loss=0.62684  val_loss=0.58045 | train_MAE=0.6642  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 028 | train_loss=0.59865  val_loss=0.57899 | train_MAE=0.7015  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 029 | train_loss=0.61565  val_loss=0.58572 | train_MAE=0.6642  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 030 | train_loss=0.61110  val_loss=0.58642 | train_MAE=0.6604  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 031 | train_loss=0.60510  val_loss=0.58763 | train_MAE=0.6660  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 032 | train_loss=0.60359  val_loss=0.58779 | train_MAE=0.6716  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 033 | train_loss=0.59736  val_loss=0.58617 | train_MAE=0.6772  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 034 | train_loss=0.61024  val_loss=0.58484 | train_MAE=0.6810  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 035 | train_loss=0.59465  val_loss=0.58285 | train_MAE=0.7034  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 036 | train_loss=0.58410  val_loss=0.58188 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 037 | train_loss=0.60382  val_loss=0.57858 | train_MAE=0.6586  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 038 | train_loss=0.59174  val_loss=0.57979 | train_MAE=0.6810  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 039 | train_loss=0.59816  val_loss=0.58095 | train_MAE=0.6660  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 040 | train_loss=0.60119  val_loss=0.58537 | train_MAE=0.6604  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 041 | train_loss=0.60351  val_loss=0.58328 | train_MAE=0.6623  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 042 | train_loss=0.59945  val_loss=0.58387 | train_MAE=0.6772  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 043 | train_loss=0.59514  val_loss=0.58489 | train_MAE=0.6884  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 044 | train_loss=0.58836  val_loss=0.58450 | train_MAE=0.6735  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 045 | train_loss=0.59153  val_loss=0.58113 | train_MAE=0.6679  val_MAE=0.7304 | lr=0.001 | time=0.16s\n",
      "Epoch 046 | train_loss=0.60547  val_loss=0.58264 | train_MAE=0.6660  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 047 | train_loss=0.58363  val_loss=0.58063 | train_MAE=0.6959  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 048 | train_loss=0.59908  val_loss=0.58334 | train_MAE=0.6828  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 049 | train_loss=0.58573  val_loss=0.58473 | train_MAE=0.6847  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 050 | train_loss=0.57356  val_loss=0.58509 | train_MAE=0.6847  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 051 | train_loss=0.57743  val_loss=0.58947 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 052 | train_loss=0.58581  val_loss=0.58586 | train_MAE=0.6866  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 053 | train_loss=0.58724  val_loss=0.58418 | train_MAE=0.6623  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 054 | train_loss=0.59228  val_loss=0.58535 | train_MAE=0.6754  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 055 | train_loss=0.58617  val_loss=0.58277 | train_MAE=0.6772  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 056 | train_loss=0.57647  val_loss=0.58168 | train_MAE=0.6884  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 057 | train_loss=0.56693  val_loss=0.58205 | train_MAE=0.7090  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 058 | train_loss=0.58482  val_loss=0.58836 | train_MAE=0.6866  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 059 | train_loss=0.60350  val_loss=0.58023 | train_MAE=0.6884  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 060 | train_loss=0.57286  val_loss=0.58133 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 061 | train_loss=0.57246  val_loss=0.58732 | train_MAE=0.7071  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 062 | train_loss=0.57204  val_loss=0.58998 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 063 | train_loss=0.57331  val_loss=0.58878 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 064 | train_loss=0.58017  val_loss=0.58595 | train_MAE=0.6866  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 065 | train_loss=0.56074  val_loss=0.58820 | train_MAE=0.7276  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 066 | train_loss=0.56102  val_loss=0.59050 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 067 | train_loss=0.56651  val_loss=0.58607 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 068 | train_loss=0.57412  val_loss=0.58588 | train_MAE=0.6884  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 069 | train_loss=0.58036  val_loss=0.58386 | train_MAE=0.6940  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 070 | train_loss=0.56962  val_loss=0.58574 | train_MAE=0.6996  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 071 | train_loss=0.57410  val_loss=0.59005 | train_MAE=0.7015  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 072 | train_loss=0.56863  val_loss=0.59029 | train_MAE=0.7108  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 073 | train_loss=0.57382  val_loss=0.58619 | train_MAE=0.6959  val_MAE=0.7565 | lr=0.001 | time=0.09s\n",
      "Epoch 074 | train_loss=0.56077  val_loss=0.58289 | train_MAE=0.7090  val_MAE=0.7478 | lr=0.001 | time=0.09s\n",
      "Epoch 075 | train_loss=0.57719  val_loss=0.58102 | train_MAE=0.6884  val_MAE=0.7391 | lr=0.001 | time=0.09s\n",
      "Epoch 076 | train_loss=0.56250  val_loss=0.58129 | train_MAE=0.7015  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 077 | train_loss=0.57694  val_loss=0.57923 | train_MAE=0.6828  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 078 | train_loss=0.58371  val_loss=0.58204 | train_MAE=0.6623  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 079 | train_loss=0.56481  val_loss=0.58570 | train_MAE=0.6996  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 080 | train_loss=0.57814  val_loss=0.58416 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 081 | train_loss=0.57114  val_loss=0.58070 | train_MAE=0.6996  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 082 | train_loss=0.55873  val_loss=0.58447 | train_MAE=0.7127  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 083 | train_loss=0.57288  val_loss=0.58511 | train_MAE=0.6828  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 084 | train_loss=0.56721  val_loss=0.58422 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.001 | time=0.09s\n",
      "Epoch 085 | train_loss=0.57240  val_loss=0.58457 | train_MAE=0.6828  val_MAE=0.7304 | lr=0.001 | time=0.09s\n",
      "Epoch 086 | train_loss=0.56454  val_loss=0.58164 | train_MAE=0.6903  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 087 | train_loss=0.56523  val_loss=0.58184 | train_MAE=0.7127  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 088 | train_loss=0.57093  val_loss=0.58375 | train_MAE=0.7090  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 089 | train_loss=0.55793  val_loss=0.59294 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 090 | train_loss=0.55597  val_loss=0.59311 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 091 | train_loss=0.57546  val_loss=0.58765 | train_MAE=0.6828  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 092 | train_loss=0.56163  val_loss=0.58502 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 093 | train_loss=0.56511  val_loss=0.58772 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 094 | train_loss=0.56753  val_loss=0.58651 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 095 | train_loss=0.54222  val_loss=0.58725 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 096 | train_loss=0.55552  val_loss=0.59003 | train_MAE=0.7071  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 097 | train_loss=0.56059  val_loss=0.59052 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 098 | train_loss=0.55712  val_loss=0.58875 | train_MAE=0.6903  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 099 | train_loss=0.56224  val_loss=0.58661 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 100 | train_loss=0.55335  val_loss=0.58415 | train_MAE=0.7463  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 101 | train_loss=0.55805  val_loss=0.58817 | train_MAE=0.6959  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 102 | train_loss=0.55897  val_loss=0.58763 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 103 | train_loss=0.56098  val_loss=0.58398 | train_MAE=0.7183  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 104 | train_loss=0.57502  val_loss=0.58514 | train_MAE=0.7052  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 105 | train_loss=0.56610  val_loss=0.57826 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 106 | train_loss=0.55769  val_loss=0.58210 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 107 | train_loss=0.55597  val_loss=0.58756 | train_MAE=0.7108  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 108 | train_loss=0.56162  val_loss=0.58694 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 109 | train_loss=0.55273  val_loss=0.58613 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 110 | train_loss=0.54789  val_loss=0.59122 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 111 | train_loss=0.56524  val_loss=0.59094 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 112 | train_loss=0.55077  val_loss=0.58304 | train_MAE=0.7201  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 113 | train_loss=0.56279  val_loss=0.58085 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 114 | train_loss=0.55031  val_loss=0.58896 | train_MAE=0.7146  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 115 | train_loss=0.54623  val_loss=0.58207 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 116 | train_loss=0.54102  val_loss=0.57572 | train_MAE=0.7239  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 117 | train_loss=0.56754  val_loss=0.57381 | train_MAE=0.6828  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 118 | train_loss=0.55754  val_loss=0.57572 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 119 | train_loss=0.55222  val_loss=0.57667 | train_MAE=0.7239  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 120 | train_loss=0.53724  val_loss=0.57616 | train_MAE=0.7369  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 121 | train_loss=0.55738  val_loss=0.58254 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 122 | train_loss=0.54316  val_loss=0.57493 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 123 | train_loss=0.54289  val_loss=0.57484 | train_MAE=0.7407  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 124 | train_loss=0.54562  val_loss=0.57378 | train_MAE=0.7052  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 125 | train_loss=0.54663  val_loss=0.57862 | train_MAE=0.7295  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 126 | train_loss=0.54834  val_loss=0.57379 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 127 | train_loss=0.55258  val_loss=0.57204 | train_MAE=0.7108  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 128 | train_loss=0.55804  val_loss=0.57407 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 129 | train_loss=0.55681  val_loss=0.57528 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 130 | train_loss=0.54755  val_loss=0.57345 | train_MAE=0.7146  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 131 | train_loss=0.55339  val_loss=0.57806 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 132 | train_loss=0.54741  val_loss=0.57786 | train_MAE=0.7127  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 133 | train_loss=0.53009  val_loss=0.58137 | train_MAE=0.7295  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 134 | train_loss=0.55025  val_loss=0.58161 | train_MAE=0.7220  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 135 | train_loss=0.54631  val_loss=0.58122 | train_MAE=0.7425  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 136 | train_loss=0.54993  val_loss=0.57722 | train_MAE=0.7164  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 137 | train_loss=0.54279  val_loss=0.57696 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 138 | train_loss=0.54456  val_loss=0.57661 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 139 | train_loss=0.54126  val_loss=0.57892 | train_MAE=0.7425  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 140 | train_loss=0.53575  val_loss=0.58704 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 141 | train_loss=0.52326  val_loss=0.58115 | train_MAE=0.7201  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 142 | train_loss=0.54332  val_loss=0.58633 | train_MAE=0.7220  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 143 | train_loss=0.55144  val_loss=0.58252 | train_MAE=0.7295  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 144 | train_loss=0.54072  val_loss=0.58441 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 145 | train_loss=0.54499  val_loss=0.58392 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 146 | train_loss=0.53532  val_loss=0.58735 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 147 | train_loss=0.53705  val_loss=0.58890 | train_MAE=0.7388  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 148 | train_loss=0.54728  val_loss=0.58464 | train_MAE=0.7108  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 149 | train_loss=0.54446  val_loss=0.58660 | train_MAE=0.7276  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 150 | train_loss=0.54149  val_loss=0.58290 | train_MAE=0.7313  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 151 | train_loss=0.53849  val_loss=0.58018 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 152 | train_loss=0.53626  val_loss=0.57911 | train_MAE=0.7276  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 153 | train_loss=0.53830  val_loss=0.58089 | train_MAE=0.7313  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 154 | train_loss=0.52361  val_loss=0.58475 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 155 | train_loss=0.54485  val_loss=0.58675 | train_MAE=0.7071  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 156 | train_loss=0.52435  val_loss=0.58959 | train_MAE=0.7295  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 157 | train_loss=0.54190  val_loss=0.58985 | train_MAE=0.7034  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 158 | train_loss=0.53554  val_loss=0.58258 | train_MAE=0.7276  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 159 | train_loss=0.54325  val_loss=0.58349 | train_MAE=0.7183  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 160 | train_loss=0.53650  val_loss=0.58472 | train_MAE=0.7351  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 161 | train_loss=0.53419  val_loss=0.57739 | train_MAE=0.7295  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 162 | train_loss=0.52540  val_loss=0.57746 | train_MAE=0.7388  val_MAE=0.7217 | lr=0.001 | time=0.09s\n",
      "Epoch 163 | train_loss=0.54103  val_loss=0.57484 | train_MAE=0.7351  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 164 | train_loss=0.52094  val_loss=0.57590 | train_MAE=0.7407  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 165 | train_loss=0.52993  val_loss=0.57715 | train_MAE=0.7183  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 166 | train_loss=0.53040  val_loss=0.58293 | train_MAE=0.7164  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 167 | train_loss=0.53308  val_loss=0.58840 | train_MAE=0.7052  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 168 | train_loss=0.54257  val_loss=0.58160 | train_MAE=0.7257  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 169 | train_loss=0.53439  val_loss=0.57764 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 170 | train_loss=0.54072  val_loss=0.58582 | train_MAE=0.7332  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 171 | train_loss=0.54602  val_loss=0.57009 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 172 | train_loss=0.53683  val_loss=0.58055 | train_MAE=0.7183  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 173 | train_loss=0.52771  val_loss=0.57894 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 174 | train_loss=0.52531  val_loss=0.58002 | train_MAE=0.7444  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 175 | train_loss=0.54040  val_loss=0.57931 | train_MAE=0.7127  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 176 | train_loss=0.53465  val_loss=0.58622 | train_MAE=0.7444  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 177 | train_loss=0.52758  val_loss=0.58529 | train_MAE=0.7388  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 178 | train_loss=0.53331  val_loss=0.59127 | train_MAE=0.7239  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 179 | train_loss=0.52265  val_loss=0.59136 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 180 | train_loss=0.52682  val_loss=0.58699 | train_MAE=0.7295  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 181 | train_loss=0.54754  val_loss=0.58617 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 182 | train_loss=0.53079  val_loss=0.58799 | train_MAE=0.7332  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 183 | train_loss=0.52824  val_loss=0.57998 | train_MAE=0.7295  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 184 | train_loss=0.52685  val_loss=0.57486 | train_MAE=0.7351  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 185 | train_loss=0.52174  val_loss=0.58694 | train_MAE=0.7351  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 186 | train_loss=0.52609  val_loss=0.59196 | train_MAE=0.7351  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 187 | train_loss=0.52593  val_loss=0.59001 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 188 | train_loss=0.50481  val_loss=0.58847 | train_MAE=0.7407  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 189 | train_loss=0.52168  val_loss=0.59550 | train_MAE=0.7407  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 190 | train_loss=0.52622  val_loss=0.59385 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 191 | train_loss=0.53808  val_loss=0.57747 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 192 | train_loss=0.52392  val_loss=0.58325 | train_MAE=0.7276  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 193 | train_loss=0.51950  val_loss=0.58259 | train_MAE=0.7425  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 194 | train_loss=0.52110  val_loss=0.58675 | train_MAE=0.7388  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 195 | train_loss=0.52814  val_loss=0.58580 | train_MAE=0.7127  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 196 | train_loss=0.52296  val_loss=0.57723 | train_MAE=0.7257  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 197 | train_loss=0.53579  val_loss=0.57775 | train_MAE=0.7388  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 198 | train_loss=0.51996  val_loss=0.57177 | train_MAE=0.7201  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 199 | train_loss=0.51871  val_loss=0.58200 | train_MAE=0.7369  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 200 | train_loss=0.50538  val_loss=0.58125 | train_MAE=0.7444  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Total training time: 16.31s\n",
      "Test Accuracy: 0.6435\n",
      "\n",
      "Training with dropout=0.3\n",
      "Epoch 001 | train_loss=1.41819  val_loss=0.75998 | train_MAE=0.5075  val_MAE=0.6522 | lr=0.001 | time=0.09s\n",
      "Epoch 002 | train_loss=1.01848  val_loss=0.68969 | train_MAE=0.5690  val_MAE=0.5130 | lr=0.001 | time=0.08s\n",
      "Epoch 003 | train_loss=0.89007  val_loss=0.67684 | train_MAE=0.5392  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 004 | train_loss=0.87299  val_loss=0.67194 | train_MAE=0.5448  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 005 | train_loss=0.84437  val_loss=0.68178 | train_MAE=0.5784  val_MAE=0.6174 | lr=0.001 | time=0.08s\n",
      "Epoch 006 | train_loss=0.73846  val_loss=0.67918 | train_MAE=0.5933  val_MAE=0.5739 | lr=0.001 | time=0.08s\n",
      "Epoch 007 | train_loss=0.70576  val_loss=0.67151 | train_MAE=0.6213  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 008 | train_loss=0.74930  val_loss=0.65776 | train_MAE=0.5746  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 009 | train_loss=0.72845  val_loss=0.64747 | train_MAE=0.6231  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 010 | train_loss=0.69222  val_loss=0.64970 | train_MAE=0.6157  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 011 | train_loss=0.72043  val_loss=0.64912 | train_MAE=0.5877  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 012 | train_loss=0.66602  val_loss=0.65158 | train_MAE=0.6455  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 013 | train_loss=0.70354  val_loss=0.64563 | train_MAE=0.6007  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 014 | train_loss=0.68619  val_loss=0.63986 | train_MAE=0.6119  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 015 | train_loss=0.67818  val_loss=0.63461 | train_MAE=0.6325  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 016 | train_loss=0.67055  val_loss=0.63381 | train_MAE=0.6175  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 017 | train_loss=0.69722  val_loss=0.62881 | train_MAE=0.6269  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 018 | train_loss=0.65968  val_loss=0.63228 | train_MAE=0.6399  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 019 | train_loss=0.66453  val_loss=0.62830 | train_MAE=0.6623  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 020 | train_loss=0.65486  val_loss=0.63029 | train_MAE=0.6362  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 021 | train_loss=0.65627  val_loss=0.62007 | train_MAE=0.6437  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 022 | train_loss=0.66453  val_loss=0.61671 | train_MAE=0.6231  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 023 | train_loss=0.65488  val_loss=0.61742 | train_MAE=0.6362  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 024 | train_loss=0.63717  val_loss=0.61680 | train_MAE=0.6250  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 025 | train_loss=0.64488  val_loss=0.61065 | train_MAE=0.6325  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 026 | train_loss=0.67059  val_loss=0.61668 | train_MAE=0.6474  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 027 | train_loss=0.64668  val_loss=0.62303 | train_MAE=0.6381  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 028 | train_loss=0.64853  val_loss=0.61594 | train_MAE=0.6287  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 029 | train_loss=0.63900  val_loss=0.61079 | train_MAE=0.6325  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 030 | train_loss=0.65128  val_loss=0.60383 | train_MAE=0.6586  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 031 | train_loss=0.64178  val_loss=0.60892 | train_MAE=0.6493  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 032 | train_loss=0.63544  val_loss=0.60923 | train_MAE=0.6437  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 033 | train_loss=0.63531  val_loss=0.60440 | train_MAE=0.6660  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 034 | train_loss=0.62875  val_loss=0.60202 | train_MAE=0.6698  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 035 | train_loss=0.62924  val_loss=0.59760 | train_MAE=0.6660  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 036 | train_loss=0.63557  val_loss=0.59899 | train_MAE=0.6437  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 037 | train_loss=0.63899  val_loss=0.59421 | train_MAE=0.6399  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 038 | train_loss=0.61916  val_loss=0.59620 | train_MAE=0.6772  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 039 | train_loss=0.62560  val_loss=0.59794 | train_MAE=0.6604  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 040 | train_loss=0.62544  val_loss=0.59634 | train_MAE=0.6642  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 041 | train_loss=0.61664  val_loss=0.59349 | train_MAE=0.6679  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 042 | train_loss=0.61162  val_loss=0.58855 | train_MAE=0.6455  val_MAE=0.7304 | lr=0.001 | time=0.07s\n",
      "Epoch 043 | train_loss=0.60581  val_loss=0.58619 | train_MAE=0.6903  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 044 | train_loss=0.61860  val_loss=0.58744 | train_MAE=0.6511  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 045 | train_loss=0.61964  val_loss=0.58630 | train_MAE=0.6679  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 046 | train_loss=0.62011  val_loss=0.58685 | train_MAE=0.6530  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 047 | train_loss=0.60412  val_loss=0.58400 | train_MAE=0.6698  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 048 | train_loss=0.61525  val_loss=0.58618 | train_MAE=0.6903  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 049 | train_loss=0.59859  val_loss=0.58524 | train_MAE=0.6866  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 050 | train_loss=0.62861  val_loss=0.59050 | train_MAE=0.6474  val_MAE=0.6957 | lr=0.001 | time=0.13s\n",
      "Epoch 051 | train_loss=0.60987  val_loss=0.59251 | train_MAE=0.6530  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 052 | train_loss=0.59753  val_loss=0.58860 | train_MAE=0.6754  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 053 | train_loss=0.62353  val_loss=0.58862 | train_MAE=0.6530  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 054 | train_loss=0.62015  val_loss=0.59229 | train_MAE=0.6604  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 055 | train_loss=0.60846  val_loss=0.58853 | train_MAE=0.6567  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 056 | train_loss=0.61342  val_loss=0.58616 | train_MAE=0.6549  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 057 | train_loss=0.62840  val_loss=0.58747 | train_MAE=0.6716  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 058 | train_loss=0.60508  val_loss=0.59003 | train_MAE=0.6623  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 059 | train_loss=0.61984  val_loss=0.59022 | train_MAE=0.6530  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 060 | train_loss=0.61514  val_loss=0.59031 | train_MAE=0.6679  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 061 | train_loss=0.61943  val_loss=0.59127 | train_MAE=0.6493  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 062 | train_loss=0.61556  val_loss=0.58985 | train_MAE=0.6735  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 063 | train_loss=0.58585  val_loss=0.58523 | train_MAE=0.6698  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 064 | train_loss=0.61239  val_loss=0.58493 | train_MAE=0.6903  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 065 | train_loss=0.59958  val_loss=0.58783 | train_MAE=0.6698  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 066 | train_loss=0.62991  val_loss=0.58711 | train_MAE=0.6604  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 067 | train_loss=0.60521  val_loss=0.58631 | train_MAE=0.6642  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 068 | train_loss=0.60437  val_loss=0.58328 | train_MAE=0.6716  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 069 | train_loss=0.59282  val_loss=0.58176 | train_MAE=0.6567  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 070 | train_loss=0.59285  val_loss=0.58254 | train_MAE=0.6828  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 071 | train_loss=0.58905  val_loss=0.58188 | train_MAE=0.6847  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 072 | train_loss=0.60758  val_loss=0.58191 | train_MAE=0.6791  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 073 | train_loss=0.61241  val_loss=0.57951 | train_MAE=0.6604  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 074 | train_loss=0.59671  val_loss=0.58189 | train_MAE=0.6903  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 075 | train_loss=0.59814  val_loss=0.58442 | train_MAE=0.6772  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 076 | train_loss=0.59648  val_loss=0.58601 | train_MAE=0.6791  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 077 | train_loss=0.58465  val_loss=0.58371 | train_MAE=0.6754  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 078 | train_loss=0.59176  val_loss=0.58321 | train_MAE=0.6698  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 079 | train_loss=0.58009  val_loss=0.58130 | train_MAE=0.6847  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 080 | train_loss=0.58068  val_loss=0.58251 | train_MAE=0.6922  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 081 | train_loss=0.58487  val_loss=0.58040 | train_MAE=0.6828  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 082 | train_loss=0.59528  val_loss=0.58377 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 083 | train_loss=0.60290  val_loss=0.58436 | train_MAE=0.6623  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 084 | train_loss=0.57685  val_loss=0.58435 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 085 | train_loss=0.60185  val_loss=0.58434 | train_MAE=0.6810  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 086 | train_loss=0.60079  val_loss=0.58449 | train_MAE=0.6660  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 087 | train_loss=0.57091  val_loss=0.58373 | train_MAE=0.6978  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 088 | train_loss=0.58952  val_loss=0.58276 | train_MAE=0.6791  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 089 | train_loss=0.58529  val_loss=0.57818 | train_MAE=0.6884  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 090 | train_loss=0.59429  val_loss=0.57943 | train_MAE=0.6772  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 091 | train_loss=0.59106  val_loss=0.58393 | train_MAE=0.6959  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 092 | train_loss=0.59894  val_loss=0.58220 | train_MAE=0.6735  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 093 | train_loss=0.60288  val_loss=0.58062 | train_MAE=0.6847  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 094 | train_loss=0.57550  val_loss=0.57805 | train_MAE=0.7071  val_MAE=0.7652 | lr=0.001 | time=0.08s\n",
      "Epoch 095 | train_loss=0.58498  val_loss=0.57998 | train_MAE=0.6810  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 096 | train_loss=0.56129  val_loss=0.58248 | train_MAE=0.6866  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 097 | train_loss=0.58319  val_loss=0.58499 | train_MAE=0.7071  val_MAE=0.7652 | lr=0.001 | time=0.08s\n",
      "Epoch 098 | train_loss=0.59093  val_loss=0.57887 | train_MAE=0.6922  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 099 | train_loss=0.59001  val_loss=0.57927 | train_MAE=0.6810  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 100 | train_loss=0.58470  val_loss=0.58377 | train_MAE=0.6754  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 101 | train_loss=0.56400  val_loss=0.58249 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 102 | train_loss=0.59399  val_loss=0.58117 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 103 | train_loss=0.57433  val_loss=0.57914 | train_MAE=0.7015  val_MAE=0.7217 | lr=0.001 | time=0.09s\n",
      "Epoch 104 | train_loss=0.56660  val_loss=0.57589 | train_MAE=0.6978  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 105 | train_loss=0.59036  val_loss=0.57745 | train_MAE=0.6716  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 106 | train_loss=0.56964  val_loss=0.58319 | train_MAE=0.7052  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 107 | train_loss=0.57628  val_loss=0.58396 | train_MAE=0.6959  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 108 | train_loss=0.58413  val_loss=0.58223 | train_MAE=0.6754  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 109 | train_loss=0.58075  val_loss=0.58261 | train_MAE=0.6791  val_MAE=0.7652 | lr=0.001 | time=0.08s\n",
      "Epoch 110 | train_loss=0.57573  val_loss=0.58169 | train_MAE=0.7071  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 111 | train_loss=0.57871  val_loss=0.58030 | train_MAE=0.6772  val_MAE=0.7652 | lr=0.001 | time=0.08s\n",
      "Epoch 112 | train_loss=0.58941  val_loss=0.58247 | train_MAE=0.6791  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 113 | train_loss=0.56367  val_loss=0.58225 | train_MAE=0.6940  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 114 | train_loss=0.58050  val_loss=0.58196 | train_MAE=0.6940  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 115 | train_loss=0.57271  val_loss=0.58417 | train_MAE=0.6978  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 116 | train_loss=0.58347  val_loss=0.58053 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 117 | train_loss=0.57962  val_loss=0.57980 | train_MAE=0.6903  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 118 | train_loss=0.57826  val_loss=0.58013 | train_MAE=0.6903  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 119 | train_loss=0.57199  val_loss=0.58275 | train_MAE=0.7071  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 120 | train_loss=0.57244  val_loss=0.57694 | train_MAE=0.6884  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 121 | train_loss=0.55141  val_loss=0.58038 | train_MAE=0.7201  val_MAE=0.7652 | lr=0.001 | time=0.08s\n",
      "Epoch 122 | train_loss=0.56086  val_loss=0.58790 | train_MAE=0.7015  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 123 | train_loss=0.56700  val_loss=0.58267 | train_MAE=0.6940  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 124 | train_loss=0.55669  val_loss=0.58241 | train_MAE=0.7257  val_MAE=0.7739 | lr=0.001 | time=0.08s\n",
      "Epoch 125 | train_loss=0.57551  val_loss=0.58074 | train_MAE=0.6978  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 126 | train_loss=0.57306  val_loss=0.58125 | train_MAE=0.7015  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 127 | train_loss=0.57682  val_loss=0.58319 | train_MAE=0.6922  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 128 | train_loss=0.55889  val_loss=0.58199 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 129 | train_loss=0.57720  val_loss=0.58309 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 130 | train_loss=0.56214  val_loss=0.58641 | train_MAE=0.6978  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 131 | train_loss=0.56918  val_loss=0.58485 | train_MAE=0.7034  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 132 | train_loss=0.54923  val_loss=0.58836 | train_MAE=0.7146  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 133 | train_loss=0.56890  val_loss=0.59059 | train_MAE=0.7052  val_MAE=0.7652 | lr=0.001 | time=0.08s\n",
      "Epoch 134 | train_loss=0.57831  val_loss=0.58436 | train_MAE=0.7127  val_MAE=0.7652 | lr=0.001 | time=0.08s\n",
      "Epoch 135 | train_loss=0.56226  val_loss=0.58074 | train_MAE=0.7108  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 136 | train_loss=0.56258  val_loss=0.58375 | train_MAE=0.7108  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 137 | train_loss=0.55596  val_loss=0.58390 | train_MAE=0.7369  val_MAE=0.7565 | lr=0.001 | time=0.07s\n",
      "Epoch 138 | train_loss=0.57542  val_loss=0.58339 | train_MAE=0.6940  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 139 | train_loss=0.56303  val_loss=0.58681 | train_MAE=0.6884  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 140 | train_loss=0.57433  val_loss=0.58273 | train_MAE=0.6996  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 141 | train_loss=0.57356  val_loss=0.57864 | train_MAE=0.7015  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 142 | train_loss=0.56412  val_loss=0.57993 | train_MAE=0.7090  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 143 | train_loss=0.56231  val_loss=0.58820 | train_MAE=0.6884  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 144 | train_loss=0.56870  val_loss=0.58886 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 145 | train_loss=0.57051  val_loss=0.57876 | train_MAE=0.7015  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 146 | train_loss=0.56531  val_loss=0.57827 | train_MAE=0.6996  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 147 | train_loss=0.56559  val_loss=0.58195 | train_MAE=0.6903  val_MAE=0.7652 | lr=0.001 | time=0.08s\n",
      "Epoch 148 | train_loss=0.56402  val_loss=0.57738 | train_MAE=0.6866  val_MAE=0.7652 | lr=0.001 | time=0.08s\n",
      "Epoch 149 | train_loss=0.56590  val_loss=0.58205 | train_MAE=0.7146  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 150 | train_loss=0.56236  val_loss=0.57957 | train_MAE=0.7090  val_MAE=0.7652 | lr=0.001 | time=0.08s\n",
      "Epoch 151 | train_loss=0.55780  val_loss=0.58731 | train_MAE=0.7052  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 152 | train_loss=0.55157  val_loss=0.59613 | train_MAE=0.7127  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 153 | train_loss=0.56582  val_loss=0.58782 | train_MAE=0.7108  val_MAE=0.7652 | lr=0.001 | time=0.08s\n",
      "Epoch 154 | train_loss=0.55472  val_loss=0.57723 | train_MAE=0.6922  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 155 | train_loss=0.54103  val_loss=0.58406 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 156 | train_loss=0.53273  val_loss=0.59307 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 157 | train_loss=0.56944  val_loss=0.58718 | train_MAE=0.6996  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 158 | train_loss=0.54108  val_loss=0.58174 | train_MAE=0.7351  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 159 | train_loss=0.55215  val_loss=0.58543 | train_MAE=0.7239  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 160 | train_loss=0.55595  val_loss=0.58837 | train_MAE=0.7257  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 161 | train_loss=0.56799  val_loss=0.58440 | train_MAE=0.7034  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 162 | train_loss=0.55544  val_loss=0.58607 | train_MAE=0.6959  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 163 | train_loss=0.56098  val_loss=0.58867 | train_MAE=0.6996  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 164 | train_loss=0.55099  val_loss=0.58742 | train_MAE=0.6978  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 165 | train_loss=0.55541  val_loss=0.58348 | train_MAE=0.7164  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 166 | train_loss=0.55693  val_loss=0.58559 | train_MAE=0.6847  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 167 | train_loss=0.56026  val_loss=0.58189 | train_MAE=0.6940  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 168 | train_loss=0.55636  val_loss=0.57774 | train_MAE=0.6959  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 169 | train_loss=0.56316  val_loss=0.58020 | train_MAE=0.7015  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 170 | train_loss=0.56437  val_loss=0.58446 | train_MAE=0.6959  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 171 | train_loss=0.54850  val_loss=0.58065 | train_MAE=0.7351  val_MAE=0.7565 | lr=0.001 | time=0.08s\n",
      "Epoch 172 | train_loss=0.55157  val_loss=0.57464 | train_MAE=0.6884  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 173 | train_loss=0.55085  val_loss=0.57800 | train_MAE=0.7239  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 174 | train_loss=0.54862  val_loss=0.57928 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 175 | train_loss=0.54997  val_loss=0.57870 | train_MAE=0.7146  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 176 | train_loss=0.55208  val_loss=0.57574 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 177 | train_loss=0.54717  val_loss=0.58156 | train_MAE=0.7164  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 178 | train_loss=0.55435  val_loss=0.58129 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 179 | train_loss=0.54279  val_loss=0.58664 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 180 | train_loss=0.55251  val_loss=0.59706 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 181 | train_loss=0.54613  val_loss=0.58840 | train_MAE=0.6940  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 182 | train_loss=0.57384  val_loss=0.58955 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 183 | train_loss=0.54560  val_loss=0.58592 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 184 | train_loss=0.57072  val_loss=0.58429 | train_MAE=0.7015  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 185 | train_loss=0.54931  val_loss=0.59026 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 186 | train_loss=0.54114  val_loss=0.58231 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 187 | train_loss=0.53790  val_loss=0.58709 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 188 | train_loss=0.54697  val_loss=0.58293 | train_MAE=0.7015  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 189 | train_loss=0.55847  val_loss=0.58487 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 190 | train_loss=0.55630  val_loss=0.59408 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 191 | train_loss=0.54484  val_loss=0.58661 | train_MAE=0.7090  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 192 | train_loss=0.55831  val_loss=0.58354 | train_MAE=0.7052  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 193 | train_loss=0.55710  val_loss=0.58148 | train_MAE=0.7146  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 194 | train_loss=0.54621  val_loss=0.58060 | train_MAE=0.7164  val_MAE=0.7304 | lr=0.001 | time=0.10s\n",
      "Epoch 195 | train_loss=0.53247  val_loss=0.58518 | train_MAE=0.7276  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 196 | train_loss=0.55359  val_loss=0.58508 | train_MAE=0.7295  val_MAE=0.7304 | lr=0.001 | time=0.07s\n",
      "Epoch 197 | train_loss=0.54453  val_loss=0.59572 | train_MAE=0.7146  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 198 | train_loss=0.53430  val_loss=0.59095 | train_MAE=0.7425  val_MAE=0.7478 | lr=0.001 | time=0.08s\n",
      "Epoch 199 | train_loss=0.53609  val_loss=0.57563 | train_MAE=0.7276  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 200 | train_loss=0.54765  val_loss=0.58473 | train_MAE=0.7257  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Total training time: 16.17s\n",
      "Test Accuracy: 0.6261\n",
      "\n",
      "Training with dropout=0.4\n",
      "Epoch 001 | train_loss=2.03639  val_loss=0.68891 | train_MAE=0.4813  val_MAE=0.6435 | lr=0.001 | time=0.09s\n",
      "Epoch 002 | train_loss=1.49375  val_loss=0.66651 | train_MAE=0.5280  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 003 | train_loss=1.16448  val_loss=0.72322 | train_MAE=0.5504  val_MAE=0.4174 | lr=0.001 | time=0.08s\n",
      "Epoch 004 | train_loss=1.01557  val_loss=0.69748 | train_MAE=0.5187  val_MAE=0.5478 | lr=0.001 | time=0.08s\n",
      "Epoch 005 | train_loss=0.96765  val_loss=0.68503 | train_MAE=0.5541  val_MAE=0.6261 | lr=0.001 | time=0.08s\n",
      "Epoch 006 | train_loss=0.80263  val_loss=0.68582 | train_MAE=0.5858  val_MAE=0.6348 | lr=0.001 | time=0.08s\n",
      "Epoch 007 | train_loss=0.85070  val_loss=0.67893 | train_MAE=0.5392  val_MAE=0.6348 | lr=0.001 | time=0.08s\n",
      "Epoch 008 | train_loss=0.78231  val_loss=0.67200 | train_MAE=0.5840  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 009 | train_loss=0.79546  val_loss=0.66874 | train_MAE=0.5560  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 010 | train_loss=0.79798  val_loss=0.66921 | train_MAE=0.5653  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 011 | train_loss=0.73893  val_loss=0.66942 | train_MAE=0.5616  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 012 | train_loss=0.72090  val_loss=0.66278 | train_MAE=0.6045  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 013 | train_loss=0.69861  val_loss=0.65874 | train_MAE=0.6045  val_MAE=0.6435 | lr=0.001 | time=0.08s\n",
      "Epoch 014 | train_loss=0.70339  val_loss=0.65342 | train_MAE=0.6101  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 015 | train_loss=0.68371  val_loss=0.65138 | train_MAE=0.6399  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 016 | train_loss=0.70449  val_loss=0.65057 | train_MAE=0.6045  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 017 | train_loss=0.68838  val_loss=0.64894 | train_MAE=0.5896  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 018 | train_loss=0.68091  val_loss=0.64706 | train_MAE=0.6604  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 019 | train_loss=0.70456  val_loss=0.64656 | train_MAE=0.5989  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 020 | train_loss=0.68828  val_loss=0.64815 | train_MAE=0.6063  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 021 | train_loss=0.67621  val_loss=0.65057 | train_MAE=0.6157  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 022 | train_loss=0.65633  val_loss=0.65226 | train_MAE=0.6343  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 023 | train_loss=0.67192  val_loss=0.65215 | train_MAE=0.6381  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 024 | train_loss=0.66976  val_loss=0.64973 | train_MAE=0.6362  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 025 | train_loss=0.68089  val_loss=0.64661 | train_MAE=0.6175  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 026 | train_loss=0.65383  val_loss=0.64315 | train_MAE=0.6623  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 027 | train_loss=0.67434  val_loss=0.64383 | train_MAE=0.6493  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 028 | train_loss=0.66249  val_loss=0.64410 | train_MAE=0.6586  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 029 | train_loss=0.65095  val_loss=0.64137 | train_MAE=0.6735  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 030 | train_loss=0.66375  val_loss=0.63696 | train_MAE=0.6567  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 031 | train_loss=0.65383  val_loss=0.63416 | train_MAE=0.6455  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 032 | train_loss=0.67954  val_loss=0.63457 | train_MAE=0.6474  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 033 | train_loss=0.64222  val_loss=0.63738 | train_MAE=0.6437  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 034 | train_loss=0.68066  val_loss=0.63938 | train_MAE=0.6567  val_MAE=0.6870 | lr=0.001 | time=0.16s\n",
      "Epoch 035 | train_loss=0.65702  val_loss=0.63900 | train_MAE=0.6325  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 036 | train_loss=0.66543  val_loss=0.63769 | train_MAE=0.6362  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 037 | train_loss=0.64586  val_loss=0.63657 | train_MAE=0.6418  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 038 | train_loss=0.64772  val_loss=0.63540 | train_MAE=0.6474  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 039 | train_loss=0.63341  val_loss=0.63272 | train_MAE=0.6660  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 040 | train_loss=0.63703  val_loss=0.62949 | train_MAE=0.6623  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 041 | train_loss=0.63469  val_loss=0.62827 | train_MAE=0.6660  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 042 | train_loss=0.64968  val_loss=0.62707 | train_MAE=0.6586  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 043 | train_loss=0.62472  val_loss=0.62852 | train_MAE=0.6828  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 044 | train_loss=0.63516  val_loss=0.62621 | train_MAE=0.6567  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 045 | train_loss=0.63247  val_loss=0.62154 | train_MAE=0.6866  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 046 | train_loss=0.64429  val_loss=0.61996 | train_MAE=0.6716  val_MAE=0.6957 | lr=0.001 | time=0.09s\n",
      "Epoch 047 | train_loss=0.62517  val_loss=0.61959 | train_MAE=0.6642  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 048 | train_loss=0.64456  val_loss=0.62059 | train_MAE=0.6511  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 049 | train_loss=0.63633  val_loss=0.61970 | train_MAE=0.6623  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 050 | train_loss=0.62821  val_loss=0.61561 | train_MAE=0.6604  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 051 | train_loss=0.63285  val_loss=0.61180 | train_MAE=0.6567  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 052 | train_loss=0.62743  val_loss=0.60627 | train_MAE=0.6847  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 053 | train_loss=0.63706  val_loss=0.60287 | train_MAE=0.6474  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 054 | train_loss=0.62683  val_loss=0.60349 | train_MAE=0.6642  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 055 | train_loss=0.62468  val_loss=0.60349 | train_MAE=0.6530  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 056 | train_loss=0.62568  val_loss=0.60327 | train_MAE=0.6847  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 057 | train_loss=0.61665  val_loss=0.59958 | train_MAE=0.6679  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 058 | train_loss=0.63112  val_loss=0.59937 | train_MAE=0.6698  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 059 | train_loss=0.61467  val_loss=0.59907 | train_MAE=0.6623  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 060 | train_loss=0.62958  val_loss=0.59898 | train_MAE=0.6679  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 061 | train_loss=0.60736  val_loss=0.59974 | train_MAE=0.6772  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 062 | train_loss=0.62504  val_loss=0.60134 | train_MAE=0.6754  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 063 | train_loss=0.63308  val_loss=0.60118 | train_MAE=0.6493  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 064 | train_loss=0.61584  val_loss=0.60101 | train_MAE=0.6772  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 065 | train_loss=0.61589  val_loss=0.60181 | train_MAE=0.6549  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 066 | train_loss=0.61482  val_loss=0.60173 | train_MAE=0.6735  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 067 | train_loss=0.60312  val_loss=0.60252 | train_MAE=0.6828  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 068 | train_loss=0.61413  val_loss=0.59779 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 069 | train_loss=0.61031  val_loss=0.59639 | train_MAE=0.6679  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 070 | train_loss=0.59142  val_loss=0.59415 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 071 | train_loss=0.61134  val_loss=0.59747 | train_MAE=0.6866  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 072 | train_loss=0.60245  val_loss=0.59510 | train_MAE=0.6884  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 073 | train_loss=0.60620  val_loss=0.59394 | train_MAE=0.6698  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 074 | train_loss=0.60883  val_loss=0.59442 | train_MAE=0.6716  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 075 | train_loss=0.59135  val_loss=0.59396 | train_MAE=0.6884  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 076 | train_loss=0.60402  val_loss=0.59303 | train_MAE=0.6828  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 077 | train_loss=0.61522  val_loss=0.59277 | train_MAE=0.6772  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 078 | train_loss=0.59556  val_loss=0.59053 | train_MAE=0.7071  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 079 | train_loss=0.61160  val_loss=0.59237 | train_MAE=0.6586  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 080 | train_loss=0.60260  val_loss=0.59175 | train_MAE=0.6772  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 081 | train_loss=0.61207  val_loss=0.59241 | train_MAE=0.6735  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 082 | train_loss=0.58027  val_loss=0.59228 | train_MAE=0.6735  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 083 | train_loss=0.60004  val_loss=0.59081 | train_MAE=0.6810  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 084 | train_loss=0.60011  val_loss=0.59104 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 085 | train_loss=0.59197  val_loss=0.59264 | train_MAE=0.6940  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 086 | train_loss=0.61062  val_loss=0.59328 | train_MAE=0.6698  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 087 | train_loss=0.59686  val_loss=0.59369 | train_MAE=0.6922  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 088 | train_loss=0.59726  val_loss=0.59321 | train_MAE=0.6660  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 089 | train_loss=0.57504  val_loss=0.59063 | train_MAE=0.6996  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 090 | train_loss=0.59718  val_loss=0.58632 | train_MAE=0.7034  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 091 | train_loss=0.58762  val_loss=0.58206 | train_MAE=0.6847  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 092 | train_loss=0.60408  val_loss=0.58791 | train_MAE=0.6754  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 093 | train_loss=0.59219  val_loss=0.58699 | train_MAE=0.6922  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 094 | train_loss=0.59195  val_loss=0.58300 | train_MAE=0.7071  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 095 | train_loss=0.58978  val_loss=0.58075 | train_MAE=0.6791  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 096 | train_loss=0.60293  val_loss=0.58358 | train_MAE=0.6698  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 097 | train_loss=0.59937  val_loss=0.58776 | train_MAE=0.6810  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 098 | train_loss=0.57952  val_loss=0.58936 | train_MAE=0.6978  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 099 | train_loss=0.59633  val_loss=0.58764 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 100 | train_loss=0.61140  val_loss=0.58827 | train_MAE=0.6754  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 101 | train_loss=0.58214  val_loss=0.58565 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 102 | train_loss=0.60718  val_loss=0.58314 | train_MAE=0.6716  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 103 | train_loss=0.58900  val_loss=0.58418 | train_MAE=0.6735  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 104 | train_loss=0.59239  val_loss=0.58509 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 105 | train_loss=0.57598  val_loss=0.58822 | train_MAE=0.7127  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 106 | train_loss=0.58153  val_loss=0.58627 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 107 | train_loss=0.60505  val_loss=0.58571 | train_MAE=0.6623  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 108 | train_loss=0.59203  val_loss=0.58231 | train_MAE=0.6903  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 109 | train_loss=0.58419  val_loss=0.58175 | train_MAE=0.6903  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 110 | train_loss=0.56968  val_loss=0.58421 | train_MAE=0.7071  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 111 | train_loss=0.56351  val_loss=0.58383 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 112 | train_loss=0.56001  val_loss=0.59096 | train_MAE=0.6884  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 113 | train_loss=0.56281  val_loss=0.60355 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 114 | train_loss=0.56651  val_loss=0.58459 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 115 | train_loss=0.60221  val_loss=0.58219 | train_MAE=0.6828  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 116 | train_loss=0.58313  val_loss=0.58122 | train_MAE=0.7034  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 117 | train_loss=0.57946  val_loss=0.58121 | train_MAE=0.7108  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 118 | train_loss=0.58678  val_loss=0.58685 | train_MAE=0.6940  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 119 | train_loss=0.56706  val_loss=0.58996 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 120 | train_loss=0.57624  val_loss=0.58687 | train_MAE=0.6884  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 121 | train_loss=0.58085  val_loss=0.57833 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 122 | train_loss=0.57224  val_loss=0.57849 | train_MAE=0.7015  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 123 | train_loss=0.56719  val_loss=0.57979 | train_MAE=0.7146  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 124 | train_loss=0.59467  val_loss=0.57647 | train_MAE=0.7034  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 125 | train_loss=0.58567  val_loss=0.57784 | train_MAE=0.6940  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 126 | train_loss=0.58018  val_loss=0.58184 | train_MAE=0.6959  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 127 | train_loss=0.57306  val_loss=0.58432 | train_MAE=0.7015  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 128 | train_loss=0.58205  val_loss=0.58823 | train_MAE=0.6810  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 129 | train_loss=0.57425  val_loss=0.58640 | train_MAE=0.7164  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 130 | train_loss=0.58079  val_loss=0.58456 | train_MAE=0.6940  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 131 | train_loss=0.55330  val_loss=0.58240 | train_MAE=0.7108  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 132 | train_loss=0.58019  val_loss=0.58827 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 133 | train_loss=0.58270  val_loss=0.58088 | train_MAE=0.7183  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 134 | train_loss=0.58685  val_loss=0.58023 | train_MAE=0.7052  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 135 | train_loss=0.57172  val_loss=0.58530 | train_MAE=0.7146  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 136 | train_loss=0.56934  val_loss=0.59058 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 137 | train_loss=0.57505  val_loss=0.58572 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 138 | train_loss=0.59116  val_loss=0.58367 | train_MAE=0.6716  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 139 | train_loss=0.56010  val_loss=0.58359 | train_MAE=0.6996  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 140 | train_loss=0.56802  val_loss=0.57879 | train_MAE=0.6978  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 141 | train_loss=0.57000  val_loss=0.57921 | train_MAE=0.6959  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 142 | train_loss=0.58929  val_loss=0.57698 | train_MAE=0.6866  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 143 | train_loss=0.57243  val_loss=0.57888 | train_MAE=0.7351  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 144 | train_loss=0.58441  val_loss=0.57956 | train_MAE=0.6828  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 145 | train_loss=0.57239  val_loss=0.58198 | train_MAE=0.7146  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 146 | train_loss=0.56233  val_loss=0.58397 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 147 | train_loss=0.57353  val_loss=0.58261 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 148 | train_loss=0.56632  val_loss=0.57671 | train_MAE=0.6922  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 149 | train_loss=0.57036  val_loss=0.57955 | train_MAE=0.7071  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 150 | train_loss=0.56944  val_loss=0.58633 | train_MAE=0.6903  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 151 | train_loss=0.58412  val_loss=0.58013 | train_MAE=0.6903  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 152 | train_loss=0.56420  val_loss=0.57700 | train_MAE=0.6959  val_MAE=0.6957 | lr=0.001 | time=0.09s\n",
      "Epoch 153 | train_loss=0.57004  val_loss=0.57687 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 154 | train_loss=0.56499  val_loss=0.57918 | train_MAE=0.7201  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 155 | train_loss=0.55601  val_loss=0.58387 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 156 | train_loss=0.54873  val_loss=0.58506 | train_MAE=0.7220  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 157 | train_loss=0.56175  val_loss=0.58494 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 158 | train_loss=0.56256  val_loss=0.58605 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 159 | train_loss=0.57132  val_loss=0.57960 | train_MAE=0.6959  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 160 | train_loss=0.54857  val_loss=0.58136 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 161 | train_loss=0.58324  val_loss=0.57708 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 162 | train_loss=0.55877  val_loss=0.58257 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 163 | train_loss=0.57144  val_loss=0.58596 | train_MAE=0.7090  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 164 | train_loss=0.57845  val_loss=0.58143 | train_MAE=0.6978  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 165 | train_loss=0.56398  val_loss=0.58435 | train_MAE=0.6940  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 166 | train_loss=0.56740  val_loss=0.58783 | train_MAE=0.6978  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 167 | train_loss=0.56964  val_loss=0.58487 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 168 | train_loss=0.56994  val_loss=0.57910 | train_MAE=0.7146  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 169 | train_loss=0.57575  val_loss=0.58321 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 170 | train_loss=0.56743  val_loss=0.58190 | train_MAE=0.7034  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 171 | train_loss=0.55525  val_loss=0.58465 | train_MAE=0.7201  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 172 | train_loss=0.57024  val_loss=0.58462 | train_MAE=0.7164  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 173 | train_loss=0.55123  val_loss=0.58347 | train_MAE=0.7146  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 174 | train_loss=0.56868  val_loss=0.58466 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 175 | train_loss=0.55250  val_loss=0.58495 | train_MAE=0.7295  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 176 | train_loss=0.55801  val_loss=0.57671 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 177 | train_loss=0.57678  val_loss=0.57529 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 178 | train_loss=0.57431  val_loss=0.58357 | train_MAE=0.6847  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 179 | train_loss=0.56171  val_loss=0.58138 | train_MAE=0.7071  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 180 | train_loss=0.55413  val_loss=0.58232 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 181 | train_loss=0.55692  val_loss=0.58264 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 182 | train_loss=0.55648  val_loss=0.58763 | train_MAE=0.7220  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 183 | train_loss=0.55950  val_loss=0.58534 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 184 | train_loss=0.55108  val_loss=0.58739 | train_MAE=0.7015  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 185 | train_loss=0.56435  val_loss=0.58243 | train_MAE=0.6996  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 186 | train_loss=0.55007  val_loss=0.58075 | train_MAE=0.7034  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 187 | train_loss=0.55051  val_loss=0.58616 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.001 | time=0.09s\n",
      "Epoch 188 | train_loss=0.56535  val_loss=0.57902 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 189 | train_loss=0.56145  val_loss=0.57817 | train_MAE=0.6959  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 190 | train_loss=0.55085  val_loss=0.57967 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 191 | train_loss=0.56596  val_loss=0.58032 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 192 | train_loss=0.54691  val_loss=0.57924 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 193 | train_loss=0.54796  val_loss=0.58365 | train_MAE=0.7052  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 194 | train_loss=0.57230  val_loss=0.58612 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 195 | train_loss=0.55789  val_loss=0.58969 | train_MAE=0.6940  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 196 | train_loss=0.57240  val_loss=0.58785 | train_MAE=0.6847  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 197 | train_loss=0.56115  val_loss=0.58834 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 198 | train_loss=0.55397  val_loss=0.58518 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 199 | train_loss=0.54887  val_loss=0.58348 | train_MAE=0.7034  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 200 | train_loss=0.53713  val_loss=0.57884 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Total training time: 16.31s\n",
      "Test Accuracy: 0.5913\n",
      "\n",
      "Training with dropout=0.5\n",
      "Epoch 001 | train_loss=2.02458  val_loss=0.87645 | train_MAE=0.5112  val_MAE=0.6522 | lr=0.001 | time=0.09s\n",
      "Epoch 002 | train_loss=1.52764  val_loss=0.72796 | train_MAE=0.5616  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 003 | train_loss=1.22333  val_loss=0.70451 | train_MAE=0.5336  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 004 | train_loss=1.05634  val_loss=0.68962 | train_MAE=0.5224  val_MAE=0.6435 | lr=0.001 | time=0.08s\n",
      "Epoch 005 | train_loss=1.00980  val_loss=0.68208 | train_MAE=0.5448  val_MAE=0.6348 | lr=0.001 | time=0.08s\n",
      "Epoch 006 | train_loss=0.88901  val_loss=0.67957 | train_MAE=0.5578  val_MAE=0.6435 | lr=0.001 | time=0.08s\n",
      "Epoch 007 | train_loss=0.89574  val_loss=0.67955 | train_MAE=0.5373  val_MAE=0.6087 | lr=0.001 | time=0.08s\n",
      "Epoch 008 | train_loss=0.80927  val_loss=0.67830 | train_MAE=0.5485  val_MAE=0.6087 | lr=0.001 | time=0.08s\n",
      "Epoch 009 | train_loss=0.79699  val_loss=0.67831 | train_MAE=0.5560  val_MAE=0.6261 | lr=0.001 | time=0.08s\n",
      "Epoch 010 | train_loss=0.80381  val_loss=0.67683 | train_MAE=0.5690  val_MAE=0.6348 | lr=0.001 | time=0.08s\n",
      "Epoch 011 | train_loss=0.79356  val_loss=0.67633 | train_MAE=0.5448  val_MAE=0.6348 | lr=0.001 | time=0.08s\n",
      "Epoch 012 | train_loss=0.75939  val_loss=0.67664 | train_MAE=0.5541  val_MAE=0.6348 | lr=0.001 | time=0.08s\n",
      "Epoch 013 | train_loss=0.74280  val_loss=0.67690 | train_MAE=0.5448  val_MAE=0.6435 | lr=0.001 | time=0.08s\n",
      "Epoch 014 | train_loss=0.72956  val_loss=0.67496 | train_MAE=0.5746  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 015 | train_loss=0.75126  val_loss=0.67354 | train_MAE=0.5765  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 016 | train_loss=0.69780  val_loss=0.67367 | train_MAE=0.6231  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 017 | train_loss=0.71194  val_loss=0.67426 | train_MAE=0.5970  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 018 | train_loss=0.73862  val_loss=0.67317 | train_MAE=0.6045  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 019 | train_loss=0.69628  val_loss=0.67317 | train_MAE=0.6194  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 020 | train_loss=0.69431  val_loss=0.67266 | train_MAE=0.6045  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 021 | train_loss=0.70735  val_loss=0.67128 | train_MAE=0.5989  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 022 | train_loss=0.69203  val_loss=0.66995 | train_MAE=0.6045  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 023 | train_loss=0.68562  val_loss=0.66836 | train_MAE=0.6082  val_MAE=0.6522 | lr=0.001 | time=0.13s\n",
      "Epoch 024 | train_loss=0.69799  val_loss=0.66704 | train_MAE=0.6343  val_MAE=0.6522 | lr=0.001 | time=0.09s\n",
      "Epoch 025 | train_loss=0.66801  val_loss=0.66635 | train_MAE=0.6325  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 026 | train_loss=0.67072  val_loss=0.66525 | train_MAE=0.6586  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 027 | train_loss=0.66639  val_loss=0.66406 | train_MAE=0.6474  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 028 | train_loss=0.66623  val_loss=0.66265 | train_MAE=0.6455  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 029 | train_loss=0.67352  val_loss=0.66205 | train_MAE=0.6287  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 030 | train_loss=0.66543  val_loss=0.66091 | train_MAE=0.6623  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 031 | train_loss=0.67651  val_loss=0.66082 | train_MAE=0.6269  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 032 | train_loss=0.66857  val_loss=0.65910 | train_MAE=0.6250  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 033 | train_loss=0.67727  val_loss=0.65663 | train_MAE=0.6138  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 034 | train_loss=0.67690  val_loss=0.65491 | train_MAE=0.6325  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 035 | train_loss=0.66247  val_loss=0.65378 | train_MAE=0.6511  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 036 | train_loss=0.65162  val_loss=0.65172 | train_MAE=0.6604  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 037 | train_loss=0.65955  val_loss=0.65125 | train_MAE=0.6381  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 038 | train_loss=0.67094  val_loss=0.65128 | train_MAE=0.6586  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 039 | train_loss=0.66806  val_loss=0.65174 | train_MAE=0.6418  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 040 | train_loss=0.65627  val_loss=0.65083 | train_MAE=0.6530  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 041 | train_loss=0.66741  val_loss=0.65004 | train_MAE=0.6325  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 042 | train_loss=0.65856  val_loss=0.64957 | train_MAE=0.6549  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 043 | train_loss=0.65070  val_loss=0.64756 | train_MAE=0.6399  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 044 | train_loss=0.65508  val_loss=0.64452 | train_MAE=0.6530  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 045 | train_loss=0.65692  val_loss=0.64094 | train_MAE=0.6642  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 046 | train_loss=0.66106  val_loss=0.64063 | train_MAE=0.6567  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 047 | train_loss=0.66190  val_loss=0.64149 | train_MAE=0.6604  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 048 | train_loss=0.66612  val_loss=0.64181 | train_MAE=0.6530  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 049 | train_loss=0.64827  val_loss=0.64043 | train_MAE=0.6511  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 050 | train_loss=0.63707  val_loss=0.63614 | train_MAE=0.6567  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 051 | train_loss=0.65642  val_loss=0.63261 | train_MAE=0.6325  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 052 | train_loss=0.65358  val_loss=0.63022 | train_MAE=0.6474  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 053 | train_loss=0.65611  val_loss=0.63104 | train_MAE=0.6511  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 054 | train_loss=0.63936  val_loss=0.62950 | train_MAE=0.6549  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 055 | train_loss=0.65627  val_loss=0.63054 | train_MAE=0.6660  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 056 | train_loss=0.62416  val_loss=0.62656 | train_MAE=0.6716  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 057 | train_loss=0.65132  val_loss=0.62584 | train_MAE=0.6623  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 058 | train_loss=0.65368  val_loss=0.62430 | train_MAE=0.6493  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 059 | train_loss=0.63025  val_loss=0.62138 | train_MAE=0.6716  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 060 | train_loss=0.66119  val_loss=0.62167 | train_MAE=0.6418  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 061 | train_loss=0.65143  val_loss=0.62425 | train_MAE=0.6604  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 062 | train_loss=0.64103  val_loss=0.62454 | train_MAE=0.6493  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 063 | train_loss=0.64659  val_loss=0.62369 | train_MAE=0.6549  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 064 | train_loss=0.62317  val_loss=0.61920 | train_MAE=0.6772  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 065 | train_loss=0.63525  val_loss=0.61517 | train_MAE=0.6623  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 066 | train_loss=0.63341  val_loss=0.61422 | train_MAE=0.6586  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 067 | train_loss=0.65678  val_loss=0.61335 | train_MAE=0.6567  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 068 | train_loss=0.63358  val_loss=0.61753 | train_MAE=0.6716  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 069 | train_loss=0.63765  val_loss=0.61799 | train_MAE=0.6866  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 070 | train_loss=0.64436  val_loss=0.61723 | train_MAE=0.6567  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 071 | train_loss=0.62658  val_loss=0.61480 | train_MAE=0.6716  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 072 | train_loss=0.63607  val_loss=0.61129 | train_MAE=0.6567  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 073 | train_loss=0.64044  val_loss=0.61278 | train_MAE=0.6455  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 074 | train_loss=0.63832  val_loss=0.61121 | train_MAE=0.6604  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 075 | train_loss=0.62956  val_loss=0.61274 | train_MAE=0.6623  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 076 | train_loss=0.61789  val_loss=0.61222 | train_MAE=0.6679  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 077 | train_loss=0.61636  val_loss=0.61000 | train_MAE=0.6716  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 078 | train_loss=0.62340  val_loss=0.60635 | train_MAE=0.6903  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 079 | train_loss=0.61996  val_loss=0.60258 | train_MAE=0.6754  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 080 | train_loss=0.62295  val_loss=0.59872 | train_MAE=0.6549  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 081 | train_loss=0.62813  val_loss=0.60029 | train_MAE=0.6735  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 082 | train_loss=0.63304  val_loss=0.60130 | train_MAE=0.6418  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 083 | train_loss=0.59663  val_loss=0.60139 | train_MAE=0.6735  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 084 | train_loss=0.62293  val_loss=0.59992 | train_MAE=0.6455  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 085 | train_loss=0.63530  val_loss=0.60075 | train_MAE=0.6698  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 086 | train_loss=0.64501  val_loss=0.60377 | train_MAE=0.6549  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 087 | train_loss=0.63329  val_loss=0.60666 | train_MAE=0.6418  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 088 | train_loss=0.63464  val_loss=0.60721 | train_MAE=0.6623  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 089 | train_loss=0.61573  val_loss=0.60757 | train_MAE=0.6772  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 090 | train_loss=0.62614  val_loss=0.60521 | train_MAE=0.6735  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 091 | train_loss=0.63958  val_loss=0.60579 | train_MAE=0.6549  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 092 | train_loss=0.63802  val_loss=0.60882 | train_MAE=0.6474  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 093 | train_loss=0.61790  val_loss=0.60926 | train_MAE=0.6716  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 094 | train_loss=0.61724  val_loss=0.60587 | train_MAE=0.6604  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 095 | train_loss=0.61348  val_loss=0.60367 | train_MAE=0.6978  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 096 | train_loss=0.62555  val_loss=0.60112 | train_MAE=0.6623  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 097 | train_loss=0.62068  val_loss=0.60120 | train_MAE=0.6828  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 098 | train_loss=0.61554  val_loss=0.59903 | train_MAE=0.6642  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 099 | train_loss=0.62505  val_loss=0.59858 | train_MAE=0.6418  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 100 | train_loss=0.61796  val_loss=0.59770 | train_MAE=0.6642  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 101 | train_loss=0.62363  val_loss=0.59638 | train_MAE=0.6660  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 102 | train_loss=0.61889  val_loss=0.59576 | train_MAE=0.6772  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 103 | train_loss=0.61827  val_loss=0.59517 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 104 | train_loss=0.60721  val_loss=0.59465 | train_MAE=0.6959  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 105 | train_loss=0.61263  val_loss=0.59365 | train_MAE=0.6511  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 106 | train_loss=0.61233  val_loss=0.59367 | train_MAE=0.6772  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 107 | train_loss=0.59778  val_loss=0.58994 | train_MAE=0.6866  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 108 | train_loss=0.59851  val_loss=0.58723 | train_MAE=0.6828  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 109 | train_loss=0.59271  val_loss=0.58484 | train_MAE=0.6828  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 110 | train_loss=0.60901  val_loss=0.58704 | train_MAE=0.6754  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 111 | train_loss=0.61639  val_loss=0.58877 | train_MAE=0.6698  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 112 | train_loss=0.59554  val_loss=0.58913 | train_MAE=0.6959  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 113 | train_loss=0.61150  val_loss=0.58974 | train_MAE=0.6716  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 114 | train_loss=0.60442  val_loss=0.58975 | train_MAE=0.6866  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 115 | train_loss=0.59899  val_loss=0.58793 | train_MAE=0.6959  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 116 | train_loss=0.59969  val_loss=0.58477 | train_MAE=0.6660  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 117 | train_loss=0.58114  val_loss=0.58394 | train_MAE=0.6959  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 118 | train_loss=0.60003  val_loss=0.58343 | train_MAE=0.6660  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 119 | train_loss=0.59838  val_loss=0.58509 | train_MAE=0.6660  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 120 | train_loss=0.59864  val_loss=0.58605 | train_MAE=0.6549  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 121 | train_loss=0.60911  val_loss=0.58802 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 122 | train_loss=0.59553  val_loss=0.58668 | train_MAE=0.6828  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 123 | train_loss=0.59642  val_loss=0.58664 | train_MAE=0.6791  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 124 | train_loss=0.58840  val_loss=0.58522 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 125 | train_loss=0.58818  val_loss=0.58591 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 126 | train_loss=0.59488  val_loss=0.58695 | train_MAE=0.7052  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 127 | train_loss=0.61070  val_loss=0.58370 | train_MAE=0.6828  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 128 | train_loss=0.59908  val_loss=0.58453 | train_MAE=0.6754  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 129 | train_loss=0.60406  val_loss=0.59120 | train_MAE=0.6549  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 130 | train_loss=0.60360  val_loss=0.58929 | train_MAE=0.6922  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 131 | train_loss=0.59945  val_loss=0.58902 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 132 | train_loss=0.60511  val_loss=0.58658 | train_MAE=0.6903  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 133 | train_loss=0.59559  val_loss=0.58365 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 134 | train_loss=0.60380  val_loss=0.58431 | train_MAE=0.6698  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 135 | train_loss=0.59747  val_loss=0.59340 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 136 | train_loss=0.60110  val_loss=0.59213 | train_MAE=0.6604  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 137 | train_loss=0.61155  val_loss=0.59160 | train_MAE=0.6772  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 138 | train_loss=0.58568  val_loss=0.58778 | train_MAE=0.6828  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 139 | train_loss=0.57607  val_loss=0.58550 | train_MAE=0.6940  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 140 | train_loss=0.58884  val_loss=0.58391 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 141 | train_loss=0.59460  val_loss=0.58214 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 142 | train_loss=0.59126  val_loss=0.57980 | train_MAE=0.7052  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 143 | train_loss=0.58750  val_loss=0.57777 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 144 | train_loss=0.59551  val_loss=0.57788 | train_MAE=0.6679  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 145 | train_loss=0.59431  val_loss=0.57959 | train_MAE=0.6791  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 146 | train_loss=0.60319  val_loss=0.58119 | train_MAE=0.6791  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 147 | train_loss=0.58060  val_loss=0.57921 | train_MAE=0.7052  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 148 | train_loss=0.58720  val_loss=0.57902 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 149 | train_loss=0.61566  val_loss=0.58149 | train_MAE=0.6884  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 150 | train_loss=0.58554  val_loss=0.58388 | train_MAE=0.6922  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 151 | train_loss=0.58692  val_loss=0.58627 | train_MAE=0.6828  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 152 | train_loss=0.58180  val_loss=0.58526 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 153 | train_loss=0.59572  val_loss=0.58401 | train_MAE=0.6866  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 154 | train_loss=0.58302  val_loss=0.58048 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 155 | train_loss=0.58687  val_loss=0.57805 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 156 | train_loss=0.58266  val_loss=0.58098 | train_MAE=0.6847  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 157 | train_loss=0.58284  val_loss=0.58023 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 158 | train_loss=0.58446  val_loss=0.57956 | train_MAE=0.6828  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 159 | train_loss=0.58643  val_loss=0.58068 | train_MAE=0.6828  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 160 | train_loss=0.57834  val_loss=0.57999 | train_MAE=0.6847  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 161 | train_loss=0.57906  val_loss=0.57931 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 162 | train_loss=0.59646  val_loss=0.58059 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 163 | train_loss=0.58114  val_loss=0.57958 | train_MAE=0.7015  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 164 | train_loss=0.57842  val_loss=0.57739 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 165 | train_loss=0.57706  val_loss=0.57921 | train_MAE=0.7034  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 166 | train_loss=0.59222  val_loss=0.58159 | train_MAE=0.6735  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 167 | train_loss=0.58951  val_loss=0.58267 | train_MAE=0.6791  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 168 | train_loss=0.57807  val_loss=0.58177 | train_MAE=0.6922  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 169 | train_loss=0.59170  val_loss=0.58161 | train_MAE=0.6623  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 170 | train_loss=0.58965  val_loss=0.57789 | train_MAE=0.6884  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 171 | train_loss=0.58820  val_loss=0.57986 | train_MAE=0.6884  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 172 | train_loss=0.57783  val_loss=0.58111 | train_MAE=0.7052  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 173 | train_loss=0.57957  val_loss=0.58132 | train_MAE=0.7090  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 174 | train_loss=0.59034  val_loss=0.58533 | train_MAE=0.6660  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 175 | train_loss=0.57399  val_loss=0.59547 | train_MAE=0.6996  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 176 | train_loss=0.58012  val_loss=0.58633 | train_MAE=0.6978  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 177 | train_loss=0.57455  val_loss=0.58121 | train_MAE=0.6828  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 178 | train_loss=0.58200  val_loss=0.58274 | train_MAE=0.6754  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 179 | train_loss=0.58263  val_loss=0.59100 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 180 | train_loss=0.57023  val_loss=0.58979 | train_MAE=0.6903  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 181 | train_loss=0.56353  val_loss=0.58490 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 182 | train_loss=0.57143  val_loss=0.58117 | train_MAE=0.6791  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 183 | train_loss=0.54977  val_loss=0.57785 | train_MAE=0.6959  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 184 | train_loss=0.58876  val_loss=0.58053 | train_MAE=0.6884  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 185 | train_loss=0.56589  val_loss=0.57971 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 186 | train_loss=0.57363  val_loss=0.58401 | train_MAE=0.7034  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 187 | train_loss=0.55751  val_loss=0.58135 | train_MAE=0.7146  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 188 | train_loss=0.56784  val_loss=0.57745 | train_MAE=0.6791  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 189 | train_loss=0.55442  val_loss=0.57912 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 190 | train_loss=0.56905  val_loss=0.58467 | train_MAE=0.6810  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 191 | train_loss=0.58004  val_loss=0.59169 | train_MAE=0.6922  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 192 | train_loss=0.57858  val_loss=0.58770 | train_MAE=0.6791  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 193 | train_loss=0.58886  val_loss=0.58835 | train_MAE=0.6866  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 194 | train_loss=0.56908  val_loss=0.58116 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 195 | train_loss=0.57272  val_loss=0.58134 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 196 | train_loss=0.57280  val_loss=0.58477 | train_MAE=0.6754  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 197 | train_loss=0.58157  val_loss=0.58373 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 198 | train_loss=0.55839  val_loss=0.58101 | train_MAE=0.6922  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 199 | train_loss=0.55838  val_loss=0.58628 | train_MAE=0.7015  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 200 | train_loss=0.58368  val_loss=0.57816 | train_MAE=0.6940  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Total training time: 16.13s\n",
      "Test Accuracy: 0.6087\n"
     ]
    }
   ],
   "source": [
    "print(\"TUNING DROPOUT RATE\")\n",
    "\n",
    "#all the different dropout values I'll try\n",
    "dropout_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "#results\n",
    "dropout_results = []\n",
    "\n",
    "for dropout in dropout_values:\n",
    "    print(f\"\\nTraining with dropout={dropout}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = NeuralNetworkFlexible(dropout=dropout).to(device)\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Train (reusing the training model from part 1)\n",
    "    history = train_model(model, X_train_dl, X_val_dl, epochs=200)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    total_loss, total_n = 0.0, 0\n",
    "    all_logits, all_true = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xb, yb in X_test_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            batch_loss = loss(logits, yb).item()\n",
    "            total_loss += batch_loss * xb.size(0)\n",
    "            total_n += xb.size(0)\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_true.append(yb.cpu())\n",
    "    \n",
    "    test_loss = total_loss / total_n\n",
    "    logits = torch.cat(all_logits).numpy().ravel()\n",
    "    y_true = torch.cat(all_true).numpy().astype(int)\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    y_pred = (probs >= 0.5).astype(int)\n",
    "    \n",
    "    test_acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    #adding best values of the model using the thos droput values\n",
    "    dropout_results.append({\n",
    "        'Dropout': dropout,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09473c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROPOUT RATE TUNING - RESULTS TABLE\n",
      " Dropout  Test Accuracy  Precision   Recall  F1 Score\n",
      "     0.0       0.608696   0.437500 0.341463  0.383562\n",
      "     0.1       0.617391   0.448276 0.317073  0.371429\n",
      "     0.2       0.643478   0.500000 0.317073  0.388060\n",
      "     0.3       0.626087   0.461538 0.292683  0.358209\n",
      "     0.4       0.591304   0.350000 0.170732  0.229508\n",
      "     0.5       0.608696   0.300000 0.073171  0.117647\n",
      "\n",
      " Best Dropout: 0.2 with accuracy 0.6435\n"
     ]
    }
   ],
   "source": [
    "# Display results table\n",
    "dropout_df = pd.DataFrame(dropout_results)\n",
    "print(\"DROPOUT RATE TUNING - RESULTS TABLE\")\n",
    "print(dropout_df.to_string(index=False))\n",
    "\n",
    "#finds best dropout test based on test accuracy\n",
    "best_dropout = dropout_df.loc[dropout_df['Test Accuracy'].idxmax(), 'Dropout']\n",
    "print(f\"\\n Best Dropout: {best_dropout} with accuracy {dropout_df['Test Accuracy'].max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a86b16d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: TUNING LEARNING RATE\n",
      "\n",
      "Training with learning_rate=0.0001\n",
      "Epoch 001 | train_loss=1.15122  val_loss=0.86891 | train_MAE=0.6082  val_MAE=0.6870 | lr=0.0001 | time=0.09s\n",
      "Epoch 002 | train_loss=1.03581  val_loss=0.74300 | train_MAE=0.5858  val_MAE=0.6783 | lr=0.0001 | time=0.11s\n",
      "Epoch 003 | train_loss=1.01127  val_loss=0.69221 | train_MAE=0.5019  val_MAE=0.6609 | lr=0.0001 | time=0.11s\n",
      "Epoch 004 | train_loss=1.01723  val_loss=0.67011 | train_MAE=0.5280  val_MAE=0.6000 | lr=0.0001 | time=0.08s\n",
      "Epoch 005 | train_loss=0.94707  val_loss=0.66173 | train_MAE=0.5205  val_MAE=0.6000 | lr=0.0001 | time=0.08s\n",
      "Epoch 006 | train_loss=0.86852  val_loss=0.65569 | train_MAE=0.5466  val_MAE=0.6348 | lr=0.0001 | time=0.08s\n",
      "Epoch 007 | train_loss=0.87717  val_loss=0.65250 | train_MAE=0.5485  val_MAE=0.6696 | lr=0.0001 | time=0.08s\n",
      "Epoch 008 | train_loss=0.83676  val_loss=0.65148 | train_MAE=0.5840  val_MAE=0.6870 | lr=0.0001 | time=0.08s\n",
      "Epoch 009 | train_loss=0.88987  val_loss=0.64885 | train_MAE=0.5336  val_MAE=0.6870 | lr=0.0001 | time=0.08s\n",
      "Epoch 010 | train_loss=0.84114  val_loss=0.64800 | train_MAE=0.5597  val_MAE=0.6783 | lr=0.0001 | time=0.08s\n",
      "Epoch 011 | train_loss=0.83407  val_loss=0.64815 | train_MAE=0.5653  val_MAE=0.6783 | lr=0.0001 | time=0.08s\n",
      "Epoch 012 | train_loss=0.85104  val_loss=0.64891 | train_MAE=0.5784  val_MAE=0.6783 | lr=0.0001 | time=0.08s\n",
      "Epoch 013 | train_loss=0.84828  val_loss=0.64626 | train_MAE=0.5877  val_MAE=0.6783 | lr=0.0001 | time=0.08s\n",
      "Epoch 014 | train_loss=0.76546  val_loss=0.64575 | train_MAE=0.5765  val_MAE=0.6696 | lr=0.0001 | time=0.08s\n",
      "Epoch 015 | train_loss=0.83165  val_loss=0.64562 | train_MAE=0.5951  val_MAE=0.6696 | lr=0.0001 | time=0.08s\n",
      "Epoch 016 | train_loss=0.79008  val_loss=0.64429 | train_MAE=0.5989  val_MAE=0.6783 | lr=0.0001 | time=0.08s\n",
      "Epoch 017 | train_loss=0.89755  val_loss=0.64340 | train_MAE=0.5485  val_MAE=0.6783 | lr=0.0001 | time=0.08s\n",
      "Epoch 018 | train_loss=0.77053  val_loss=0.64162 | train_MAE=0.6045  val_MAE=0.6783 | lr=0.0001 | time=0.08s\n",
      "Epoch 019 | train_loss=0.80471  val_loss=0.64150 | train_MAE=0.5672  val_MAE=0.6696 | lr=0.0001 | time=0.09s\n",
      "Epoch 020 | train_loss=0.75575  val_loss=0.63943 | train_MAE=0.5970  val_MAE=0.6696 | lr=0.0001 | time=0.08s\n",
      "Epoch 021 | train_loss=0.75449  val_loss=0.63834 | train_MAE=0.5653  val_MAE=0.6696 | lr=0.0001 | time=0.08s\n",
      "Epoch 022 | train_loss=0.76176  val_loss=0.63643 | train_MAE=0.5951  val_MAE=0.6870 | lr=0.0001 | time=0.08s\n",
      "Epoch 023 | train_loss=0.74075  val_loss=0.63582 | train_MAE=0.6082  val_MAE=0.6783 | lr=0.0001 | time=0.09s\n",
      "Epoch 024 | train_loss=0.78650  val_loss=0.63544 | train_MAE=0.5877  val_MAE=0.6609 | lr=0.0001 | time=0.08s\n",
      "Epoch 025 | train_loss=0.73508  val_loss=0.63535 | train_MAE=0.6138  val_MAE=0.6609 | lr=0.0001 | time=0.08s\n",
      "Epoch 026 | train_loss=0.77274  val_loss=0.63591 | train_MAE=0.5840  val_MAE=0.6696 | lr=0.0001 | time=0.08s\n",
      "Epoch 027 | train_loss=0.78671  val_loss=0.63538 | train_MAE=0.5578  val_MAE=0.6609 | lr=0.0001 | time=0.08s\n",
      "Epoch 028 | train_loss=0.74827  val_loss=0.63627 | train_MAE=0.6045  val_MAE=0.6522 | lr=0.0001 | time=0.08s\n",
      "Epoch 029 | train_loss=0.72070  val_loss=0.63582 | train_MAE=0.5914  val_MAE=0.6609 | lr=0.0001 | time=0.08s\n",
      "Epoch 030 | train_loss=0.70994  val_loss=0.63511 | train_MAE=0.6119  val_MAE=0.6609 | lr=0.0001 | time=0.08s\n",
      "Epoch 031 | train_loss=0.71677  val_loss=0.63392 | train_MAE=0.6063  val_MAE=0.6435 | lr=0.0001 | time=0.08s\n",
      "Epoch 032 | train_loss=0.69810  val_loss=0.63419 | train_MAE=0.6287  val_MAE=0.6435 | lr=0.0001 | time=0.08s\n",
      "Epoch 033 | train_loss=0.77044  val_loss=0.63510 | train_MAE=0.5877  val_MAE=0.6696 | lr=0.0001 | time=0.08s\n",
      "Epoch 034 | train_loss=0.72378  val_loss=0.63606 | train_MAE=0.6045  val_MAE=0.6957 | lr=0.0001 | time=0.08s\n",
      "Epoch 035 | train_loss=0.73985  val_loss=0.63469 | train_MAE=0.5914  val_MAE=0.6957 | lr=0.0001 | time=0.08s\n",
      "Epoch 036 | train_loss=0.69502  val_loss=0.63271 | train_MAE=0.6045  val_MAE=0.6870 | lr=0.0001 | time=0.08s\n",
      "Epoch 037 | train_loss=0.71617  val_loss=0.63172 | train_MAE=0.6063  val_MAE=0.6609 | lr=0.0001 | time=0.08s\n",
      "Epoch 038 | train_loss=0.67320  val_loss=0.63132 | train_MAE=0.6474  val_MAE=0.6609 | lr=0.0001 | time=0.08s\n",
      "Epoch 039 | train_loss=0.69916  val_loss=0.63088 | train_MAE=0.6157  val_MAE=0.6696 | lr=0.0001 | time=0.08s\n",
      "Epoch 040 | train_loss=0.69484  val_loss=0.63111 | train_MAE=0.6175  val_MAE=0.6609 | lr=0.0001 | time=0.08s\n",
      "Epoch 041 | train_loss=0.71471  val_loss=0.63105 | train_MAE=0.6175  val_MAE=0.6696 | lr=0.0001 | time=0.08s\n",
      "Epoch 042 | train_loss=0.69129  val_loss=0.63032 | train_MAE=0.6101  val_MAE=0.6870 | lr=0.0001 | time=0.08s\n",
      "Epoch 043 | train_loss=0.67868  val_loss=0.62999 | train_MAE=0.6343  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 044 | train_loss=0.68277  val_loss=0.63077 | train_MAE=0.6343  val_MAE=0.6870 | lr=0.0001 | time=0.08s\n",
      "Epoch 045 | train_loss=0.71200  val_loss=0.63170 | train_MAE=0.5989  val_MAE=0.6783 | lr=0.0001 | time=0.08s\n",
      "Epoch 046 | train_loss=0.72891  val_loss=0.63190 | train_MAE=0.5858  val_MAE=0.6783 | lr=0.0001 | time=0.08s\n",
      "Epoch 047 | train_loss=0.72585  val_loss=0.63073 | train_MAE=0.6157  val_MAE=0.6870 | lr=0.0001 | time=0.08s\n",
      "Epoch 048 | train_loss=0.67482  val_loss=0.62891 | train_MAE=0.6119  val_MAE=0.6957 | lr=0.0001 | time=0.08s\n",
      "Epoch 049 | train_loss=0.65769  val_loss=0.62656 | train_MAE=0.6623  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 050 | train_loss=0.67587  val_loss=0.62426 | train_MAE=0.6343  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 051 | train_loss=0.69728  val_loss=0.62395 | train_MAE=0.6325  val_MAE=0.6957 | lr=0.0001 | time=0.08s\n",
      "Epoch 052 | train_loss=0.72526  val_loss=0.62416 | train_MAE=0.6157  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 053 | train_loss=0.69288  val_loss=0.62467 | train_MAE=0.6119  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 054 | train_loss=0.66958  val_loss=0.62431 | train_MAE=0.6455  val_MAE=0.6957 | lr=0.0001 | time=0.08s\n",
      "Epoch 055 | train_loss=0.72623  val_loss=0.62460 | train_MAE=0.6063  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 056 | train_loss=0.68041  val_loss=0.62390 | train_MAE=0.6306  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 057 | train_loss=0.69167  val_loss=0.62259 | train_MAE=0.6119  val_MAE=0.6957 | lr=0.0001 | time=0.08s\n",
      "Epoch 058 | train_loss=0.70365  val_loss=0.62159 | train_MAE=0.5933  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 059 | train_loss=0.64165  val_loss=0.62135 | train_MAE=0.6623  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 060 | train_loss=0.70219  val_loss=0.62159 | train_MAE=0.6418  val_MAE=0.6957 | lr=0.0001 | time=0.08s\n",
      "Epoch 061 | train_loss=0.68500  val_loss=0.62105 | train_MAE=0.6231  val_MAE=0.6957 | lr=0.0001 | time=0.08s\n",
      "Epoch 062 | train_loss=0.67051  val_loss=0.62013 | train_MAE=0.6418  val_MAE=0.6870 | lr=0.0001 | time=0.08s\n",
      "Epoch 063 | train_loss=0.67874  val_loss=0.61876 | train_MAE=0.6175  val_MAE=0.6870 | lr=0.0001 | time=0.08s\n",
      "Epoch 064 | train_loss=0.67747  val_loss=0.61781 | train_MAE=0.6325  val_MAE=0.6957 | lr=0.0001 | time=0.08s\n",
      "Epoch 065 | train_loss=0.71127  val_loss=0.61640 | train_MAE=0.6287  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 066 | train_loss=0.70095  val_loss=0.61627 | train_MAE=0.5840  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 067 | train_loss=0.69588  val_loss=0.61689 | train_MAE=0.6194  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 068 | train_loss=0.69733  val_loss=0.61746 | train_MAE=0.6213  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 069 | train_loss=0.69755  val_loss=0.61770 | train_MAE=0.6381  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 070 | train_loss=0.67851  val_loss=0.61732 | train_MAE=0.6045  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 071 | train_loss=0.65466  val_loss=0.61673 | train_MAE=0.6306  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 072 | train_loss=0.66951  val_loss=0.61681 | train_MAE=0.6287  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 073 | train_loss=0.66933  val_loss=0.61587 | train_MAE=0.6530  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 074 | train_loss=0.65215  val_loss=0.61531 | train_MAE=0.6437  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 075 | train_loss=0.67756  val_loss=0.61446 | train_MAE=0.6437  val_MAE=0.6957 | lr=0.0001 | time=0.08s\n",
      "Epoch 076 | train_loss=0.65824  val_loss=0.61254 | train_MAE=0.6213  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 077 | train_loss=0.65530  val_loss=0.61118 | train_MAE=0.6399  val_MAE=0.6870 | lr=0.0001 | time=0.08s\n",
      "Epoch 078 | train_loss=0.65290  val_loss=0.60997 | train_MAE=0.6698  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 079 | train_loss=0.66098  val_loss=0.60976 | train_MAE=0.6474  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 080 | train_loss=0.65139  val_loss=0.60947 | train_MAE=0.6604  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 081 | train_loss=0.66209  val_loss=0.60815 | train_MAE=0.6511  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 082 | train_loss=0.66700  val_loss=0.60607 | train_MAE=0.6325  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 083 | train_loss=0.67073  val_loss=0.60547 | train_MAE=0.6026  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 084 | train_loss=0.69649  val_loss=0.60503 | train_MAE=0.6045  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 085 | train_loss=0.66068  val_loss=0.60522 | train_MAE=0.6362  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 086 | train_loss=0.65882  val_loss=0.60452 | train_MAE=0.6381  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 087 | train_loss=0.66756  val_loss=0.60335 | train_MAE=0.6269  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 088 | train_loss=0.67011  val_loss=0.60334 | train_MAE=0.6493  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 089 | train_loss=0.64785  val_loss=0.60365 | train_MAE=0.6511  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 090 | train_loss=0.64153  val_loss=0.60346 | train_MAE=0.6604  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 091 | train_loss=0.63756  val_loss=0.60324 | train_MAE=0.6511  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 092 | train_loss=0.66924  val_loss=0.60297 | train_MAE=0.6362  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 093 | train_loss=0.65745  val_loss=0.60240 | train_MAE=0.6306  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 094 | train_loss=0.64995  val_loss=0.60293 | train_MAE=0.6493  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 095 | train_loss=0.64628  val_loss=0.60272 | train_MAE=0.6306  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 096 | train_loss=0.66133  val_loss=0.60210 | train_MAE=0.6119  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 097 | train_loss=0.64485  val_loss=0.60169 | train_MAE=0.6474  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 098 | train_loss=0.66244  val_loss=0.60126 | train_MAE=0.6455  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 099 | train_loss=0.65699  val_loss=0.60085 | train_MAE=0.6381  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 100 | train_loss=0.65432  val_loss=0.60087 | train_MAE=0.6660  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 101 | train_loss=0.64401  val_loss=0.60123 | train_MAE=0.6138  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 102 | train_loss=0.65684  val_loss=0.60101 | train_MAE=0.6399  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 103 | train_loss=0.65177  val_loss=0.60083 | train_MAE=0.6549  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 104 | train_loss=0.63093  val_loss=0.60042 | train_MAE=0.6493  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 105 | train_loss=0.65786  val_loss=0.59965 | train_MAE=0.6269  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 106 | train_loss=0.64958  val_loss=0.59919 | train_MAE=0.6343  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 107 | train_loss=0.65452  val_loss=0.59918 | train_MAE=0.6306  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 108 | train_loss=0.65654  val_loss=0.59830 | train_MAE=0.6287  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 109 | train_loss=0.61203  val_loss=0.59790 | train_MAE=0.6754  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 110 | train_loss=0.64905  val_loss=0.59716 | train_MAE=0.6493  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 111 | train_loss=0.63589  val_loss=0.59704 | train_MAE=0.6511  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 112 | train_loss=0.63059  val_loss=0.59777 | train_MAE=0.6604  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 113 | train_loss=0.64704  val_loss=0.59778 | train_MAE=0.6754  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 114 | train_loss=0.65108  val_loss=0.59774 | train_MAE=0.6474  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 115 | train_loss=0.63068  val_loss=0.59804 | train_MAE=0.6306  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 116 | train_loss=0.62974  val_loss=0.59889 | train_MAE=0.6735  val_MAE=0.7391 | lr=0.0001 | time=0.08s\n",
      "Epoch 117 | train_loss=0.64660  val_loss=0.59932 | train_MAE=0.6530  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 118 | train_loss=0.64729  val_loss=0.59984 | train_MAE=0.6437  val_MAE=0.7304 | lr=0.0001 | time=0.09s\n",
      "Epoch 119 | train_loss=0.65454  val_loss=0.59968 | train_MAE=0.6549  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 120 | train_loss=0.65211  val_loss=0.60038 | train_MAE=0.6287  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 121 | train_loss=0.64144  val_loss=0.60097 | train_MAE=0.6381  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 122 | train_loss=0.65815  val_loss=0.60212 | train_MAE=0.6287  val_MAE=0.6957 | lr=0.0001 | time=0.08s\n",
      "Epoch 123 | train_loss=0.63329  val_loss=0.60230 | train_MAE=0.6474  val_MAE=0.6957 | lr=0.0001 | time=0.08s\n",
      "Epoch 124 | train_loss=0.63269  val_loss=0.60299 | train_MAE=0.6586  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 125 | train_loss=0.60549  val_loss=0.60314 | train_MAE=0.6810  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 126 | train_loss=0.66154  val_loss=0.60279 | train_MAE=0.6343  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 127 | train_loss=0.62950  val_loss=0.60221 | train_MAE=0.6530  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 128 | train_loss=0.62195  val_loss=0.60157 | train_MAE=0.6903  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 129 | train_loss=0.65115  val_loss=0.60086 | train_MAE=0.6567  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 130 | train_loss=0.63325  val_loss=0.59989 | train_MAE=0.6847  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 131 | train_loss=0.61924  val_loss=0.59953 | train_MAE=0.6549  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 132 | train_loss=0.65347  val_loss=0.59915 | train_MAE=0.6455  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 133 | train_loss=0.64848  val_loss=0.59875 | train_MAE=0.6474  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 134 | train_loss=0.62479  val_loss=0.59829 | train_MAE=0.6493  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 135 | train_loss=0.63116  val_loss=0.59783 | train_MAE=0.6586  val_MAE=0.7043 | lr=0.0001 | time=0.08s\n",
      "Epoch 136 | train_loss=0.63275  val_loss=0.59736 | train_MAE=0.6735  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 137 | train_loss=0.61972  val_loss=0.59639 | train_MAE=0.6847  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 138 | train_loss=0.63456  val_loss=0.59553 | train_MAE=0.6474  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 139 | train_loss=0.63603  val_loss=0.59472 | train_MAE=0.6567  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 140 | train_loss=0.64038  val_loss=0.59385 | train_MAE=0.6735  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 141 | train_loss=0.63917  val_loss=0.59383 | train_MAE=0.6455  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 142 | train_loss=0.62902  val_loss=0.59439 | train_MAE=0.6437  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 143 | train_loss=0.62188  val_loss=0.59473 | train_MAE=0.6698  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 144 | train_loss=0.60937  val_loss=0.59419 | train_MAE=0.6772  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 145 | train_loss=0.62388  val_loss=0.59416 | train_MAE=0.6735  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 146 | train_loss=0.62645  val_loss=0.59362 | train_MAE=0.6549  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 147 | train_loss=0.64351  val_loss=0.59320 | train_MAE=0.6418  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 148 | train_loss=0.61827  val_loss=0.59242 | train_MAE=0.6567  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 149 | train_loss=0.63445  val_loss=0.59187 | train_MAE=0.6642  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 150 | train_loss=0.62882  val_loss=0.59145 | train_MAE=0.6455  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 151 | train_loss=0.64192  val_loss=0.59115 | train_MAE=0.6418  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 152 | train_loss=0.62423  val_loss=0.59116 | train_MAE=0.6530  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 153 | train_loss=0.62171  val_loss=0.59140 | train_MAE=0.6642  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 154 | train_loss=0.65369  val_loss=0.59188 | train_MAE=0.6623  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 155 | train_loss=0.63836  val_loss=0.59283 | train_MAE=0.6549  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 156 | train_loss=0.62789  val_loss=0.59343 | train_MAE=0.6455  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 157 | train_loss=0.64496  val_loss=0.59350 | train_MAE=0.6437  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 158 | train_loss=0.64277  val_loss=0.59381 | train_MAE=0.6567  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 159 | train_loss=0.64445  val_loss=0.59420 | train_MAE=0.6698  val_MAE=0.7304 | lr=0.0001 | time=0.09s\n",
      "Epoch 160 | train_loss=0.61847  val_loss=0.59433 | train_MAE=0.6679  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 161 | train_loss=0.63111  val_loss=0.59449 | train_MAE=0.6567  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 162 | train_loss=0.62445  val_loss=0.59451 | train_MAE=0.6754  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 163 | train_loss=0.63194  val_loss=0.59451 | train_MAE=0.6660  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 164 | train_loss=0.63535  val_loss=0.59470 | train_MAE=0.6530  val_MAE=0.7217 | lr=0.0001 | time=0.09s\n",
      "Epoch 165 | train_loss=0.63100  val_loss=0.59505 | train_MAE=0.6828  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 166 | train_loss=0.62394  val_loss=0.59444 | train_MAE=0.6642  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 167 | train_loss=0.61696  val_loss=0.59422 | train_MAE=0.6698  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 168 | train_loss=0.62176  val_loss=0.59379 | train_MAE=0.6810  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 169 | train_loss=0.60958  val_loss=0.59374 | train_MAE=0.7090  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 170 | train_loss=0.61023  val_loss=0.59371 | train_MAE=0.6754  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 171 | train_loss=0.63401  val_loss=0.59384 | train_MAE=0.6511  val_MAE=0.7130 | lr=0.0001 | time=0.09s\n",
      "Epoch 172 | train_loss=0.63082  val_loss=0.59407 | train_MAE=0.6604  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 173 | train_loss=0.62061  val_loss=0.59463 | train_MAE=0.6567  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 174 | train_loss=0.63026  val_loss=0.59440 | train_MAE=0.6306  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 175 | train_loss=0.64197  val_loss=0.59453 | train_MAE=0.6474  val_MAE=0.7217 | lr=0.0001 | time=0.08s\n",
      "Epoch 176 | train_loss=0.60768  val_loss=0.59423 | train_MAE=0.6679  val_MAE=0.7130 | lr=0.0001 | time=0.09s\n",
      "Epoch 177 | train_loss=0.64643  val_loss=0.59464 | train_MAE=0.6604  val_MAE=0.7130 | lr=0.0001 | time=0.28s\n",
      "Epoch 178 | train_loss=0.62408  val_loss=0.59493 | train_MAE=0.6418  val_MAE=0.7130 | lr=0.0001 | time=0.16s\n",
      "Epoch 179 | train_loss=0.62458  val_loss=0.59537 | train_MAE=0.6660  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 180 | train_loss=0.62560  val_loss=0.59534 | train_MAE=0.6791  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 181 | train_loss=0.60563  val_loss=0.59490 | train_MAE=0.6772  val_MAE=0.7130 | lr=0.0001 | time=0.08s\n",
      "Epoch 182 | train_loss=0.61856  val_loss=0.59470 | train_MAE=0.6493  val_MAE=0.7391 | lr=0.0001 | time=0.08s\n",
      "Epoch 183 | train_loss=0.62023  val_loss=0.59485 | train_MAE=0.6511  val_MAE=0.7391 | lr=0.0001 | time=0.08s\n",
      "Epoch 184 | train_loss=0.61816  val_loss=0.59430 | train_MAE=0.6623  val_MAE=0.7391 | lr=0.0001 | time=0.08s\n",
      "Epoch 185 | train_loss=0.61966  val_loss=0.59392 | train_MAE=0.6437  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 186 | train_loss=0.60810  val_loss=0.59363 | train_MAE=0.6884  val_MAE=0.7304 | lr=0.0001 | time=0.12s\n",
      "Epoch 187 | train_loss=0.62188  val_loss=0.59325 | train_MAE=0.6828  val_MAE=0.7304 | lr=0.0001 | time=0.09s\n",
      "Epoch 188 | train_loss=0.62085  val_loss=0.59295 | train_MAE=0.6679  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 189 | train_loss=0.61870  val_loss=0.59279 | train_MAE=0.6604  val_MAE=0.7391 | lr=0.0001 | time=0.08s\n",
      "Epoch 190 | train_loss=0.62354  val_loss=0.59293 | train_MAE=0.6567  val_MAE=0.7391 | lr=0.0001 | time=0.08s\n",
      "Epoch 191 | train_loss=0.62281  val_loss=0.59242 | train_MAE=0.6735  val_MAE=0.7391 | lr=0.0001 | time=0.08s\n",
      "Epoch 192 | train_loss=0.61586  val_loss=0.59208 | train_MAE=0.7127  val_MAE=0.7391 | lr=0.0001 | time=0.08s\n",
      "Epoch 193 | train_loss=0.63050  val_loss=0.59208 | train_MAE=0.6716  val_MAE=0.7478 | lr=0.0001 | time=0.08s\n",
      "Epoch 194 | train_loss=0.60534  val_loss=0.59174 | train_MAE=0.6866  val_MAE=0.7478 | lr=0.0001 | time=0.08s\n",
      "Epoch 195 | train_loss=0.60338  val_loss=0.59116 | train_MAE=0.6660  val_MAE=0.7478 | lr=0.0001 | time=0.08s\n",
      "Epoch 196 | train_loss=0.61255  val_loss=0.59127 | train_MAE=0.6754  val_MAE=0.7304 | lr=0.0001 | time=0.08s\n",
      "Epoch 197 | train_loss=0.62357  val_loss=0.59102 | train_MAE=0.6828  val_MAE=0.7478 | lr=0.0001 | time=0.08s\n",
      "Epoch 198 | train_loss=0.62431  val_loss=0.59110 | train_MAE=0.6754  val_MAE=0.7478 | lr=0.0001 | time=0.08s\n",
      "Epoch 199 | train_loss=0.61382  val_loss=0.59116 | train_MAE=0.6660  val_MAE=0.7478 | lr=0.0001 | time=0.08s\n",
      "Epoch 200 | train_loss=0.62224  val_loss=0.59141 | train_MAE=0.6996  val_MAE=0.7391 | lr=0.0001 | time=0.09s\n",
      "Total training time: 16.59s\n",
      "Test Accuracy: 0.6000\n",
      "\n",
      "Training with learning_rate=0.0005\n",
      "Epoch 001 | train_loss=1.34188  val_loss=0.77777 | train_MAE=0.4925  val_MAE=0.6522 | lr=0.0005 | time=0.09s\n",
      "Epoch 002 | train_loss=1.08974  val_loss=0.64204 | train_MAE=0.5634  val_MAE=0.6522 | lr=0.0005 | time=0.12s\n",
      "Epoch 003 | train_loss=0.93726  val_loss=0.63704 | train_MAE=0.5280  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 004 | train_loss=0.87788  val_loss=0.63432 | train_MAE=0.5728  val_MAE=0.6870 | lr=0.0005 | time=0.08s\n",
      "Epoch 005 | train_loss=0.90256  val_loss=0.63461 | train_MAE=0.5896  val_MAE=0.6783 | lr=0.0005 | time=0.08s\n",
      "Epoch 006 | train_loss=0.81363  val_loss=0.63432 | train_MAE=0.6138  val_MAE=0.6870 | lr=0.0005 | time=0.09s\n",
      "Epoch 007 | train_loss=0.76890  val_loss=0.63081 | train_MAE=0.6194  val_MAE=0.6783 | lr=0.0005 | time=0.08s\n",
      "Epoch 008 | train_loss=0.74733  val_loss=0.63688 | train_MAE=0.5970  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 009 | train_loss=0.74837  val_loss=0.63301 | train_MAE=0.5951  val_MAE=0.6870 | lr=0.0005 | time=0.08s\n",
      "Epoch 010 | train_loss=0.76684  val_loss=0.62865 | train_MAE=0.6063  val_MAE=0.6783 | lr=0.0005 | time=0.08s\n",
      "Epoch 011 | train_loss=0.70689  val_loss=0.62430 | train_MAE=0.6250  val_MAE=0.6870 | lr=0.0005 | time=0.08s\n",
      "Epoch 012 | train_loss=0.71945  val_loss=0.62179 | train_MAE=0.5951  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 013 | train_loss=0.69814  val_loss=0.61374 | train_MAE=0.6119  val_MAE=0.7130 | lr=0.0005 | time=0.09s\n",
      "Epoch 014 | train_loss=0.71329  val_loss=0.61165 | train_MAE=0.6138  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 015 | train_loss=0.68365  val_loss=0.61197 | train_MAE=0.6213  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 016 | train_loss=0.66966  val_loss=0.61101 | train_MAE=0.6250  val_MAE=0.7130 | lr=0.0005 | time=0.09s\n",
      "Epoch 017 | train_loss=0.67797  val_loss=0.60898 | train_MAE=0.6511  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 018 | train_loss=0.64421  val_loss=0.60677 | train_MAE=0.6493  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 019 | train_loss=0.65854  val_loss=0.60480 | train_MAE=0.6493  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 020 | train_loss=0.64946  val_loss=0.60245 | train_MAE=0.6604  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 021 | train_loss=0.64841  val_loss=0.60095 | train_MAE=0.6586  val_MAE=0.7217 | lr=0.0005 | time=0.07s\n",
      "Epoch 022 | train_loss=0.66152  val_loss=0.60636 | train_MAE=0.6549  val_MAE=0.6783 | lr=0.0005 | time=0.08s\n",
      "Epoch 023 | train_loss=0.65059  val_loss=0.60702 | train_MAE=0.6567  val_MAE=0.6870 | lr=0.0005 | time=0.08s\n",
      "Epoch 024 | train_loss=0.63918  val_loss=0.60720 | train_MAE=0.6623  val_MAE=0.6609 | lr=0.0005 | time=0.08s\n",
      "Epoch 025 | train_loss=0.63920  val_loss=0.60680 | train_MAE=0.6362  val_MAE=0.6870 | lr=0.0005 | time=0.08s\n",
      "Epoch 026 | train_loss=0.64284  val_loss=0.60795 | train_MAE=0.6343  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 027 | train_loss=0.63141  val_loss=0.60706 | train_MAE=0.6549  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 028 | train_loss=0.61671  val_loss=0.60434 | train_MAE=0.6679  val_MAE=0.6783 | lr=0.0005 | time=0.08s\n",
      "Epoch 029 | train_loss=0.63022  val_loss=0.60101 | train_MAE=0.6623  val_MAE=0.6870 | lr=0.0005 | time=0.08s\n",
      "Epoch 030 | train_loss=0.62233  val_loss=0.59741 | train_MAE=0.6866  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 031 | train_loss=0.63053  val_loss=0.59605 | train_MAE=0.6586  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 032 | train_loss=0.62739  val_loss=0.59756 | train_MAE=0.6567  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 033 | train_loss=0.63097  val_loss=0.59906 | train_MAE=0.6791  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 034 | train_loss=0.61684  val_loss=0.59827 | train_MAE=0.6511  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 035 | train_loss=0.61195  val_loss=0.59791 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 036 | train_loss=0.59494  val_loss=0.59647 | train_MAE=0.6978  val_MAE=0.7391 | lr=0.0005 | time=0.13s\n",
      "Epoch 037 | train_loss=0.62520  val_loss=0.59521 | train_MAE=0.6716  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 038 | train_loss=0.61178  val_loss=0.59612 | train_MAE=0.6604  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 039 | train_loss=0.59904  val_loss=0.59574 | train_MAE=0.6772  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 040 | train_loss=0.60527  val_loss=0.59817 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 041 | train_loss=0.61479  val_loss=0.59758 | train_MAE=0.6586  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 042 | train_loss=0.59968  val_loss=0.59432 | train_MAE=0.6791  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 043 | train_loss=0.60479  val_loss=0.59258 | train_MAE=0.6866  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 044 | train_loss=0.59500  val_loss=0.59226 | train_MAE=0.6679  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 045 | train_loss=0.62066  val_loss=0.59083 | train_MAE=0.6754  val_MAE=0.6870 | lr=0.0005 | time=0.08s\n",
      "Epoch 046 | train_loss=0.61374  val_loss=0.59105 | train_MAE=0.6754  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 047 | train_loss=0.58831  val_loss=0.59427 | train_MAE=0.7034  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 048 | train_loss=0.62959  val_loss=0.59402 | train_MAE=0.6586  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 049 | train_loss=0.60926  val_loss=0.59131 | train_MAE=0.6679  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 050 | train_loss=0.61057  val_loss=0.58804 | train_MAE=0.6530  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 051 | train_loss=0.58529  val_loss=0.58872 | train_MAE=0.6884  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 052 | train_loss=0.59426  val_loss=0.59163 | train_MAE=0.6791  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 053 | train_loss=0.61958  val_loss=0.59076 | train_MAE=0.6623  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 054 | train_loss=0.61681  val_loss=0.58961 | train_MAE=0.6493  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 055 | train_loss=0.60386  val_loss=0.59105 | train_MAE=0.6660  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 056 | train_loss=0.58174  val_loss=0.59482 | train_MAE=0.6847  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 057 | train_loss=0.60532  val_loss=0.59276 | train_MAE=0.6772  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 058 | train_loss=0.59682  val_loss=0.58935 | train_MAE=0.6847  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 059 | train_loss=0.62135  val_loss=0.58986 | train_MAE=0.6586  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 060 | train_loss=0.61943  val_loss=0.59156 | train_MAE=0.6660  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 061 | train_loss=0.61278  val_loss=0.59535 | train_MAE=0.6940  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 062 | train_loss=0.61176  val_loss=0.59145 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 063 | train_loss=0.58552  val_loss=0.58973 | train_MAE=0.6791  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 064 | train_loss=0.58870  val_loss=0.58867 | train_MAE=0.6716  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 065 | train_loss=0.60871  val_loss=0.58870 | train_MAE=0.6866  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 066 | train_loss=0.58869  val_loss=0.58778 | train_MAE=0.6716  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 067 | train_loss=0.59491  val_loss=0.59154 | train_MAE=0.6754  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 068 | train_loss=0.57633  val_loss=0.59382 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 069 | train_loss=0.60538  val_loss=0.59147 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 070 | train_loss=0.58938  val_loss=0.58723 | train_MAE=0.6754  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 071 | train_loss=0.58368  val_loss=0.58541 | train_MAE=0.6679  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 072 | train_loss=0.58106  val_loss=0.58695 | train_MAE=0.6884  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 073 | train_loss=0.56712  val_loss=0.58911 | train_MAE=0.6978  val_MAE=0.7391 | lr=0.0005 | time=0.08s\n",
      "Epoch 074 | train_loss=0.60303  val_loss=0.58724 | train_MAE=0.6791  val_MAE=0.7391 | lr=0.0005 | time=0.08s\n",
      "Epoch 075 | train_loss=0.58304  val_loss=0.58789 | train_MAE=0.6642  val_MAE=0.7391 | lr=0.0005 | time=0.08s\n",
      "Epoch 076 | train_loss=0.60400  val_loss=0.58383 | train_MAE=0.6530  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 077 | train_loss=0.60860  val_loss=0.58586 | train_MAE=0.6679  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 078 | train_loss=0.61363  val_loss=0.58424 | train_MAE=0.6698  val_MAE=0.7391 | lr=0.0005 | time=0.08s\n",
      "Epoch 079 | train_loss=0.58125  val_loss=0.58674 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 080 | train_loss=0.58937  val_loss=0.58560 | train_MAE=0.6716  val_MAE=0.7391 | lr=0.0005 | time=0.08s\n",
      "Epoch 081 | train_loss=0.58996  val_loss=0.58825 | train_MAE=0.6735  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 082 | train_loss=0.58800  val_loss=0.58864 | train_MAE=0.6922  val_MAE=0.7391 | lr=0.0005 | time=0.08s\n",
      "Epoch 083 | train_loss=0.56954  val_loss=0.59018 | train_MAE=0.6978  val_MAE=0.7478 | lr=0.0005 | time=0.07s\n",
      "Epoch 084 | train_loss=0.57862  val_loss=0.59180 | train_MAE=0.6884  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 085 | train_loss=0.57221  val_loss=0.59236 | train_MAE=0.7052  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 086 | train_loss=0.59236  val_loss=0.59066 | train_MAE=0.6940  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 087 | train_loss=0.56745  val_loss=0.59281 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 088 | train_loss=0.58216  val_loss=0.59354 | train_MAE=0.6959  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 089 | train_loss=0.57551  val_loss=0.59438 | train_MAE=0.6772  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 090 | train_loss=0.58109  val_loss=0.59386 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 091 | train_loss=0.57516  val_loss=0.59490 | train_MAE=0.6791  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 092 | train_loss=0.56577  val_loss=0.59842 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 093 | train_loss=0.57389  val_loss=0.59567 | train_MAE=0.7034  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 094 | train_loss=0.56933  val_loss=0.59862 | train_MAE=0.6959  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 095 | train_loss=0.58200  val_loss=0.59654 | train_MAE=0.6660  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 096 | train_loss=0.58600  val_loss=0.58972 | train_MAE=0.6884  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 097 | train_loss=0.57259  val_loss=0.58943 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 098 | train_loss=0.58398  val_loss=0.59206 | train_MAE=0.6866  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 099 | train_loss=0.56443  val_loss=0.59510 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 100 | train_loss=0.56576  val_loss=0.59734 | train_MAE=0.6828  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 101 | train_loss=0.58234  val_loss=0.59017 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 102 | train_loss=0.57471  val_loss=0.58640 | train_MAE=0.6828  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 103 | train_loss=0.57390  val_loss=0.58871 | train_MAE=0.6903  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 104 | train_loss=0.57068  val_loss=0.59510 | train_MAE=0.6810  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 105 | train_loss=0.57921  val_loss=0.59332 | train_MAE=0.6828  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 106 | train_loss=0.58318  val_loss=0.59057 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 107 | train_loss=0.55966  val_loss=0.59368 | train_MAE=0.7295  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 108 | train_loss=0.57178  val_loss=0.59527 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 109 | train_loss=0.57212  val_loss=0.59471 | train_MAE=0.6828  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 110 | train_loss=0.56811  val_loss=0.59409 | train_MAE=0.6959  val_MAE=0.7391 | lr=0.0005 | time=0.08s\n",
      "Epoch 111 | train_loss=0.55359  val_loss=0.59706 | train_MAE=0.6978  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 112 | train_loss=0.56247  val_loss=0.59669 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 113 | train_loss=0.59083  val_loss=0.59129 | train_MAE=0.6810  val_MAE=0.7391 | lr=0.0005 | time=0.08s\n",
      "Epoch 114 | train_loss=0.56483  val_loss=0.58817 | train_MAE=0.6959  val_MAE=0.7478 | lr=0.0005 | time=0.08s\n",
      "Epoch 115 | train_loss=0.58668  val_loss=0.58623 | train_MAE=0.6810  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 116 | train_loss=0.56388  val_loss=0.58823 | train_MAE=0.6959  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 117 | train_loss=0.58346  val_loss=0.59394 | train_MAE=0.6642  val_MAE=0.7391 | lr=0.0005 | time=0.08s\n",
      "Epoch 118 | train_loss=0.56577  val_loss=0.59184 | train_MAE=0.6884  val_MAE=0.7304 | lr=0.0005 | time=0.08s\n",
      "Epoch 119 | train_loss=0.57213  val_loss=0.58995 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 120 | train_loss=0.56802  val_loss=0.59182 | train_MAE=0.6828  val_MAE=0.7391 | lr=0.0005 | time=0.08s\n",
      "Epoch 121 | train_loss=0.57117  val_loss=0.59143 | train_MAE=0.6791  val_MAE=0.7391 | lr=0.0005 | time=0.09s\n",
      "Epoch 122 | train_loss=0.57265  val_loss=0.59138 | train_MAE=0.6940  val_MAE=0.7478 | lr=0.0005 | time=0.07s\n",
      "Epoch 123 | train_loss=0.56822  val_loss=0.59145 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.0005 | time=0.08s\n",
      "Epoch 124 | train_loss=0.57617  val_loss=0.58985 | train_MAE=0.6922  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 125 | train_loss=0.56760  val_loss=0.59277 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 126 | train_loss=0.56687  val_loss=0.59256 | train_MAE=0.7034  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 127 | train_loss=0.55306  val_loss=0.59434 | train_MAE=0.7015  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 128 | train_loss=0.56728  val_loss=0.60081 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 129 | train_loss=0.56169  val_loss=0.59534 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 130 | train_loss=0.56528  val_loss=0.59139 | train_MAE=0.6959  val_MAE=0.6957 | lr=0.0005 | time=0.09s\n",
      "Epoch 131 | train_loss=0.56077  val_loss=0.59283 | train_MAE=0.7146  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 132 | train_loss=0.57285  val_loss=0.59283 | train_MAE=0.6922  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 133 | train_loss=0.57204  val_loss=0.59015 | train_MAE=0.6754  val_MAE=0.7130 | lr=0.0005 | time=0.09s\n",
      "Epoch 134 | train_loss=0.58563  val_loss=0.59162 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 135 | train_loss=0.55271  val_loss=0.59416 | train_MAE=0.7369  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 136 | train_loss=0.56254  val_loss=0.59530 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 137 | train_loss=0.54987  val_loss=0.60181 | train_MAE=0.7108  val_MAE=0.6870 | lr=0.0005 | time=0.08s\n",
      "Epoch 138 | train_loss=0.56740  val_loss=0.60011 | train_MAE=0.7015  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 139 | train_loss=0.55816  val_loss=0.59754 | train_MAE=0.7146  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 140 | train_loss=0.56390  val_loss=0.59886 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 141 | train_loss=0.56307  val_loss=0.59570 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 142 | train_loss=0.55880  val_loss=0.59745 | train_MAE=0.7164  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 143 | train_loss=0.54920  val_loss=0.59435 | train_MAE=0.7351  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 144 | train_loss=0.55626  val_loss=0.59602 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 145 | train_loss=0.55986  val_loss=0.59665 | train_MAE=0.7127  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 146 | train_loss=0.57282  val_loss=0.59873 | train_MAE=0.6959  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 147 | train_loss=0.55706  val_loss=0.59357 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 148 | train_loss=0.56081  val_loss=0.59511 | train_MAE=0.6791  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 149 | train_loss=0.56048  val_loss=0.59841 | train_MAE=0.7164  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 150 | train_loss=0.55216  val_loss=0.59825 | train_MAE=0.6978  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 151 | train_loss=0.55321  val_loss=0.60040 | train_MAE=0.6959  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 152 | train_loss=0.55790  val_loss=0.60023 | train_MAE=0.7071  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 153 | train_loss=0.56179  val_loss=0.60394 | train_MAE=0.7164  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 154 | train_loss=0.55532  val_loss=0.59989 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 155 | train_loss=0.54508  val_loss=0.60319 | train_MAE=0.7146  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 156 | train_loss=0.56285  val_loss=0.60266 | train_MAE=0.7052  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 157 | train_loss=0.55696  val_loss=0.59917 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 158 | train_loss=0.55899  val_loss=0.59943 | train_MAE=0.6884  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 159 | train_loss=0.57105  val_loss=0.59739 | train_MAE=0.6996  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 160 | train_loss=0.55381  val_loss=0.60282 | train_MAE=0.7015  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 161 | train_loss=0.56383  val_loss=0.59916 | train_MAE=0.7015  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 162 | train_loss=0.55770  val_loss=0.60532 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 163 | train_loss=0.56666  val_loss=0.60367 | train_MAE=0.7034  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 164 | train_loss=0.56063  val_loss=0.60138 | train_MAE=0.7146  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 165 | train_loss=0.54659  val_loss=0.59873 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 166 | train_loss=0.55723  val_loss=0.59638 | train_MAE=0.6940  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 167 | train_loss=0.55582  val_loss=0.59634 | train_MAE=0.7146  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 168 | train_loss=0.56042  val_loss=0.59746 | train_MAE=0.7220  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 169 | train_loss=0.55001  val_loss=0.59953 | train_MAE=0.7164  val_MAE=0.7043 | lr=0.0005 | time=0.09s\n",
      "Epoch 170 | train_loss=0.55338  val_loss=0.60136 | train_MAE=0.7127  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 171 | train_loss=0.56851  val_loss=0.60228 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 172 | train_loss=0.55627  val_loss=0.60014 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 173 | train_loss=0.55264  val_loss=0.59889 | train_MAE=0.7034  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 174 | train_loss=0.55563  val_loss=0.59465 | train_MAE=0.6922  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 175 | train_loss=0.55437  val_loss=0.59762 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 176 | train_loss=0.54567  val_loss=0.60248 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 177 | train_loss=0.55831  val_loss=0.59324 | train_MAE=0.7071  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 178 | train_loss=0.54834  val_loss=0.59583 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.0005 | time=0.08s\n",
      "Epoch 179 | train_loss=0.56482  val_loss=0.59644 | train_MAE=0.6847  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 180 | train_loss=0.56203  val_loss=0.59418 | train_MAE=0.6791  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 181 | train_loss=0.55539  val_loss=0.59140 | train_MAE=0.7071  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 182 | train_loss=0.56109  val_loss=0.59465 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 183 | train_loss=0.55945  val_loss=0.59829 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 184 | train_loss=0.55840  val_loss=0.59694 | train_MAE=0.7146  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 185 | train_loss=0.56732  val_loss=0.59544 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 186 | train_loss=0.55208  val_loss=0.59457 | train_MAE=0.7146  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 187 | train_loss=0.55869  val_loss=0.59327 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.0005 | time=0.08s\n",
      "Epoch 188 | train_loss=0.54537  val_loss=0.59165 | train_MAE=0.7108  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 189 | train_loss=0.57229  val_loss=0.59384 | train_MAE=0.6922  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 190 | train_loss=0.54427  val_loss=0.59673 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 191 | train_loss=0.54677  val_loss=0.59838 | train_MAE=0.7164  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 192 | train_loss=0.54523  val_loss=0.59768 | train_MAE=0.7351  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 193 | train_loss=0.55639  val_loss=0.60252 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 194 | train_loss=0.55811  val_loss=0.60336 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.0005 | time=0.10s\n",
      "Epoch 195 | train_loss=0.55083  val_loss=0.60314 | train_MAE=0.7052  val_MAE=0.6957 | lr=0.0005 | time=0.18s\n",
      "Epoch 196 | train_loss=0.55218  val_loss=0.59814 | train_MAE=0.7108  val_MAE=0.6870 | lr=0.0005 | time=0.13s\n",
      "Epoch 197 | train_loss=0.54786  val_loss=0.60066 | train_MAE=0.7127  val_MAE=0.7043 | lr=0.0005 | time=0.08s\n",
      "Epoch 198 | train_loss=0.54397  val_loss=0.60315 | train_MAE=0.7332  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 199 | train_loss=0.55406  val_loss=0.59976 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Epoch 200 | train_loss=0.53576  val_loss=0.60031 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.0005 | time=0.08s\n",
      "Total training time: 16.45s\n",
      "Test Accuracy: 0.6087\n",
      "\n",
      "Training with learning_rate=0.001\n",
      "Epoch 001 | train_loss=1.28202  val_loss=0.85798 | train_MAE=0.5299  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 002 | train_loss=0.90654  val_loss=0.65869 | train_MAE=0.5728  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 003 | train_loss=0.90134  val_loss=0.64154 | train_MAE=0.5224  val_MAE=0.6783 | lr=0.001 | time=0.09s\n",
      "Epoch 004 | train_loss=0.76780  val_loss=0.63698 | train_MAE=0.5709  val_MAE=0.6696 | lr=0.001 | time=0.09s\n",
      "Epoch 005 | train_loss=0.75156  val_loss=0.62859 | train_MAE=0.5653  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 006 | train_loss=0.69171  val_loss=0.62542 | train_MAE=0.6325  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 007 | train_loss=0.66356  val_loss=0.62262 | train_MAE=0.6343  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 008 | train_loss=0.68411  val_loss=0.62196 | train_MAE=0.5970  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 009 | train_loss=0.66494  val_loss=0.61556 | train_MAE=0.6362  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 010 | train_loss=0.66970  val_loss=0.62195 | train_MAE=0.6511  val_MAE=0.6261 | lr=0.001 | time=0.08s\n",
      "Epoch 011 | train_loss=0.65033  val_loss=0.61240 | train_MAE=0.6381  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 012 | train_loss=0.63091  val_loss=0.60424 | train_MAE=0.6455  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 013 | train_loss=0.65454  val_loss=0.58914 | train_MAE=0.6343  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 014 | train_loss=0.63707  val_loss=0.59099 | train_MAE=0.6325  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 015 | train_loss=0.62925  val_loss=0.59005 | train_MAE=0.6493  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 016 | train_loss=0.62096  val_loss=0.58924 | train_MAE=0.6679  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 017 | train_loss=0.63386  val_loss=0.59236 | train_MAE=0.6455  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 018 | train_loss=0.64734  val_loss=0.59330 | train_MAE=0.6418  val_MAE=0.6435 | lr=0.001 | time=0.08s\n",
      "Epoch 019 | train_loss=0.63822  val_loss=0.59211 | train_MAE=0.6586  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 020 | train_loss=0.62108  val_loss=0.59356 | train_MAE=0.6754  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 021 | train_loss=0.65073  val_loss=0.60275 | train_MAE=0.6511  val_MAE=0.6435 | lr=0.001 | time=0.08s\n",
      "Epoch 022 | train_loss=0.63730  val_loss=0.59558 | train_MAE=0.6474  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 023 | train_loss=0.62083  val_loss=0.59117 | train_MAE=0.6567  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 024 | train_loss=0.60652  val_loss=0.58743 | train_MAE=0.6754  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 025 | train_loss=0.61579  val_loss=0.58745 | train_MAE=0.6530  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 026 | train_loss=0.61990  val_loss=0.59199 | train_MAE=0.6549  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 027 | train_loss=0.62042  val_loss=0.59499 | train_MAE=0.6511  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 028 | train_loss=0.60724  val_loss=0.59141 | train_MAE=0.6399  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 029 | train_loss=0.61369  val_loss=0.59098 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 030 | train_loss=0.57914  val_loss=0.59834 | train_MAE=0.6922  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 031 | train_loss=0.60274  val_loss=0.59502 | train_MAE=0.6642  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 032 | train_loss=0.61762  val_loss=0.59517 | train_MAE=0.6716  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 033 | train_loss=0.60141  val_loss=0.59577 | train_MAE=0.6716  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 034 | train_loss=0.59250  val_loss=0.59686 | train_MAE=0.6698  val_MAE=0.6870 | lr=0.001 | time=0.16s\n",
      "Epoch 035 | train_loss=0.58163  val_loss=0.59886 | train_MAE=0.6884  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 036 | train_loss=0.59775  val_loss=0.60630 | train_MAE=0.6772  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 037 | train_loss=0.61379  val_loss=0.60143 | train_MAE=0.6586  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 038 | train_loss=0.61056  val_loss=0.59642 | train_MAE=0.6679  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 039 | train_loss=0.58268  val_loss=0.59448 | train_MAE=0.6866  val_MAE=0.7391 | lr=0.001 | time=0.08s\n",
      "Epoch 040 | train_loss=0.59703  val_loss=0.59312 | train_MAE=0.6679  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 041 | train_loss=0.59357  val_loss=0.58935 | train_MAE=0.6828  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 042 | train_loss=0.60588  val_loss=0.58375 | train_MAE=0.6847  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 043 | train_loss=0.59585  val_loss=0.58753 | train_MAE=0.6642  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 044 | train_loss=0.60933  val_loss=0.58968 | train_MAE=0.6586  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 045 | train_loss=0.58542  val_loss=0.58905 | train_MAE=0.6772  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 046 | train_loss=0.60450  val_loss=0.58783 | train_MAE=0.6716  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 047 | train_loss=0.57859  val_loss=0.58895 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.001 | time=0.09s\n",
      "Epoch 048 | train_loss=0.59987  val_loss=0.59063 | train_MAE=0.6847  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 049 | train_loss=0.57053  val_loss=0.58445 | train_MAE=0.7015  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 050 | train_loss=0.59486  val_loss=0.58314 | train_MAE=0.6754  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 051 | train_loss=0.59589  val_loss=0.58456 | train_MAE=0.6754  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 052 | train_loss=0.60168  val_loss=0.58955 | train_MAE=0.6660  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 053 | train_loss=0.59647  val_loss=0.58708 | train_MAE=0.6642  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 054 | train_loss=0.57135  val_loss=0.58342 | train_MAE=0.6716  val_MAE=0.7043 | lr=0.001 | time=0.09s\n",
      "Epoch 055 | train_loss=0.57614  val_loss=0.58675 | train_MAE=0.6978  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 056 | train_loss=0.59518  val_loss=0.58877 | train_MAE=0.6810  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 057 | train_loss=0.57097  val_loss=0.58287 | train_MAE=0.6922  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 058 | train_loss=0.58663  val_loss=0.57889 | train_MAE=0.6959  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 059 | train_loss=0.58190  val_loss=0.58082 | train_MAE=0.6959  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 060 | train_loss=0.60021  val_loss=0.58512 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 061 | train_loss=0.59070  val_loss=0.58503 | train_MAE=0.6754  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 062 | train_loss=0.58558  val_loss=0.57883 | train_MAE=0.6828  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 063 | train_loss=0.58534  val_loss=0.58468 | train_MAE=0.7071  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 064 | train_loss=0.58956  val_loss=0.58020 | train_MAE=0.6828  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 065 | train_loss=0.58773  val_loss=0.57959 | train_MAE=0.6716  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 066 | train_loss=0.56544  val_loss=0.58498 | train_MAE=0.7183  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 067 | train_loss=0.58120  val_loss=0.58793 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 068 | train_loss=0.56975  val_loss=0.58941 | train_MAE=0.7146  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 069 | train_loss=0.57760  val_loss=0.58514 | train_MAE=0.7052  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 070 | train_loss=0.57386  val_loss=0.58389 | train_MAE=0.7108  val_MAE=0.6522 | lr=0.001 | time=0.08s\n",
      "Epoch 071 | train_loss=0.56462  val_loss=0.58773 | train_MAE=0.7071  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 072 | train_loss=0.57150  val_loss=0.58352 | train_MAE=0.6922  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 073 | train_loss=0.57195  val_loss=0.58007 | train_MAE=0.7090  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 074 | train_loss=0.55952  val_loss=0.58373 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 075 | train_loss=0.56247  val_loss=0.58076 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 076 | train_loss=0.57375  val_loss=0.57857 | train_MAE=0.6623  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 077 | train_loss=0.57896  val_loss=0.58037 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 078 | train_loss=0.56799  val_loss=0.57999 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 079 | train_loss=0.57048  val_loss=0.57817 | train_MAE=0.7071  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 080 | train_loss=0.57965  val_loss=0.57468 | train_MAE=0.6884  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 081 | train_loss=0.57090  val_loss=0.58369 | train_MAE=0.6903  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 082 | train_loss=0.56177  val_loss=0.58250 | train_MAE=0.7295  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 083 | train_loss=0.56084  val_loss=0.58045 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 084 | train_loss=0.56611  val_loss=0.58048 | train_MAE=0.7052  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 085 | train_loss=0.56042  val_loss=0.58188 | train_MAE=0.7201  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 086 | train_loss=0.55256  val_loss=0.58639 | train_MAE=0.7369  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 087 | train_loss=0.55974  val_loss=0.58568 | train_MAE=0.7127  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 088 | train_loss=0.56477  val_loss=0.58146 | train_MAE=0.7183  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 089 | train_loss=0.55336  val_loss=0.58336 | train_MAE=0.6922  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 090 | train_loss=0.56719  val_loss=0.58189 | train_MAE=0.6903  val_MAE=0.6609 | lr=0.001 | time=0.08s\n",
      "Epoch 091 | train_loss=0.55739  val_loss=0.59256 | train_MAE=0.7052  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 092 | train_loss=0.57839  val_loss=0.58449 | train_MAE=0.6903  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 093 | train_loss=0.55797  val_loss=0.58124 | train_MAE=0.7164  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 094 | train_loss=0.55106  val_loss=0.58627 | train_MAE=0.7052  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 095 | train_loss=0.56577  val_loss=0.59372 | train_MAE=0.7015  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 096 | train_loss=0.58792  val_loss=0.58197 | train_MAE=0.7090  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 097 | train_loss=0.55519  val_loss=0.58286 | train_MAE=0.7164  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 098 | train_loss=0.54474  val_loss=0.59195 | train_MAE=0.7164  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 099 | train_loss=0.54304  val_loss=0.58447 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 100 | train_loss=0.55337  val_loss=0.58215 | train_MAE=0.7052  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 101 | train_loss=0.54603  val_loss=0.58401 | train_MAE=0.7295  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 102 | train_loss=0.55521  val_loss=0.58999 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 103 | train_loss=0.54839  val_loss=0.58901 | train_MAE=0.7146  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 104 | train_loss=0.55430  val_loss=0.59411 | train_MAE=0.7164  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 105 | train_loss=0.55178  val_loss=0.58972 | train_MAE=0.7220  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 106 | train_loss=0.56108  val_loss=0.58184 | train_MAE=0.7071  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 107 | train_loss=0.56441  val_loss=0.58232 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 108 | train_loss=0.55680  val_loss=0.58838 | train_MAE=0.7239  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 109 | train_loss=0.55649  val_loss=0.58726 | train_MAE=0.7201  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 110 | train_loss=0.54823  val_loss=0.58526 | train_MAE=0.7313  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 111 | train_loss=0.55319  val_loss=0.58112 | train_MAE=0.7295  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 112 | train_loss=0.55436  val_loss=0.57800 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 113 | train_loss=0.56003  val_loss=0.58116 | train_MAE=0.7164  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 114 | train_loss=0.55723  val_loss=0.59450 | train_MAE=0.7164  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 115 | train_loss=0.54887  val_loss=0.58503 | train_MAE=0.7183  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 116 | train_loss=0.53906  val_loss=0.58395 | train_MAE=0.7239  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 117 | train_loss=0.54215  val_loss=0.58412 | train_MAE=0.7257  val_MAE=0.7043 | lr=0.001 | time=0.09s\n",
      "Epoch 118 | train_loss=0.57615  val_loss=0.58298 | train_MAE=0.6940  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 119 | train_loss=0.54811  val_loss=0.57654 | train_MAE=0.7295  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 120 | train_loss=0.55117  val_loss=0.57284 | train_MAE=0.7257  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 121 | train_loss=0.54660  val_loss=0.57586 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 122 | train_loss=0.55185  val_loss=0.58093 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 123 | train_loss=0.53655  val_loss=0.57561 | train_MAE=0.7295  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 124 | train_loss=0.52874  val_loss=0.58334 | train_MAE=0.7332  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 125 | train_loss=0.54812  val_loss=0.57907 | train_MAE=0.7276  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 126 | train_loss=0.53662  val_loss=0.57666 | train_MAE=0.7388  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 127 | train_loss=0.54014  val_loss=0.57904 | train_MAE=0.7071  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 128 | train_loss=0.54091  val_loss=0.58806 | train_MAE=0.7146  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 129 | train_loss=0.53336  val_loss=0.59079 | train_MAE=0.7257  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 130 | train_loss=0.53286  val_loss=0.60291 | train_MAE=0.7351  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 131 | train_loss=0.53814  val_loss=0.59300 | train_MAE=0.7052  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 132 | train_loss=0.53562  val_loss=0.58590 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 133 | train_loss=0.53064  val_loss=0.58187 | train_MAE=0.7407  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 134 | train_loss=0.53253  val_loss=0.58372 | train_MAE=0.7276  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 135 | train_loss=0.54802  val_loss=0.58297 | train_MAE=0.7276  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 136 | train_loss=0.53153  val_loss=0.58543 | train_MAE=0.7444  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 137 | train_loss=0.52047  val_loss=0.57666 | train_MAE=0.7407  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 138 | train_loss=0.52221  val_loss=0.57646 | train_MAE=0.7425  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 139 | train_loss=0.53767  val_loss=0.58188 | train_MAE=0.7351  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 140 | train_loss=0.53042  val_loss=0.58587 | train_MAE=0.7257  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 141 | train_loss=0.53270  val_loss=0.58165 | train_MAE=0.7444  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 142 | train_loss=0.54047  val_loss=0.58415 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 143 | train_loss=0.52834  val_loss=0.58107 | train_MAE=0.7257  val_MAE=0.6783 | lr=0.001 | time=0.09s\n",
      "Epoch 144 | train_loss=0.53919  val_loss=0.58892 | train_MAE=0.7220  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 145 | train_loss=0.54453  val_loss=0.58577 | train_MAE=0.7220  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 146 | train_loss=0.53899  val_loss=0.58334 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 147 | train_loss=0.53923  val_loss=0.58024 | train_MAE=0.7332  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 148 | train_loss=0.53253  val_loss=0.58971 | train_MAE=0.7183  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 149 | train_loss=0.53248  val_loss=0.58952 | train_MAE=0.7201  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 150 | train_loss=0.53831  val_loss=0.58082 | train_MAE=0.7220  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 151 | train_loss=0.52507  val_loss=0.58806 | train_MAE=0.7481  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 152 | train_loss=0.52598  val_loss=0.59206 | train_MAE=0.7388  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 153 | train_loss=0.52507  val_loss=0.59228 | train_MAE=0.7407  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 154 | train_loss=0.53295  val_loss=0.58637 | train_MAE=0.7071  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 155 | train_loss=0.53220  val_loss=0.58290 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 156 | train_loss=0.52556  val_loss=0.58487 | train_MAE=0.7276  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 157 | train_loss=0.53939  val_loss=0.58429 | train_MAE=0.7332  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 158 | train_loss=0.52156  val_loss=0.58190 | train_MAE=0.7351  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 159 | train_loss=0.52830  val_loss=0.58929 | train_MAE=0.7071  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 160 | train_loss=0.53692  val_loss=0.58751 | train_MAE=0.7295  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 161 | train_loss=0.51585  val_loss=0.59351 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 162 | train_loss=0.54611  val_loss=0.59097 | train_MAE=0.7295  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 163 | train_loss=0.52701  val_loss=0.59153 | train_MAE=0.7332  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 164 | train_loss=0.51969  val_loss=0.57817 | train_MAE=0.7351  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 165 | train_loss=0.51983  val_loss=0.57859 | train_MAE=0.7444  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 166 | train_loss=0.52402  val_loss=0.58706 | train_MAE=0.7239  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 167 | train_loss=0.53068  val_loss=0.58582 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 168 | train_loss=0.52319  val_loss=0.58439 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.001 | time=0.08s\n",
      "Epoch 169 | train_loss=0.52325  val_loss=0.58726 | train_MAE=0.7388  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 170 | train_loss=0.51720  val_loss=0.58462 | train_MAE=0.7351  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 171 | train_loss=0.51512  val_loss=0.59436 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 172 | train_loss=0.54078  val_loss=0.60727 | train_MAE=0.7369  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 173 | train_loss=0.51244  val_loss=0.59689 | train_MAE=0.7425  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 174 | train_loss=0.50326  val_loss=0.59669 | train_MAE=0.7332  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 175 | train_loss=0.50852  val_loss=0.61136 | train_MAE=0.7351  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 176 | train_loss=0.51520  val_loss=0.61300 | train_MAE=0.7295  val_MAE=0.6783 | lr=0.001 | time=0.08s\n",
      "Epoch 177 | train_loss=0.52474  val_loss=0.60033 | train_MAE=0.7332  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 178 | train_loss=0.51565  val_loss=0.61171 | train_MAE=0.7537  val_MAE=0.6696 | lr=0.001 | time=0.08s\n",
      "Epoch 179 | train_loss=0.53156  val_loss=0.60664 | train_MAE=0.7071  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 180 | train_loss=0.50824  val_loss=0.58979 | train_MAE=0.7332  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 181 | train_loss=0.52701  val_loss=0.60113 | train_MAE=0.7313  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 182 | train_loss=0.52407  val_loss=0.60074 | train_MAE=0.7481  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 183 | train_loss=0.51899  val_loss=0.59811 | train_MAE=0.7407  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 184 | train_loss=0.51346  val_loss=0.60232 | train_MAE=0.7519  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 185 | train_loss=0.51406  val_loss=0.60447 | train_MAE=0.7425  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 186 | train_loss=0.51813  val_loss=0.60622 | train_MAE=0.7220  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 187 | train_loss=0.51374  val_loss=0.61052 | train_MAE=0.7369  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 188 | train_loss=0.51199  val_loss=0.59361 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.001 | time=0.08s\n",
      "Epoch 189 | train_loss=0.51462  val_loss=0.60271 | train_MAE=0.7332  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 190 | train_loss=0.51436  val_loss=0.62656 | train_MAE=0.7537  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 191 | train_loss=0.51094  val_loss=0.60658 | train_MAE=0.7407  val_MAE=0.7217 | lr=0.001 | time=0.08s\n",
      "Epoch 192 | train_loss=0.50493  val_loss=0.61884 | train_MAE=0.7593  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 193 | train_loss=0.51534  val_loss=0.62512 | train_MAE=0.7463  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 194 | train_loss=0.50890  val_loss=0.60658 | train_MAE=0.7201  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Epoch 195 | train_loss=0.50696  val_loss=0.61900 | train_MAE=0.7519  val_MAE=0.7043 | lr=0.001 | time=0.08s\n",
      "Epoch 196 | train_loss=0.51440  val_loss=0.61644 | train_MAE=0.7537  val_MAE=0.6870 | lr=0.001 | time=0.07s\n",
      "Epoch 197 | train_loss=0.51554  val_loss=0.60886 | train_MAE=0.7295  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 198 | train_loss=0.49427  val_loss=0.62420 | train_MAE=0.7612  val_MAE=0.7217 | lr=0.001 | time=0.07s\n",
      "Epoch 199 | train_loss=0.49531  val_loss=0.62733 | train_MAE=0.7575  val_MAE=0.6870 | lr=0.001 | time=0.08s\n",
      "Epoch 200 | train_loss=0.51727  val_loss=0.61663 | train_MAE=0.7687  val_MAE=0.6957 | lr=0.001 | time=0.08s\n",
      "Total training time: 16.24s\n",
      "Test Accuracy: 0.6000\n",
      "\n",
      "Training with learning_rate=0.005\n",
      "Epoch 001 | train_loss=1.28305  val_loss=0.86943 | train_MAE=0.5541  val_MAE=0.3739 | lr=0.005 | time=0.08s\n",
      "Epoch 002 | train_loss=0.83085  val_loss=0.64302 | train_MAE=0.5336  val_MAE=0.6783 | lr=0.005 | time=0.08s\n",
      "Epoch 003 | train_loss=0.67886  val_loss=0.62355 | train_MAE=0.6269  val_MAE=0.6870 | lr=0.005 | time=0.08s\n",
      "Epoch 004 | train_loss=0.66428  val_loss=0.63472 | train_MAE=0.6437  val_MAE=0.6870 | lr=0.005 | time=0.08s\n",
      "Epoch 005 | train_loss=0.65146  val_loss=0.62639 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 006 | train_loss=0.62655  val_loss=0.60230 | train_MAE=0.6511  val_MAE=0.6870 | lr=0.005 | time=0.08s\n",
      "Epoch 007 | train_loss=0.64876  val_loss=0.59800 | train_MAE=0.6287  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 008 | train_loss=0.62343  val_loss=0.59910 | train_MAE=0.6660  val_MAE=0.6957 | lr=0.005 | time=0.08s\n",
      "Epoch 009 | train_loss=0.61381  val_loss=0.59950 | train_MAE=0.6716  val_MAE=0.6783 | lr=0.005 | time=0.08s\n",
      "Epoch 010 | train_loss=0.60679  val_loss=0.58906 | train_MAE=0.6698  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 011 | train_loss=0.63000  val_loss=0.59939 | train_MAE=0.6567  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 012 | train_loss=0.62200  val_loss=0.60159 | train_MAE=0.6362  val_MAE=0.6957 | lr=0.005 | time=0.08s\n",
      "Epoch 013 | train_loss=0.63000  val_loss=0.59770 | train_MAE=0.6549  val_MAE=0.6696 | lr=0.005 | time=0.08s\n",
      "Epoch 014 | train_loss=0.60554  val_loss=0.59452 | train_MAE=0.6679  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 015 | train_loss=0.61452  val_loss=0.59508 | train_MAE=0.6698  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 016 | train_loss=0.59930  val_loss=0.59454 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 017 | train_loss=0.59549  val_loss=0.58811 | train_MAE=0.6922  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 018 | train_loss=0.59297  val_loss=0.58367 | train_MAE=0.6735  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 019 | train_loss=0.58816  val_loss=0.58536 | train_MAE=0.6791  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 020 | train_loss=0.60960  val_loss=0.58141 | train_MAE=0.6735  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 021 | train_loss=0.59809  val_loss=0.59774 | train_MAE=0.6716  val_MAE=0.6957 | lr=0.005 | time=0.09s\n",
      "Epoch 022 | train_loss=0.60020  val_loss=0.58103 | train_MAE=0.7108  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 023 | train_loss=0.58009  val_loss=0.57624 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 024 | train_loss=0.59373  val_loss=0.57851 | train_MAE=0.6959  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 025 | train_loss=0.58766  val_loss=0.57756 | train_MAE=0.6847  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 026 | train_loss=0.57760  val_loss=0.57272 | train_MAE=0.6903  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 027 | train_loss=0.57688  val_loss=0.57020 | train_MAE=0.6754  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 028 | train_loss=0.58179  val_loss=0.58003 | train_MAE=0.6996  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 029 | train_loss=0.57539  val_loss=0.57879 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 030 | train_loss=0.57380  val_loss=0.57802 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 031 | train_loss=0.57890  val_loss=0.57453 | train_MAE=0.6754  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 032 | train_loss=0.58798  val_loss=0.57095 | train_MAE=0.6884  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 033 | train_loss=0.57059  val_loss=0.56915 | train_MAE=0.7090  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 034 | train_loss=0.57288  val_loss=0.57274 | train_MAE=0.7295  val_MAE=0.7478 | lr=0.005 | time=0.08s\n",
      "Epoch 035 | train_loss=0.58908  val_loss=0.57987 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 036 | train_loss=0.56707  val_loss=0.57160 | train_MAE=0.6903  val_MAE=0.7304 | lr=0.005 | time=0.09s\n",
      "Epoch 037 | train_loss=0.55301  val_loss=0.60238 | train_MAE=0.7127  val_MAE=0.7391 | lr=0.005 | time=0.15s\n",
      "Epoch 038 | train_loss=0.56959  val_loss=0.57867 | train_MAE=0.6978  val_MAE=0.7478 | lr=0.005 | time=0.08s\n",
      "Epoch 039 | train_loss=0.54779  val_loss=0.57873 | train_MAE=0.7164  val_MAE=0.6870 | lr=0.005 | time=0.08s\n",
      "Epoch 040 | train_loss=0.58140  val_loss=0.59180 | train_MAE=0.6940  val_MAE=0.6957 | lr=0.005 | time=0.08s\n",
      "Epoch 041 | train_loss=0.58002  val_loss=0.58692 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 042 | train_loss=0.56747  val_loss=0.58049 | train_MAE=0.7127  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 043 | train_loss=0.57151  val_loss=0.58073 | train_MAE=0.6810  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 044 | train_loss=0.55661  val_loss=0.56828 | train_MAE=0.7090  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 045 | train_loss=0.55869  val_loss=0.56474 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 046 | train_loss=0.55289  val_loss=0.57926 | train_MAE=0.7071  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 047 | train_loss=0.54654  val_loss=0.59288 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 048 | train_loss=0.55893  val_loss=0.58678 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 049 | train_loss=0.54423  val_loss=0.57770 | train_MAE=0.7090  val_MAE=0.6957 | lr=0.005 | time=0.08s\n",
      "Epoch 050 | train_loss=0.54818  val_loss=0.57602 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 051 | train_loss=0.55686  val_loss=0.57337 | train_MAE=0.6903  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 052 | train_loss=0.55556  val_loss=0.56696 | train_MAE=0.6959  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 053 | train_loss=0.55021  val_loss=0.57675 | train_MAE=0.7090  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 054 | train_loss=0.53795  val_loss=0.57827 | train_MAE=0.7164  val_MAE=0.7478 | lr=0.005 | time=0.08s\n",
      "Epoch 055 | train_loss=0.54845  val_loss=0.57519 | train_MAE=0.6940  val_MAE=0.7478 | lr=0.005 | time=0.08s\n",
      "Epoch 056 | train_loss=0.55188  val_loss=0.58649 | train_MAE=0.6791  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 057 | train_loss=0.53403  val_loss=0.58224 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 058 | train_loss=0.54841  val_loss=0.57779 | train_MAE=0.7052  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 059 | train_loss=0.54674  val_loss=0.59107 | train_MAE=0.7388  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 060 | train_loss=0.54806  val_loss=0.57591 | train_MAE=0.7108  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 061 | train_loss=0.55406  val_loss=0.58517 | train_MAE=0.7090  val_MAE=0.7739 | lr=0.005 | time=0.08s\n",
      "Epoch 062 | train_loss=0.54231  val_loss=0.57032 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 063 | train_loss=0.55816  val_loss=0.57525 | train_MAE=0.6978  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 064 | train_loss=0.54984  val_loss=0.56896 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 065 | train_loss=0.53259  val_loss=0.57249 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 066 | train_loss=0.55274  val_loss=0.56961 | train_MAE=0.7425  val_MAE=0.7565 | lr=0.005 | time=0.08s\n",
      "Epoch 067 | train_loss=0.53225  val_loss=0.57757 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 068 | train_loss=0.53305  val_loss=0.59577 | train_MAE=0.7332  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 069 | train_loss=0.54396  val_loss=0.60148 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 070 | train_loss=0.54614  val_loss=0.57604 | train_MAE=0.7052  val_MAE=0.6783 | lr=0.005 | time=0.08s\n",
      "Epoch 071 | train_loss=0.54126  val_loss=0.57325 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 072 | train_loss=0.53537  val_loss=0.58528 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 073 | train_loss=0.53681  val_loss=0.58729 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 074 | train_loss=0.54748  val_loss=0.58991 | train_MAE=0.7034  val_MAE=0.7739 | lr=0.005 | time=0.08s\n",
      "Epoch 075 | train_loss=0.53833  val_loss=0.58800 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 076 | train_loss=0.53092  val_loss=0.61034 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 077 | train_loss=0.53789  val_loss=0.59078 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 078 | train_loss=0.53327  val_loss=0.56673 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 079 | train_loss=0.53404  val_loss=0.56786 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 080 | train_loss=0.54460  val_loss=0.57162 | train_MAE=0.7015  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 081 | train_loss=0.54029  val_loss=0.59419 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 082 | train_loss=0.53829  val_loss=0.57137 | train_MAE=0.7108  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 083 | train_loss=0.52656  val_loss=0.57845 | train_MAE=0.7127  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 084 | train_loss=0.52258  val_loss=0.59755 | train_MAE=0.7220  val_MAE=0.7652 | lr=0.005 | time=0.08s\n",
      "Epoch 085 | train_loss=0.55368  val_loss=0.57675 | train_MAE=0.6884  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 086 | train_loss=0.52913  val_loss=0.56514 | train_MAE=0.7351  val_MAE=0.7565 | lr=0.005 | time=0.08s\n",
      "Epoch 087 | train_loss=0.52095  val_loss=0.57567 | train_MAE=0.7239  val_MAE=0.7478 | lr=0.005 | time=0.07s\n",
      "Epoch 088 | train_loss=0.53562  val_loss=0.59136 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 089 | train_loss=0.53568  val_loss=0.58404 | train_MAE=0.7052  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 090 | train_loss=0.52872  val_loss=0.58284 | train_MAE=0.7351  val_MAE=0.7478 | lr=0.005 | time=0.08s\n",
      "Epoch 091 | train_loss=0.52141  val_loss=0.56871 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 092 | train_loss=0.51801  val_loss=0.59463 | train_MAE=0.7332  val_MAE=0.7565 | lr=0.005 | time=0.08s\n",
      "Epoch 093 | train_loss=0.53676  val_loss=0.57478 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 094 | train_loss=0.54487  val_loss=0.56609 | train_MAE=0.7257  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 095 | train_loss=0.54349  val_loss=0.57091 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 096 | train_loss=0.54024  val_loss=0.57073 | train_MAE=0.7295  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 097 | train_loss=0.54864  val_loss=0.57745 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 098 | train_loss=0.52736  val_loss=0.56779 | train_MAE=0.7146  val_MAE=0.7565 | lr=0.005 | time=0.08s\n",
      "Epoch 099 | train_loss=0.52017  val_loss=0.59030 | train_MAE=0.7481  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 100 | train_loss=0.53984  val_loss=0.57694 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 101 | train_loss=0.51775  val_loss=0.58705 | train_MAE=0.7388  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 102 | train_loss=0.51997  val_loss=0.57996 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 103 | train_loss=0.54910  val_loss=0.57258 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 104 | train_loss=0.53207  val_loss=0.56883 | train_MAE=0.6996  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 105 | train_loss=0.52657  val_loss=0.57983 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 106 | train_loss=0.51950  val_loss=0.57422 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 107 | train_loss=0.54398  val_loss=0.59631 | train_MAE=0.6996  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 108 | train_loss=0.53062  val_loss=0.58647 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 109 | train_loss=0.51934  val_loss=0.57078 | train_MAE=0.7388  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 110 | train_loss=0.52662  val_loss=0.57556 | train_MAE=0.7295  val_MAE=0.7478 | lr=0.005 | time=0.07s\n",
      "Epoch 111 | train_loss=0.52440  val_loss=0.57941 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 112 | train_loss=0.49875  val_loss=0.59598 | train_MAE=0.7481  val_MAE=0.7478 | lr=0.005 | time=0.09s\n",
      "Epoch 113 | train_loss=0.52995  val_loss=0.58386 | train_MAE=0.7332  val_MAE=0.7478 | lr=0.005 | time=0.08s\n",
      "Epoch 114 | train_loss=0.52936  val_loss=0.58951 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 115 | train_loss=0.51719  val_loss=0.58537 | train_MAE=0.7369  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 116 | train_loss=0.52441  val_loss=0.58794 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 117 | train_loss=0.52086  val_loss=0.57027 | train_MAE=0.7407  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 118 | train_loss=0.52708  val_loss=0.58679 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 119 | train_loss=0.51511  val_loss=0.58978 | train_MAE=0.7276  val_MAE=0.7478 | lr=0.005 | time=0.08s\n",
      "Epoch 120 | train_loss=0.49211  val_loss=0.60318 | train_MAE=0.7481  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 121 | train_loss=0.51796  val_loss=0.57549 | train_MAE=0.7332  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 122 | train_loss=0.50504  val_loss=0.56358 | train_MAE=0.7500  val_MAE=0.7652 | lr=0.005 | time=0.08s\n",
      "Epoch 123 | train_loss=0.51047  val_loss=0.56973 | train_MAE=0.7425  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 124 | train_loss=0.52710  val_loss=0.56588 | train_MAE=0.7276  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 125 | train_loss=0.53070  val_loss=0.58268 | train_MAE=0.7146  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 126 | train_loss=0.50704  val_loss=0.58312 | train_MAE=0.7146  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 127 | train_loss=0.52041  val_loss=0.59768 | train_MAE=0.7164  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 128 | train_loss=0.51088  val_loss=0.61273 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 129 | train_loss=0.52285  val_loss=0.58268 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 130 | train_loss=0.51583  val_loss=0.58680 | train_MAE=0.7351  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 131 | train_loss=0.52554  val_loss=0.57058 | train_MAE=0.7146  val_MAE=0.7478 | lr=0.005 | time=0.08s\n",
      "Epoch 132 | train_loss=0.53080  val_loss=0.57827 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 133 | train_loss=0.51020  val_loss=0.58768 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 134 | train_loss=0.50211  val_loss=0.59534 | train_MAE=0.7481  val_MAE=0.6870 | lr=0.005 | time=0.08s\n",
      "Epoch 135 | train_loss=0.52789  val_loss=0.59519 | train_MAE=0.7201  val_MAE=0.6870 | lr=0.005 | time=0.08s\n",
      "Epoch 136 | train_loss=0.52295  val_loss=0.59596 | train_MAE=0.7201  val_MAE=0.7652 | lr=0.005 | time=0.08s\n",
      "Epoch 137 | train_loss=0.51186  val_loss=0.61252 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 138 | train_loss=0.51344  val_loss=0.60565 | train_MAE=0.7519  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 139 | train_loss=0.51474  val_loss=0.60811 | train_MAE=0.7444  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 140 | train_loss=0.50367  val_loss=0.57432 | train_MAE=0.7425  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 141 | train_loss=0.51263  val_loss=0.58437 | train_MAE=0.7519  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 142 | train_loss=0.51046  val_loss=0.59658 | train_MAE=0.7295  val_MAE=0.6957 | lr=0.005 | time=0.08s\n",
      "Epoch 143 | train_loss=0.51577  val_loss=0.57947 | train_MAE=0.7332  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 144 | train_loss=0.52408  val_loss=0.62646 | train_MAE=0.7108  val_MAE=0.6783 | lr=0.005 | time=0.08s\n",
      "Epoch 145 | train_loss=0.50965  val_loss=0.61451 | train_MAE=0.7444  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 146 | train_loss=0.49594  val_loss=0.63344 | train_MAE=0.7332  val_MAE=0.6783 | lr=0.005 | time=0.08s\n",
      "Epoch 147 | train_loss=0.49338  val_loss=0.60658 | train_MAE=0.7201  val_MAE=0.6870 | lr=0.005 | time=0.08s\n",
      "Epoch 148 | train_loss=0.51190  val_loss=0.64773 | train_MAE=0.7164  val_MAE=0.6870 | lr=0.005 | time=0.08s\n",
      "Epoch 149 | train_loss=0.52477  val_loss=0.57914 | train_MAE=0.7257  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 150 | train_loss=0.50871  val_loss=0.61372 | train_MAE=0.7481  val_MAE=0.7478 | lr=0.005 | time=0.08s\n",
      "Epoch 151 | train_loss=0.52335  val_loss=0.58919 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 152 | train_loss=0.51316  val_loss=0.58482 | train_MAE=0.7332  val_MAE=0.7391 | lr=0.005 | time=0.09s\n",
      "Epoch 153 | train_loss=0.51399  val_loss=0.64364 | train_MAE=0.7127  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 154 | train_loss=0.51016  val_loss=0.58778 | train_MAE=0.7313  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 155 | train_loss=0.48833  val_loss=0.61902 | train_MAE=0.7463  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 156 | train_loss=0.50591  val_loss=0.59466 | train_MAE=0.7407  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 157 | train_loss=0.50893  val_loss=0.57863 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 158 | train_loss=0.50371  val_loss=0.59807 | train_MAE=0.7425  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 159 | train_loss=0.49434  val_loss=0.64994 | train_MAE=0.7500  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 160 | train_loss=0.47979  val_loss=0.63449 | train_MAE=0.7556  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 161 | train_loss=0.48834  val_loss=0.62300 | train_MAE=0.7519  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 162 | train_loss=0.50999  val_loss=0.58935 | train_MAE=0.7369  val_MAE=0.6609 | lr=0.005 | time=0.08s\n",
      "Epoch 163 | train_loss=0.49666  val_loss=0.61408 | train_MAE=0.7537  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 164 | train_loss=0.51716  val_loss=0.62621 | train_MAE=0.7295  val_MAE=0.6609 | lr=0.005 | time=0.08s\n",
      "Epoch 165 | train_loss=0.50714  val_loss=0.62026 | train_MAE=0.7239  val_MAE=0.6609 | lr=0.005 | time=0.08s\n",
      "Epoch 166 | train_loss=0.49670  val_loss=0.61709 | train_MAE=0.7444  val_MAE=0.6522 | lr=0.005 | time=0.08s\n",
      "Epoch 167 | train_loss=0.48521  val_loss=0.60848 | train_MAE=0.7668  val_MAE=0.6870 | lr=0.005 | time=0.08s\n",
      "Epoch 168 | train_loss=0.50366  val_loss=0.58480 | train_MAE=0.7500  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 169 | train_loss=0.50358  val_loss=0.60451 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 170 | train_loss=0.49104  val_loss=0.60232 | train_MAE=0.7444  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 171 | train_loss=0.50449  val_loss=0.58968 | train_MAE=0.7220  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 172 | train_loss=0.51029  val_loss=0.59894 | train_MAE=0.7388  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 173 | train_loss=0.52671  val_loss=0.61778 | train_MAE=0.7034  val_MAE=0.6957 | lr=0.005 | time=0.08s\n",
      "Epoch 174 | train_loss=0.51326  val_loss=0.59776 | train_MAE=0.7313  val_MAE=0.6783 | lr=0.005 | time=0.08s\n",
      "Epoch 175 | train_loss=0.51300  val_loss=0.70405 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 176 | train_loss=0.51349  val_loss=0.58951 | train_MAE=0.7407  val_MAE=0.6870 | lr=0.005 | time=0.08s\n",
      "Epoch 177 | train_loss=0.52979  val_loss=0.60360 | train_MAE=0.7127  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 178 | train_loss=0.49884  val_loss=0.58397 | train_MAE=0.7425  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 179 | train_loss=0.50932  val_loss=0.61787 | train_MAE=0.7407  val_MAE=0.7478 | lr=0.005 | time=0.08s\n",
      "Epoch 180 | train_loss=0.49667  val_loss=0.64405 | train_MAE=0.7313  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 181 | train_loss=0.51674  val_loss=0.61886 | train_MAE=0.6996  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 182 | train_loss=0.52038  val_loss=0.60935 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 183 | train_loss=0.51128  val_loss=0.60035 | train_MAE=0.7425  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 184 | train_loss=0.54655  val_loss=0.55438 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 185 | train_loss=0.51221  val_loss=0.56139 | train_MAE=0.7481  val_MAE=0.7391 | lr=0.005 | time=0.08s\n",
      "Epoch 186 | train_loss=0.51738  val_loss=0.63960 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 187 | train_loss=0.50938  val_loss=0.59093 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 188 | train_loss=0.49151  val_loss=0.61413 | train_MAE=0.7463  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 189 | train_loss=0.50319  val_loss=0.62256 | train_MAE=0.7351  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Epoch 190 | train_loss=0.48843  val_loss=0.66314 | train_MAE=0.7444  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 191 | train_loss=0.50909  val_loss=0.59085 | train_MAE=0.7425  val_MAE=0.7043 | lr=0.005 | time=0.08s\n",
      "Epoch 192 | train_loss=0.52930  val_loss=0.59554 | train_MAE=0.7164  val_MAE=0.6783 | lr=0.005 | time=0.08s\n",
      "Epoch 193 | train_loss=0.51464  val_loss=0.59590 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 194 | train_loss=0.50442  val_loss=0.60821 | train_MAE=0.7388  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 195 | train_loss=0.49623  val_loss=0.59931 | train_MAE=0.7500  val_MAE=0.6870 | lr=0.005 | time=0.08s\n",
      "Epoch 196 | train_loss=0.50980  val_loss=0.60814 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 197 | train_loss=0.49045  val_loss=0.63211 | train_MAE=0.7500  val_MAE=0.7130 | lr=0.005 | time=0.08s\n",
      "Epoch 198 | train_loss=0.49371  val_loss=0.60133 | train_MAE=0.7537  val_MAE=0.6957 | lr=0.005 | time=0.08s\n",
      "Epoch 199 | train_loss=0.48760  val_loss=0.61508 | train_MAE=0.7481  val_MAE=0.7304 | lr=0.005 | time=0.08s\n",
      "Epoch 200 | train_loss=0.50141  val_loss=0.60257 | train_MAE=0.7201  val_MAE=0.7217 | lr=0.005 | time=0.08s\n",
      "Total training time: 16.20s\n",
      "Test Accuracy: 0.6435\n",
      "\n",
      "Training with learning_rate=0.01\n",
      "Epoch 001 | train_loss=1.57341  val_loss=0.74965 | train_MAE=0.5299  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 002 | train_loss=0.72464  val_loss=0.70092 | train_MAE=0.5522  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 003 | train_loss=0.68974  val_loss=0.68510 | train_MAE=0.6493  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 004 | train_loss=0.68356  val_loss=0.65453 | train_MAE=0.5784  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 005 | train_loss=0.67278  val_loss=0.66099 | train_MAE=0.6437  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 006 | train_loss=0.64487  val_loss=0.63647 | train_MAE=0.6511  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 007 | train_loss=0.64489  val_loss=0.63541 | train_MAE=0.6549  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 008 | train_loss=0.64459  val_loss=0.61294 | train_MAE=0.6511  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 009 | train_loss=0.63286  val_loss=0.62399 | train_MAE=0.6511  val_MAE=0.6435 | lr=0.01 | time=0.08s\n",
      "Epoch 010 | train_loss=0.62718  val_loss=0.60920 | train_MAE=0.6381  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 011 | train_loss=0.62957  val_loss=0.61849 | train_MAE=0.6623  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 012 | train_loss=0.63204  val_loss=0.59695 | train_MAE=0.6791  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 013 | train_loss=0.64621  val_loss=0.63230 | train_MAE=0.6306  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 014 | train_loss=0.64553  val_loss=0.61941 | train_MAE=0.6474  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 015 | train_loss=0.61889  val_loss=0.61347 | train_MAE=0.6511  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 016 | train_loss=0.60617  val_loss=0.59891 | train_MAE=0.6586  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 017 | train_loss=0.60539  val_loss=0.59967 | train_MAE=0.6623  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 018 | train_loss=0.58737  val_loss=0.57670 | train_MAE=0.6772  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 019 | train_loss=0.57677  val_loss=0.59945 | train_MAE=0.7015  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 020 | train_loss=0.58188  val_loss=0.59286 | train_MAE=0.6978  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 021 | train_loss=0.60852  val_loss=0.58116 | train_MAE=0.6754  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 022 | train_loss=0.59618  val_loss=0.59740 | train_MAE=0.6922  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 023 | train_loss=0.59332  val_loss=0.59220 | train_MAE=0.6996  val_MAE=0.7652 | lr=0.01 | time=0.08s\n",
      "Epoch 024 | train_loss=0.60465  val_loss=0.59453 | train_MAE=0.6772  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 025 | train_loss=0.58649  val_loss=0.58618 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 026 | train_loss=0.59814  val_loss=0.59204 | train_MAE=0.6716  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 027 | train_loss=0.56894  val_loss=0.58855 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 028 | train_loss=0.57073  val_loss=0.59050 | train_MAE=0.6772  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 029 | train_loss=0.55082  val_loss=0.58740 | train_MAE=0.6978  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 030 | train_loss=0.56943  val_loss=0.57493 | train_MAE=0.6996  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 031 | train_loss=0.56668  val_loss=0.58989 | train_MAE=0.6978  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 032 | train_loss=0.57638  val_loss=0.57152 | train_MAE=0.6772  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 033 | train_loss=0.57056  val_loss=0.57453 | train_MAE=0.6940  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 034 | train_loss=0.56691  val_loss=0.57479 | train_MAE=0.6940  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 035 | train_loss=0.55750  val_loss=0.60449 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 036 | train_loss=0.55909  val_loss=0.57365 | train_MAE=0.7034  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 037 | train_loss=0.56800  val_loss=0.57963 | train_MAE=0.7108  val_MAE=0.7304 | lr=0.01 | time=0.15s\n",
      "Epoch 038 | train_loss=0.56330  val_loss=0.59571 | train_MAE=0.6922  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 039 | train_loss=0.56753  val_loss=0.58282 | train_MAE=0.7034  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 040 | train_loss=0.57148  val_loss=0.59381 | train_MAE=0.6959  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 041 | train_loss=0.57006  val_loss=0.58584 | train_MAE=0.6810  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 042 | train_loss=0.54156  val_loss=0.59650 | train_MAE=0.7052  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 043 | train_loss=0.57950  val_loss=0.58812 | train_MAE=0.6884  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 044 | train_loss=0.56862  val_loss=0.57155 | train_MAE=0.7146  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 045 | train_loss=0.56845  val_loss=0.58749 | train_MAE=0.7034  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 046 | train_loss=0.55929  val_loss=0.61492 | train_MAE=0.7034  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 047 | train_loss=0.56439  val_loss=0.58216 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 048 | train_loss=0.56034  val_loss=0.58589 | train_MAE=0.6754  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 049 | train_loss=0.55977  val_loss=0.62159 | train_MAE=0.7164  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 050 | train_loss=0.56126  val_loss=0.56703 | train_MAE=0.6978  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 051 | train_loss=0.57009  val_loss=0.61579 | train_MAE=0.6810  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 052 | train_loss=0.56821  val_loss=0.57358 | train_MAE=0.7127  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 053 | train_loss=0.59309  val_loss=0.59613 | train_MAE=0.6884  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 054 | train_loss=0.58686  val_loss=0.58007 | train_MAE=0.7015  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 055 | train_loss=0.56534  val_loss=0.57546 | train_MAE=0.7108  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 056 | train_loss=0.56017  val_loss=0.56547 | train_MAE=0.7201  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 057 | train_loss=0.54994  val_loss=0.56768 | train_MAE=0.7015  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 058 | train_loss=0.56545  val_loss=0.56369 | train_MAE=0.6940  val_MAE=0.7391 | lr=0.01 | time=0.11s\n",
      "Epoch 059 | train_loss=0.55774  val_loss=0.57613 | train_MAE=0.7090  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 060 | train_loss=0.56699  val_loss=0.57000 | train_MAE=0.7015  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 061 | train_loss=0.57120  val_loss=0.57557 | train_MAE=0.7034  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 062 | train_loss=0.58891  val_loss=0.56035 | train_MAE=0.6623  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 063 | train_loss=0.53784  val_loss=0.58683 | train_MAE=0.7239  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 064 | train_loss=0.56249  val_loss=0.55299 | train_MAE=0.6978  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 065 | train_loss=0.55936  val_loss=0.58103 | train_MAE=0.6959  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 066 | train_loss=0.54166  val_loss=0.58057 | train_MAE=0.7127  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 067 | train_loss=0.56966  val_loss=0.58763 | train_MAE=0.6959  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 068 | train_loss=0.56799  val_loss=0.54532 | train_MAE=0.6996  val_MAE=0.7652 | lr=0.01 | time=0.09s\n",
      "Epoch 069 | train_loss=0.55446  val_loss=0.55926 | train_MAE=0.6978  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 070 | train_loss=0.54484  val_loss=0.55685 | train_MAE=0.7108  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 071 | train_loss=0.53514  val_loss=0.57133 | train_MAE=0.7183  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 072 | train_loss=0.57005  val_loss=0.59317 | train_MAE=0.6996  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 073 | train_loss=0.54501  val_loss=0.55366 | train_MAE=0.6922  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 074 | train_loss=0.54492  val_loss=0.57397 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 075 | train_loss=0.55584  val_loss=0.56254 | train_MAE=0.7164  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 076 | train_loss=0.56151  val_loss=0.59964 | train_MAE=0.7071  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 077 | train_loss=0.56559  val_loss=0.58202 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 078 | train_loss=0.55378  val_loss=0.55598 | train_MAE=0.6940  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 079 | train_loss=0.53655  val_loss=0.61312 | train_MAE=0.7388  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 080 | train_loss=0.58140  val_loss=0.55439 | train_MAE=0.6810  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 081 | train_loss=0.54820  val_loss=0.55998 | train_MAE=0.7239  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 082 | train_loss=0.56285  val_loss=0.56399 | train_MAE=0.7183  val_MAE=0.7652 | lr=0.01 | time=0.08s\n",
      "Epoch 083 | train_loss=0.55212  val_loss=0.57235 | train_MAE=0.7108  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 084 | train_loss=0.56397  val_loss=0.55442 | train_MAE=0.6996  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 085 | train_loss=0.54813  val_loss=0.55191 | train_MAE=0.7183  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 086 | train_loss=0.53502  val_loss=0.65253 | train_MAE=0.7090  val_MAE=0.6435 | lr=0.01 | time=0.08s\n",
      "Epoch 087 | train_loss=0.53590  val_loss=0.56124 | train_MAE=0.7332  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 088 | train_loss=0.57423  val_loss=0.55611 | train_MAE=0.6959  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 089 | train_loss=0.54746  val_loss=0.57654 | train_MAE=0.7257  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 090 | train_loss=0.55096  val_loss=0.55473 | train_MAE=0.6772  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 091 | train_loss=0.55195  val_loss=0.56898 | train_MAE=0.6940  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 092 | train_loss=0.53941  val_loss=0.60905 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 093 | train_loss=0.53841  val_loss=0.56266 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 094 | train_loss=0.54534  val_loss=0.58055 | train_MAE=0.7220  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 095 | train_loss=0.53927  val_loss=0.61207 | train_MAE=0.7090  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 096 | train_loss=0.56244  val_loss=0.54748 | train_MAE=0.7052  val_MAE=0.7478 | lr=0.01 | time=0.09s\n",
      "Epoch 097 | train_loss=0.54827  val_loss=0.55217 | train_MAE=0.7034  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 098 | train_loss=0.54906  val_loss=0.57312 | train_MAE=0.7164  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 099 | train_loss=0.58725  val_loss=0.58352 | train_MAE=0.6754  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 100 | train_loss=0.54239  val_loss=0.56176 | train_MAE=0.7108  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 101 | train_loss=0.54133  val_loss=0.56063 | train_MAE=0.7108  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 102 | train_loss=0.56139  val_loss=0.55387 | train_MAE=0.6996  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 103 | train_loss=0.54287  val_loss=0.57644 | train_MAE=0.6940  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 104 | train_loss=0.54502  val_loss=0.55754 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 105 | train_loss=0.54651  val_loss=0.55669 | train_MAE=0.7146  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 106 | train_loss=0.53723  val_loss=0.56680 | train_MAE=0.7146  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 107 | train_loss=0.53139  val_loss=0.52307 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 108 | train_loss=0.54616  val_loss=0.60385 | train_MAE=0.7239  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 109 | train_loss=0.59385  val_loss=0.55635 | train_MAE=0.6884  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 110 | train_loss=0.53247  val_loss=0.55691 | train_MAE=0.7239  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 111 | train_loss=0.54405  val_loss=0.58951 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 112 | train_loss=0.53556  val_loss=0.56872 | train_MAE=0.7313  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 113 | train_loss=0.54632  val_loss=0.56771 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 114 | train_loss=0.52566  val_loss=0.60001 | train_MAE=0.7034  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 115 | train_loss=0.53079  val_loss=0.56522 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 116 | train_loss=0.51698  val_loss=0.59915 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 117 | train_loss=0.53333  val_loss=0.56006 | train_MAE=0.7127  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 118 | train_loss=0.56050  val_loss=0.59818 | train_MAE=0.6959  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 119 | train_loss=0.53209  val_loss=0.58278 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 120 | train_loss=0.54830  val_loss=0.56071 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 121 | train_loss=0.52960  val_loss=0.55446 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 122 | train_loss=0.54722  val_loss=0.56400 | train_MAE=0.7369  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 123 | train_loss=0.53917  val_loss=0.57492 | train_MAE=0.7369  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 124 | train_loss=0.54749  val_loss=0.55869 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 125 | train_loss=0.53487  val_loss=0.56915 | train_MAE=0.7090  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 126 | train_loss=0.53204  val_loss=0.59241 | train_MAE=0.7183  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 127 | train_loss=0.53593  val_loss=0.57712 | train_MAE=0.7313  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 128 | train_loss=0.53627  val_loss=0.58259 | train_MAE=0.7127  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 129 | train_loss=0.55406  val_loss=0.56732 | train_MAE=0.7034  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 130 | train_loss=0.53728  val_loss=0.57025 | train_MAE=0.7257  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 131 | train_loss=0.50547  val_loss=0.56818 | train_MAE=0.7631  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 132 | train_loss=0.55259  val_loss=0.60096 | train_MAE=0.7164  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 133 | train_loss=0.55541  val_loss=0.55184 | train_MAE=0.6866  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 134 | train_loss=0.54494  val_loss=0.57877 | train_MAE=0.7220  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 135 | train_loss=0.52747  val_loss=0.54884 | train_MAE=0.7295  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 136 | train_loss=0.54023  val_loss=0.59160 | train_MAE=0.7164  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 137 | train_loss=0.53594  val_loss=0.54759 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 138 | train_loss=0.56083  val_loss=0.56511 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 139 | train_loss=0.53831  val_loss=0.54134 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 140 | train_loss=0.57864  val_loss=0.56123 | train_MAE=0.6940  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 141 | train_loss=0.55708  val_loss=0.55517 | train_MAE=0.6940  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 142 | train_loss=0.53078  val_loss=0.57354 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 143 | train_loss=0.53234  val_loss=0.56374 | train_MAE=0.7183  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 144 | train_loss=0.53855  val_loss=0.54670 | train_MAE=0.7313  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 145 | train_loss=0.51280  val_loss=0.56083 | train_MAE=0.7369  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 146 | train_loss=0.50878  val_loss=0.57765 | train_MAE=0.7313  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 147 | train_loss=0.55132  val_loss=0.54215 | train_MAE=0.7071  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 148 | train_loss=0.51926  val_loss=0.54931 | train_MAE=0.7425  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 149 | train_loss=0.52045  val_loss=0.56791 | train_MAE=0.7388  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 150 | train_loss=0.52267  val_loss=0.61325 | train_MAE=0.7313  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 151 | train_loss=0.55141  val_loss=0.54827 | train_MAE=0.6996  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 152 | train_loss=0.53542  val_loss=0.55729 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 153 | train_loss=0.52232  val_loss=0.55781 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 154 | train_loss=0.52155  val_loss=0.56903 | train_MAE=0.7388  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 155 | train_loss=0.52608  val_loss=0.57756 | train_MAE=0.7239  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 156 | train_loss=0.53782  val_loss=0.60525 | train_MAE=0.7108  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 157 | train_loss=0.52272  val_loss=0.53736 | train_MAE=0.7313  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 158 | train_loss=0.53972  val_loss=0.57851 | train_MAE=0.7146  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 159 | train_loss=0.56132  val_loss=0.53444 | train_MAE=0.7201  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 160 | train_loss=0.55441  val_loss=0.54409 | train_MAE=0.7388  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 161 | train_loss=0.54678  val_loss=0.55135 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 162 | train_loss=0.53875  val_loss=0.54239 | train_MAE=0.7034  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 163 | train_loss=0.52219  val_loss=0.57989 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 164 | train_loss=0.55333  val_loss=0.59556 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 165 | train_loss=0.54957  val_loss=0.57044 | train_MAE=0.6903  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 166 | train_loss=0.52009  val_loss=0.56848 | train_MAE=0.7369  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 167 | train_loss=0.54859  val_loss=0.53726 | train_MAE=0.7052  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 168 | train_loss=0.53518  val_loss=0.55854 | train_MAE=0.7351  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 169 | train_loss=0.52554  val_loss=0.54887 | train_MAE=0.7220  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 170 | train_loss=0.53529  val_loss=0.53755 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 171 | train_loss=0.52796  val_loss=0.55702 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 172 | train_loss=0.54021  val_loss=0.52435 | train_MAE=0.7332  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 173 | train_loss=0.52662  val_loss=0.54630 | train_MAE=0.7388  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 174 | train_loss=0.55337  val_loss=0.53555 | train_MAE=0.7369  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 175 | train_loss=0.54334  val_loss=0.55557 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 176 | train_loss=0.57028  val_loss=0.56636 | train_MAE=0.7052  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 177 | train_loss=0.53228  val_loss=0.60613 | train_MAE=0.7239  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 178 | train_loss=0.55429  val_loss=0.54583 | train_MAE=0.7090  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 179 | train_loss=0.54494  val_loss=0.54674 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 180 | train_loss=0.53558  val_loss=0.55333 | train_MAE=0.7201  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 181 | train_loss=0.54264  val_loss=0.52876 | train_MAE=0.7239  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 182 | train_loss=0.54165  val_loss=0.55985 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 183 | train_loss=0.53813  val_loss=0.53030 | train_MAE=0.7332  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 184 | train_loss=0.54070  val_loss=0.57454 | train_MAE=0.7463  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 185 | train_loss=0.53473  val_loss=0.52955 | train_MAE=0.7146  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 186 | train_loss=0.56784  val_loss=0.58650 | train_MAE=0.6959  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 187 | train_loss=0.55797  val_loss=0.54745 | train_MAE=0.6996  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 188 | train_loss=0.55723  val_loss=0.58349 | train_MAE=0.7183  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 189 | train_loss=0.55232  val_loss=0.54357 | train_MAE=0.7239  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 190 | train_loss=0.51312  val_loss=0.55295 | train_MAE=0.7164  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 191 | train_loss=0.52435  val_loss=0.58738 | train_MAE=0.7351  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 192 | train_loss=0.53250  val_loss=0.54345 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 193 | train_loss=0.52310  val_loss=0.55779 | train_MAE=0.7556  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 194 | train_loss=0.53723  val_loss=0.54773 | train_MAE=0.7239  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 195 | train_loss=0.54104  val_loss=0.55762 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 196 | train_loss=0.51602  val_loss=0.55573 | train_MAE=0.7313  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 197 | train_loss=0.54148  val_loss=0.60152 | train_MAE=0.7220  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 198 | train_loss=0.51738  val_loss=0.52738 | train_MAE=0.7481  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 199 | train_loss=0.53564  val_loss=0.58253 | train_MAE=0.7090  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 200 | train_loss=0.53179  val_loss=0.55027 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Total training time: 16.33s\n",
      "Test Accuracy: 0.6696\n"
     ]
    }
   ],
   "source": [
    "#pretty much same thing as dropout just with learning rate instead\n",
    "print(\"STEP 2: TUNING LEARNING RATE\")\n",
    "\n",
    "\n",
    "lr_values = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\n",
    "lr_results = []\n",
    "\n",
    "for lr in lr_values:\n",
    "    print(f\"\\nTraining with learning_rate={lr}\")\n",
    "    \n",
    "    # Create model (using best dropout from previous step)\n",
    "    model = NeuralNetworkFlexible(dropout=best_dropout).to(device)\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Train\n",
    "    history = train_model(model, X_train_dl, X_val_dl, epochs=200)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    total_loss, total_n = 0.0, 0\n",
    "    all_logits, all_true = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xb, yb in X_test_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            batch_loss = loss(logits, yb).item()\n",
    "            total_loss += batch_loss * xb.size(0)\n",
    "            total_n += xb.size(0)\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_true.append(yb.cpu())\n",
    "    \n",
    "    test_loss = total_loss / total_n\n",
    "    logits = torch.cat(all_logits).numpy().ravel()\n",
    "    y_true = torch.cat(all_true).numpy().astype(int)\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    y_pred = (probs >= 0.5).astype(int)\n",
    "    \n",
    "    test_acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    \n",
    "    lr_results.append({\n",
    "        'Learning Rate': lr,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "973d8690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEARNING RATE TUNING - RESULTS TABLE\n",
      " Learning Rate  Test Accuracy  Precision   Recall  F1 Score\n",
      "        0.0001       0.600000   0.380952 0.195122  0.258065\n",
      "        0.0005       0.608696   0.416667 0.243902  0.307692\n",
      "        0.0010       0.600000   0.419355 0.317073  0.361111\n",
      "        0.0050       0.643478   0.500000 0.219512  0.305085\n",
      "        0.0100       0.669565   0.538462 0.512195  0.525000\n",
      "\n",
      " Best Learning Rate: 0.01 with accuracy 0.6696\n"
     ]
    }
   ],
   "source": [
    "lr_df = pd.DataFrame(lr_results)\n",
    "\n",
    "print(\"LEARNING RATE TUNING - RESULTS TABLE\")\n",
    "\n",
    "print(lr_df.to_string(index=False))\n",
    "\n",
    "best_lr = lr_df.loc[lr_df['Test Accuracy'].idxmax(), 'Learning Rate']\n",
    "print(f\"\\n Best Learning Rate: {best_lr} with accuracy {lr_df['Test Accuracy'].max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10fc21e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: TUNING HIDDEN LAYER SIZE\n",
      "\n",
      "Training with hidden_size=32\n",
      "Epoch 001 | train_loss=0.95075  val_loss=0.70758 | train_MAE=0.5634  val_MAE=0.6783 | lr=0.01 | time=0.22s\n",
      "Epoch 002 | train_loss=0.69294  val_loss=0.64918 | train_MAE=0.6381  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 003 | train_loss=0.66094  val_loss=0.64232 | train_MAE=0.6586  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 004 | train_loss=0.63685  val_loss=0.62191 | train_MAE=0.6679  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 005 | train_loss=0.63738  val_loss=0.60245 | train_MAE=0.6399  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 006 | train_loss=0.61912  val_loss=0.58370 | train_MAE=0.6604  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 007 | train_loss=0.60803  val_loss=0.59581 | train_MAE=0.6810  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 008 | train_loss=0.61387  val_loss=0.59034 | train_MAE=0.6586  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 009 | train_loss=0.62805  val_loss=0.59136 | train_MAE=0.6754  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 010 | train_loss=0.62323  val_loss=0.60485 | train_MAE=0.6679  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 011 | train_loss=0.60235  val_loss=0.58739 | train_MAE=0.6735  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 012 | train_loss=0.61405  val_loss=0.57352 | train_MAE=0.6772  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 013 | train_loss=0.59652  val_loss=0.57659 | train_MAE=0.6623  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 014 | train_loss=0.60345  val_loss=0.57470 | train_MAE=0.7071  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 015 | train_loss=0.58135  val_loss=0.56565 | train_MAE=0.6754  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 016 | train_loss=0.58299  val_loss=0.56396 | train_MAE=0.7052  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 017 | train_loss=0.56909  val_loss=0.55445 | train_MAE=0.7351  val_MAE=0.7652 | lr=0.01 | time=0.08s\n",
      "Epoch 018 | train_loss=0.59315  val_loss=0.57163 | train_MAE=0.6716  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 019 | train_loss=0.59331  val_loss=0.57372 | train_MAE=0.6754  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 020 | train_loss=0.56958  val_loss=0.56471 | train_MAE=0.7164  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 021 | train_loss=0.56988  val_loss=0.55981 | train_MAE=0.7108  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 022 | train_loss=0.56428  val_loss=0.59868 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 023 | train_loss=0.56519  val_loss=0.56139 | train_MAE=0.6978  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 024 | train_loss=0.55229  val_loss=0.58512 | train_MAE=0.7015  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 025 | train_loss=0.56588  val_loss=0.57226 | train_MAE=0.6940  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 026 | train_loss=0.56190  val_loss=0.59649 | train_MAE=0.7071  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 027 | train_loss=0.56653  val_loss=0.56268 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 028 | train_loss=0.56713  val_loss=0.57146 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 029 | train_loss=0.55358  val_loss=0.57455 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 030 | train_loss=0.57783  val_loss=0.56837 | train_MAE=0.6810  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 031 | train_loss=0.57800  val_loss=0.58012 | train_MAE=0.6772  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 032 | train_loss=0.58332  val_loss=0.54661 | train_MAE=0.6810  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 033 | train_loss=0.57972  val_loss=0.57045 | train_MAE=0.6903  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 034 | train_loss=0.56770  val_loss=0.56657 | train_MAE=0.6922  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 035 | train_loss=0.57255  val_loss=0.57685 | train_MAE=0.6903  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 036 | train_loss=0.55021  val_loss=0.57323 | train_MAE=0.7052  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 037 | train_loss=0.54735  val_loss=0.56229 | train_MAE=0.7146  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 038 | train_loss=0.55312  val_loss=0.58511 | train_MAE=0.7201  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 039 | train_loss=0.57206  val_loss=0.57638 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 040 | train_loss=0.54930  val_loss=0.58279 | train_MAE=0.6884  val_MAE=0.6783 | lr=0.01 | time=0.09s\n",
      "Epoch 041 | train_loss=0.56011  val_loss=0.57806 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 042 | train_loss=0.55324  val_loss=0.56218 | train_MAE=0.7239  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 043 | train_loss=0.55475  val_loss=0.56455 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 044 | train_loss=0.54696  val_loss=0.55665 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 045 | train_loss=0.56408  val_loss=0.57111 | train_MAE=0.7388  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 046 | train_loss=0.56505  val_loss=0.55216 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.01 | time=0.12s\n",
      "Epoch 047 | train_loss=0.54204  val_loss=0.55608 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 048 | train_loss=0.54806  val_loss=0.55114 | train_MAE=0.7201  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 049 | train_loss=0.55022  val_loss=0.56459 | train_MAE=0.6922  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 050 | train_loss=0.55377  val_loss=0.56691 | train_MAE=0.6978  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 051 | train_loss=0.54435  val_loss=0.59023 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 052 | train_loss=0.54347  val_loss=0.56331 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 053 | train_loss=0.55480  val_loss=0.57240 | train_MAE=0.7332  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 054 | train_loss=0.55459  val_loss=0.56207 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 055 | train_loss=0.55132  val_loss=0.55762 | train_MAE=0.7220  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 056 | train_loss=0.55684  val_loss=0.56646 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 057 | train_loss=0.55740  val_loss=0.58487 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 058 | train_loss=0.56524  val_loss=0.58622 | train_MAE=0.7164  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 059 | train_loss=0.54914  val_loss=0.57300 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 060 | train_loss=0.54949  val_loss=0.59911 | train_MAE=0.7276  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 061 | train_loss=0.54912  val_loss=0.56035 | train_MAE=0.7351  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 062 | train_loss=0.53686  val_loss=0.56315 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 063 | train_loss=0.55912  val_loss=0.58804 | train_MAE=0.6884  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 064 | train_loss=0.56448  val_loss=0.58013 | train_MAE=0.6903  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 065 | train_loss=0.55929  val_loss=0.54955 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 066 | train_loss=0.53852  val_loss=0.56138 | train_MAE=0.7463  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 067 | train_loss=0.52400  val_loss=0.57124 | train_MAE=0.7388  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 068 | train_loss=0.55882  val_loss=0.59670 | train_MAE=0.7183  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 069 | train_loss=0.54260  val_loss=0.55592 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 070 | train_loss=0.54716  val_loss=0.57923 | train_MAE=0.7295  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 071 | train_loss=0.53201  val_loss=0.54978 | train_MAE=0.7239  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 072 | train_loss=0.53685  val_loss=0.58543 | train_MAE=0.7481  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 073 | train_loss=0.51730  val_loss=0.55557 | train_MAE=0.7239  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 074 | train_loss=0.54590  val_loss=0.54074 | train_MAE=0.7425  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 075 | train_loss=0.54517  val_loss=0.57606 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 076 | train_loss=0.56068  val_loss=0.54956 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 077 | train_loss=0.54273  val_loss=0.56121 | train_MAE=0.7201  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 078 | train_loss=0.54809  val_loss=0.58522 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 079 | train_loss=0.53570  val_loss=0.56963 | train_MAE=0.7295  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 080 | train_loss=0.53611  val_loss=0.56370 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 081 | train_loss=0.55020  val_loss=0.56518 | train_MAE=0.7146  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 082 | train_loss=0.52478  val_loss=0.56538 | train_MAE=0.7481  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 083 | train_loss=0.55804  val_loss=0.58147 | train_MAE=0.7183  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 084 | train_loss=0.54331  val_loss=0.57903 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 085 | train_loss=0.54636  val_loss=0.55840 | train_MAE=0.7369  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 086 | train_loss=0.54438  val_loss=0.56350 | train_MAE=0.7239  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 087 | train_loss=0.55908  val_loss=0.57326 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 088 | train_loss=0.53999  val_loss=0.57397 | train_MAE=0.7407  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 089 | train_loss=0.56048  val_loss=0.55935 | train_MAE=0.6978  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 090 | train_loss=0.53408  val_loss=0.59633 | train_MAE=0.7332  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 091 | train_loss=0.54858  val_loss=0.55694 | train_MAE=0.7183  val_MAE=0.7478 | lr=0.01 | time=0.11s\n",
      "Epoch 092 | train_loss=0.55307  val_loss=0.56450 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 093 | train_loss=0.54667  val_loss=0.55413 | train_MAE=0.7239  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 094 | train_loss=0.54890  val_loss=0.57760 | train_MAE=0.7164  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 095 | train_loss=0.54394  val_loss=0.58643 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 096 | train_loss=0.53825  val_loss=0.56959 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 097 | train_loss=0.52143  val_loss=0.59565 | train_MAE=0.7071  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 098 | train_loss=0.54149  val_loss=0.55696 | train_MAE=0.7239  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 099 | train_loss=0.55316  val_loss=0.56559 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 100 | train_loss=0.55950  val_loss=0.55536 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 101 | train_loss=0.54732  val_loss=0.56708 | train_MAE=0.7127  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 102 | train_loss=0.54079  val_loss=0.56177 | train_MAE=0.7164  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 103 | train_loss=0.53660  val_loss=0.56260 | train_MAE=0.7239  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 104 | train_loss=0.52465  val_loss=0.56049 | train_MAE=0.7183  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 105 | train_loss=0.54883  val_loss=0.58590 | train_MAE=0.7295  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 106 | train_loss=0.56191  val_loss=0.55300 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 107 | train_loss=0.55294  val_loss=0.56128 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 108 | train_loss=0.52955  val_loss=0.55902 | train_MAE=0.7351  val_MAE=0.7304 | lr=0.01 | time=0.14s\n",
      "Epoch 109 | train_loss=0.52328  val_loss=0.57214 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 110 | train_loss=0.52280  val_loss=0.56214 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 111 | train_loss=0.52649  val_loss=0.55045 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 112 | train_loss=0.54547  val_loss=0.56622 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 113 | train_loss=0.52809  val_loss=0.55711 | train_MAE=0.7425  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 114 | train_loss=0.52548  val_loss=0.54638 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 115 | train_loss=0.52442  val_loss=0.57688 | train_MAE=0.7108  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 116 | train_loss=0.52065  val_loss=0.54928 | train_MAE=0.7332  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 117 | train_loss=0.52729  val_loss=0.54614 | train_MAE=0.7239  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 118 | train_loss=0.55428  val_loss=0.54793 | train_MAE=0.7369  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 119 | train_loss=0.53846  val_loss=0.57558 | train_MAE=0.7332  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 120 | train_loss=0.55464  val_loss=0.57098 | train_MAE=0.7108  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 121 | train_loss=0.54157  val_loss=0.55959 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 122 | train_loss=0.53282  val_loss=0.55448 | train_MAE=0.7071  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 123 | train_loss=0.53690  val_loss=0.62346 | train_MAE=0.7052  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 124 | train_loss=0.53185  val_loss=0.57346 | train_MAE=0.7201  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 125 | train_loss=0.53406  val_loss=0.58501 | train_MAE=0.7127  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 126 | train_loss=0.51868  val_loss=0.58015 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 127 | train_loss=0.55587  val_loss=0.61062 | train_MAE=0.7257  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 128 | train_loss=0.54810  val_loss=0.57149 | train_MAE=0.6996  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 129 | train_loss=0.55922  val_loss=0.56571 | train_MAE=0.7071  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 130 | train_loss=0.53381  val_loss=0.56932 | train_MAE=0.7351  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 131 | train_loss=0.52725  val_loss=0.54806 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 132 | train_loss=0.54614  val_loss=0.55134 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 133 | train_loss=0.52688  val_loss=0.58203 | train_MAE=0.7351  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 134 | train_loss=0.56268  val_loss=0.71429 | train_MAE=0.6959  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 135 | train_loss=0.58853  val_loss=0.57958 | train_MAE=0.7015  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 136 | train_loss=0.54193  val_loss=0.56258 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 137 | train_loss=0.55173  val_loss=0.58568 | train_MAE=0.7146  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 138 | train_loss=0.55445  val_loss=0.55224 | train_MAE=0.6940  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 139 | train_loss=0.55750  val_loss=0.53991 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 140 | train_loss=0.54012  val_loss=0.57657 | train_MAE=0.7295  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 141 | train_loss=0.53591  val_loss=0.56992 | train_MAE=0.7369  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 142 | train_loss=0.54518  val_loss=0.60888 | train_MAE=0.7127  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 143 | train_loss=0.54731  val_loss=0.55930 | train_MAE=0.7052  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 144 | train_loss=0.53281  val_loss=0.55624 | train_MAE=0.7444  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 145 | train_loss=0.54569  val_loss=0.58198 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 146 | train_loss=0.51905  val_loss=0.58982 | train_MAE=0.7556  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 147 | train_loss=0.55500  val_loss=0.57588 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 148 | train_loss=0.53067  val_loss=0.59821 | train_MAE=0.7183  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 149 | train_loss=0.53434  val_loss=0.55090 | train_MAE=0.7239  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 150 | train_loss=0.51400  val_loss=0.57729 | train_MAE=0.7388  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 151 | train_loss=0.51804  val_loss=0.55795 | train_MAE=0.7239  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 152 | train_loss=0.51629  val_loss=0.57444 | train_MAE=0.7351  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 153 | train_loss=0.53684  val_loss=0.55709 | train_MAE=0.7276  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 154 | train_loss=0.51435  val_loss=0.61543 | train_MAE=0.7425  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 155 | train_loss=0.54630  val_loss=0.53365 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 156 | train_loss=0.51495  val_loss=0.59113 | train_MAE=0.7761  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 157 | train_loss=0.54980  val_loss=0.54853 | train_MAE=0.7276  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 158 | train_loss=0.53326  val_loss=0.60605 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 159 | train_loss=0.53323  val_loss=0.58056 | train_MAE=0.7239  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 160 | train_loss=0.53353  val_loss=0.55126 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 161 | train_loss=0.55418  val_loss=0.57752 | train_MAE=0.7407  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 162 | train_loss=0.52968  val_loss=0.56699 | train_MAE=0.7239  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 163 | train_loss=0.52301  val_loss=0.55640 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 164 | train_loss=0.51746  val_loss=0.57412 | train_MAE=0.7239  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 165 | train_loss=0.54134  val_loss=0.58430 | train_MAE=0.7313  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 166 | train_loss=0.51934  val_loss=0.55772 | train_MAE=0.7425  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 167 | train_loss=0.52418  val_loss=0.57143 | train_MAE=0.7108  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 168 | train_loss=0.53289  val_loss=0.56793 | train_MAE=0.7500  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 169 | train_loss=0.53422  val_loss=0.53373 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 170 | train_loss=0.53136  val_loss=0.58291 | train_MAE=0.7332  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 171 | train_loss=0.53409  val_loss=0.60432 | train_MAE=0.7369  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 172 | train_loss=0.51582  val_loss=0.53475 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 173 | train_loss=0.51836  val_loss=0.54821 | train_MAE=0.7425  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 174 | train_loss=0.54207  val_loss=0.62254 | train_MAE=0.7257  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 175 | train_loss=0.54359  val_loss=0.54620 | train_MAE=0.7220  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 176 | train_loss=0.54800  val_loss=0.58830 | train_MAE=0.7090  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 177 | train_loss=0.51902  val_loss=0.57253 | train_MAE=0.7369  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 178 | train_loss=0.52250  val_loss=0.56865 | train_MAE=0.7407  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 179 | train_loss=0.51398  val_loss=0.56088 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 180 | train_loss=0.50498  val_loss=0.54672 | train_MAE=0.7332  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 181 | train_loss=0.50271  val_loss=0.61369 | train_MAE=0.7463  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 182 | train_loss=0.49466  val_loss=0.55504 | train_MAE=0.7425  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 183 | train_loss=0.50987  val_loss=0.62212 | train_MAE=0.7388  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 184 | train_loss=0.52473  val_loss=0.58458 | train_MAE=0.7295  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 185 | train_loss=0.52858  val_loss=0.59133 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 186 | train_loss=0.52431  val_loss=0.53895 | train_MAE=0.7556  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 187 | train_loss=0.52986  val_loss=0.61393 | train_MAE=0.7481  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 188 | train_loss=0.54405  val_loss=0.54280 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 189 | train_loss=0.53053  val_loss=0.57878 | train_MAE=0.7463  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 190 | train_loss=0.54948  val_loss=0.55582 | train_MAE=0.7071  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 191 | train_loss=0.51453  val_loss=0.56705 | train_MAE=0.7369  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 192 | train_loss=0.50738  val_loss=0.56984 | train_MAE=0.7332  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 193 | train_loss=0.51672  val_loss=0.58730 | train_MAE=0.7519  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 194 | train_loss=0.50085  val_loss=0.55977 | train_MAE=0.7593  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 195 | train_loss=0.53181  val_loss=0.57085 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 196 | train_loss=0.52255  val_loss=0.56325 | train_MAE=0.7201  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 197 | train_loss=0.53081  val_loss=0.60224 | train_MAE=0.7425  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 198 | train_loss=0.54216  val_loss=0.53584 | train_MAE=0.7351  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 199 | train_loss=0.52763  val_loss=0.65355 | train_MAE=0.7463  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 200 | train_loss=0.55242  val_loss=0.54085 | train_MAE=0.7164  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Total training time: 16.52s\n",
      "Test Accuracy: 0.6522\n",
      "\n",
      "Training with hidden_size=64\n",
      "Epoch 001 | train_loss=1.41166  val_loss=0.68340 | train_MAE=0.5187  val_MAE=0.5826 | lr=0.01 | time=0.09s\n",
      "Epoch 002 | train_loss=0.71526  val_loss=0.65885 | train_MAE=0.6437  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 003 | train_loss=0.67155  val_loss=0.64630 | train_MAE=0.6381  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 004 | train_loss=0.63997  val_loss=0.63348 | train_MAE=0.6735  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 005 | train_loss=0.66500  val_loss=0.63223 | train_MAE=0.6381  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 006 | train_loss=0.64195  val_loss=0.60560 | train_MAE=0.6567  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 007 | train_loss=0.61573  val_loss=0.61062 | train_MAE=0.6586  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 008 | train_loss=0.62355  val_loss=0.59490 | train_MAE=0.6735  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 009 | train_loss=0.62674  val_loss=0.59111 | train_MAE=0.6530  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 010 | train_loss=0.60612  val_loss=0.58199 | train_MAE=0.6791  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 011 | train_loss=0.59723  val_loss=0.56886 | train_MAE=0.6828  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 012 | train_loss=0.60032  val_loss=0.56424 | train_MAE=0.6791  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 013 | train_loss=0.59350  val_loss=0.57060 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 014 | train_loss=0.59560  val_loss=0.59377 | train_MAE=0.6847  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 015 | train_loss=0.62128  val_loss=0.60937 | train_MAE=0.6791  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 016 | train_loss=0.61500  val_loss=0.59182 | train_MAE=0.6511  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 017 | train_loss=0.60157  val_loss=0.55884 | train_MAE=0.6511  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 018 | train_loss=0.62201  val_loss=0.57126 | train_MAE=0.6791  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 019 | train_loss=0.58643  val_loss=0.57253 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 020 | train_loss=0.58843  val_loss=0.58280 | train_MAE=0.6866  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 021 | train_loss=0.56434  val_loss=0.55972 | train_MAE=0.6903  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 022 | train_loss=0.56852  val_loss=0.58778 | train_MAE=0.6922  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 023 | train_loss=0.57806  val_loss=0.56941 | train_MAE=0.6884  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 024 | train_loss=0.57812  val_loss=0.55899 | train_MAE=0.6791  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 025 | train_loss=0.59872  val_loss=0.56841 | train_MAE=0.6679  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 026 | train_loss=0.58382  val_loss=0.57360 | train_MAE=0.6660  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 027 | train_loss=0.57001  val_loss=0.57573 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 028 | train_loss=0.59397  val_loss=0.59612 | train_MAE=0.6828  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 029 | train_loss=0.59379  val_loss=0.55090 | train_MAE=0.6828  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 030 | train_loss=0.57968  val_loss=0.55834 | train_MAE=0.6660  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 031 | train_loss=0.57646  val_loss=0.57360 | train_MAE=0.6716  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 032 | train_loss=0.55217  val_loss=0.55701 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 033 | train_loss=0.57762  val_loss=0.57500 | train_MAE=0.6810  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 034 | train_loss=0.58813  val_loss=0.56409 | train_MAE=0.6791  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 035 | train_loss=0.56243  val_loss=0.56245 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 036 | train_loss=0.54963  val_loss=0.57407 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 037 | train_loss=0.57651  val_loss=0.58348 | train_MAE=0.6903  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 038 | train_loss=0.55256  val_loss=0.55714 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 039 | train_loss=0.58562  val_loss=0.57364 | train_MAE=0.6940  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 040 | train_loss=0.55997  val_loss=0.55865 | train_MAE=0.6922  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 041 | train_loss=0.57931  val_loss=0.55489 | train_MAE=0.6959  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 042 | train_loss=0.55581  val_loss=0.55139 | train_MAE=0.7295  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 043 | train_loss=0.56651  val_loss=0.58532 | train_MAE=0.6922  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 044 | train_loss=0.57850  val_loss=0.55993 | train_MAE=0.6810  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 045 | train_loss=0.56689  val_loss=0.58047 | train_MAE=0.6940  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 046 | train_loss=0.54100  val_loss=0.57114 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 047 | train_loss=0.57358  val_loss=0.57233 | train_MAE=0.6978  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 048 | train_loss=0.58214  val_loss=0.57648 | train_MAE=0.6884  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 049 | train_loss=0.56949  val_loss=0.59653 | train_MAE=0.6735  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 050 | train_loss=0.57046  val_loss=0.56170 | train_MAE=0.6791  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 051 | train_loss=0.54330  val_loss=0.58194 | train_MAE=0.7127  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 052 | train_loss=0.53618  val_loss=0.59206 | train_MAE=0.7015  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 053 | train_loss=0.54996  val_loss=0.56174 | train_MAE=0.7146  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 054 | train_loss=0.54163  val_loss=0.58143 | train_MAE=0.7332  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 055 | train_loss=0.54948  val_loss=0.55604 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 056 | train_loss=0.56741  val_loss=0.58682 | train_MAE=0.7071  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 057 | train_loss=0.56365  val_loss=0.53774 | train_MAE=0.6922  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 058 | train_loss=0.55470  val_loss=0.54284 | train_MAE=0.7239  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 059 | train_loss=0.54650  val_loss=0.57386 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 060 | train_loss=0.56692  val_loss=0.54670 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 061 | train_loss=0.55413  val_loss=0.56217 | train_MAE=0.7015  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 062 | train_loss=0.53789  val_loss=0.56318 | train_MAE=0.7313  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 063 | train_loss=0.55407  val_loss=0.57691 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 064 | train_loss=0.55234  val_loss=0.59280 | train_MAE=0.7034  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 065 | train_loss=0.55292  val_loss=0.57363 | train_MAE=0.7052  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 066 | train_loss=0.53850  val_loss=0.56528 | train_MAE=0.7127  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 067 | train_loss=0.57351  val_loss=0.56987 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 068 | train_loss=0.57166  val_loss=0.55766 | train_MAE=0.7052  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 069 | train_loss=0.55661  val_loss=0.56504 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 070 | train_loss=0.54708  val_loss=0.55859 | train_MAE=0.6940  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 071 | train_loss=0.54360  val_loss=0.57082 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 072 | train_loss=0.54672  val_loss=0.55753 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 073 | train_loss=0.54153  val_loss=0.58475 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 074 | train_loss=0.54727  val_loss=0.55515 | train_MAE=0.7127  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 075 | train_loss=0.56029  val_loss=0.55116 | train_MAE=0.6978  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 076 | train_loss=0.55536  val_loss=0.55663 | train_MAE=0.7034  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 077 | train_loss=0.54705  val_loss=0.55343 | train_MAE=0.7127  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 078 | train_loss=0.55423  val_loss=0.53909 | train_MAE=0.7407  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 079 | train_loss=0.54397  val_loss=0.59834 | train_MAE=0.7108  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 080 | train_loss=0.57369  val_loss=0.55683 | train_MAE=0.6903  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 081 | train_loss=0.55174  val_loss=0.56951 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 082 | train_loss=0.54818  val_loss=0.55909 | train_MAE=0.7183  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 083 | train_loss=0.53280  val_loss=0.57020 | train_MAE=0.7146  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 084 | train_loss=0.50909  val_loss=0.57573 | train_MAE=0.7388  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 085 | train_loss=0.56954  val_loss=0.56076 | train_MAE=0.7015  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 086 | train_loss=0.56702  val_loss=0.55997 | train_MAE=0.6903  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 087 | train_loss=0.53386  val_loss=0.54778 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 088 | train_loss=0.55100  val_loss=0.56363 | train_MAE=0.7146  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 089 | train_loss=0.54157  val_loss=0.54651 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 090 | train_loss=0.53147  val_loss=0.63243 | train_MAE=0.7444  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 091 | train_loss=0.53106  val_loss=0.55618 | train_MAE=0.7146  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 092 | train_loss=0.54988  val_loss=0.56159 | train_MAE=0.6978  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 093 | train_loss=0.56127  val_loss=0.57019 | train_MAE=0.6847  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 094 | train_loss=0.54919  val_loss=0.56969 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 095 | train_loss=0.54202  val_loss=0.55928 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 096 | train_loss=0.53361  val_loss=0.57732 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 097 | train_loss=0.52943  val_loss=0.56718 | train_MAE=0.7220  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 098 | train_loss=0.53305  val_loss=0.56754 | train_MAE=0.7425  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 099 | train_loss=0.53267  val_loss=0.58817 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 100 | train_loss=0.54266  val_loss=0.58635 | train_MAE=0.7276  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 101 | train_loss=0.54346  val_loss=0.56422 | train_MAE=0.7090  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 102 | train_loss=0.53208  val_loss=0.55720 | train_MAE=0.7201  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 103 | train_loss=0.55565  val_loss=0.57488 | train_MAE=0.6940  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 104 | train_loss=0.55963  val_loss=0.55003 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 105 | train_loss=0.54550  val_loss=0.59274 | train_MAE=0.7164  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 106 | train_loss=0.53583  val_loss=0.56329 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 107 | train_loss=0.52518  val_loss=0.59290 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 108 | train_loss=0.53354  val_loss=0.57182 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 109 | train_loss=0.53221  val_loss=0.57095 | train_MAE=0.7332  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 110 | train_loss=0.53262  val_loss=0.55498 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 111 | train_loss=0.54983  val_loss=0.54241 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 112 | train_loss=0.55789  val_loss=0.56726 | train_MAE=0.7015  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 113 | train_loss=0.56071  val_loss=0.57812 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 114 | train_loss=0.53186  val_loss=0.59654 | train_MAE=0.7201  val_MAE=0.7043 | lr=0.01 | time=0.15s\n",
      "Epoch 115 | train_loss=0.55892  val_loss=0.57021 | train_MAE=0.6959  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 116 | train_loss=0.54825  val_loss=0.57746 | train_MAE=0.7164  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 117 | train_loss=0.57663  val_loss=0.54269 | train_MAE=0.7015  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 118 | train_loss=0.54442  val_loss=0.56383 | train_MAE=0.7276  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 119 | train_loss=0.55765  val_loss=0.57464 | train_MAE=0.7108  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 120 | train_loss=0.54597  val_loss=0.57362 | train_MAE=0.7220  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 121 | train_loss=0.52103  val_loss=0.57579 | train_MAE=0.7332  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 122 | train_loss=0.52262  val_loss=0.59726 | train_MAE=0.7313  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 123 | train_loss=0.53389  val_loss=0.55834 | train_MAE=0.7257  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 124 | train_loss=0.54801  val_loss=0.55418 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 125 | train_loss=0.52120  val_loss=0.59026 | train_MAE=0.7519  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 126 | train_loss=0.53796  val_loss=0.56384 | train_MAE=0.7127  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 127 | train_loss=0.52774  val_loss=0.55663 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 128 | train_loss=0.52139  val_loss=0.58394 | train_MAE=0.7313  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 129 | train_loss=0.54687  val_loss=0.57603 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 130 | train_loss=0.52970  val_loss=0.55910 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 131 | train_loss=0.54877  val_loss=0.59125 | train_MAE=0.6996  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 132 | train_loss=0.54894  val_loss=0.58371 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 133 | train_loss=0.55734  val_loss=0.57642 | train_MAE=0.7351  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 134 | train_loss=0.51506  val_loss=0.58331 | train_MAE=0.7201  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 135 | train_loss=0.52817  val_loss=0.56565 | train_MAE=0.7108  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 136 | train_loss=0.52927  val_loss=0.57450 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 137 | train_loss=0.52208  val_loss=0.55095 | train_MAE=0.7332  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 138 | train_loss=0.52210  val_loss=0.56786 | train_MAE=0.7369  val_MAE=0.6783 | lr=0.01 | time=0.09s\n",
      "Epoch 139 | train_loss=0.55147  val_loss=0.56118 | train_MAE=0.7295  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 140 | train_loss=0.51579  val_loss=0.58458 | train_MAE=0.7425  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 141 | train_loss=0.53860  val_loss=0.58542 | train_MAE=0.7444  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 142 | train_loss=0.52949  val_loss=0.57436 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 143 | train_loss=0.52895  val_loss=0.57495 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 144 | train_loss=0.53363  val_loss=0.59006 | train_MAE=0.7164  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 145 | train_loss=0.52062  val_loss=0.57448 | train_MAE=0.7090  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 146 | train_loss=0.52142  val_loss=0.55850 | train_MAE=0.7127  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 147 | train_loss=0.53573  val_loss=0.57245 | train_MAE=0.7295  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 148 | train_loss=0.52244  val_loss=0.60254 | train_MAE=0.7295  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 149 | train_loss=0.52212  val_loss=0.55134 | train_MAE=0.7239  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 150 | train_loss=0.51710  val_loss=0.62323 | train_MAE=0.7146  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 151 | train_loss=0.52518  val_loss=0.58183 | train_MAE=0.7444  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 152 | train_loss=0.52354  val_loss=0.56558 | train_MAE=0.7090  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 153 | train_loss=0.53837  val_loss=0.61633 | train_MAE=0.6959  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 154 | train_loss=0.51674  val_loss=0.56314 | train_MAE=0.7351  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 155 | train_loss=0.50080  val_loss=0.59781 | train_MAE=0.7388  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 156 | train_loss=0.50912  val_loss=0.57799 | train_MAE=0.7388  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 157 | train_loss=0.52792  val_loss=0.61058 | train_MAE=0.7369  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 158 | train_loss=0.52935  val_loss=0.58143 | train_MAE=0.7164  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 159 | train_loss=0.51862  val_loss=0.58531 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 160 | train_loss=0.53028  val_loss=0.53049 | train_MAE=0.7146  val_MAE=0.7565 | lr=0.01 | time=0.07s\n",
      "Epoch 161 | train_loss=0.51913  val_loss=0.61363 | train_MAE=0.7481  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 162 | train_loss=0.54479  val_loss=0.57681 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 163 | train_loss=0.54488  val_loss=0.55897 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 164 | train_loss=0.53284  val_loss=0.62400 | train_MAE=0.7388  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 165 | train_loss=0.56564  val_loss=0.55205 | train_MAE=0.6903  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 166 | train_loss=0.57785  val_loss=0.56006 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 167 | train_loss=0.54821  val_loss=0.55311 | train_MAE=0.7146  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 168 | train_loss=0.55211  val_loss=0.56084 | train_MAE=0.7090  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 169 | train_loss=0.56951  val_loss=0.55634 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 170 | train_loss=0.54761  val_loss=0.54084 | train_MAE=0.7127  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 171 | train_loss=0.55039  val_loss=0.54839 | train_MAE=0.7388  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 172 | train_loss=0.54105  val_loss=0.55675 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 173 | train_loss=0.53024  val_loss=0.56635 | train_MAE=0.7146  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 174 | train_loss=0.51018  val_loss=0.59173 | train_MAE=0.7519  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 175 | train_loss=0.51685  val_loss=0.56565 | train_MAE=0.7537  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 176 | train_loss=0.50875  val_loss=0.55230 | train_MAE=0.7332  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 177 | train_loss=0.51710  val_loss=0.54966 | train_MAE=0.7351  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 178 | train_loss=0.51537  val_loss=0.58625 | train_MAE=0.7257  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 179 | train_loss=0.51748  val_loss=0.57957 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 180 | train_loss=0.52635  val_loss=0.57483 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 181 | train_loss=0.54262  val_loss=0.59844 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 182 | train_loss=0.52291  val_loss=0.58327 | train_MAE=0.7388  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 183 | train_loss=0.53155  val_loss=0.54885 | train_MAE=0.7388  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 184 | train_loss=0.52684  val_loss=0.58149 | train_MAE=0.7201  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 185 | train_loss=0.53031  val_loss=0.55759 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 186 | train_loss=0.53802  val_loss=0.63117 | train_MAE=0.7257  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 187 | train_loss=0.54361  val_loss=0.55313 | train_MAE=0.7015  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 188 | train_loss=0.56819  val_loss=0.56072 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 189 | train_loss=0.52209  val_loss=0.54325 | train_MAE=0.7463  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 190 | train_loss=0.54613  val_loss=0.58890 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 191 | train_loss=0.52762  val_loss=0.56835 | train_MAE=0.7146  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 192 | train_loss=0.53226  val_loss=0.54299 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 193 | train_loss=0.54135  val_loss=0.55338 | train_MAE=0.7146  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 194 | train_loss=0.51821  val_loss=0.58958 | train_MAE=0.7164  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 195 | train_loss=0.53494  val_loss=0.55212 | train_MAE=0.7239  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 196 | train_loss=0.53115  val_loss=0.58888 | train_MAE=0.7519  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 197 | train_loss=0.52830  val_loss=0.57525 | train_MAE=0.7164  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 198 | train_loss=0.53458  val_loss=0.58614 | train_MAE=0.7425  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 199 | train_loss=0.53140  val_loss=0.57060 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 200 | train_loss=0.50215  val_loss=0.55109 | train_MAE=0.7556  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Total training time: 16.27s\n",
      "Test Accuracy: 0.6870\n",
      "\n",
      "Training with hidden_size=128\n",
      "Epoch 001 | train_loss=2.05949  val_loss=0.70405 | train_MAE=0.5392  val_MAE=0.6522 | lr=0.01 | time=0.47s\n",
      "Epoch 002 | train_loss=0.68506  val_loss=0.67530 | train_MAE=0.6213  val_MAE=0.6522 | lr=0.01 | time=0.07s\n",
      "Epoch 003 | train_loss=0.65508  val_loss=0.60800 | train_MAE=0.6586  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 004 | train_loss=0.65172  val_loss=0.61046 | train_MAE=0.6660  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 005 | train_loss=0.63409  val_loss=0.60751 | train_MAE=0.6586  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 006 | train_loss=0.64153  val_loss=0.60093 | train_MAE=0.6511  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 007 | train_loss=0.62077  val_loss=0.59533 | train_MAE=0.6679  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 008 | train_loss=0.61137  val_loss=0.59255 | train_MAE=0.6847  val_MAE=0.7391 | lr=0.01 | time=0.07s\n",
      "Epoch 009 | train_loss=0.60354  val_loss=0.58709 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.01 | time=0.07s\n",
      "Epoch 010 | train_loss=0.59368  val_loss=0.58828 | train_MAE=0.6735  val_MAE=0.6783 | lr=0.01 | time=0.07s\n",
      "Epoch 011 | train_loss=0.60182  val_loss=0.59315 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 012 | train_loss=0.62355  val_loss=0.61254 | train_MAE=0.6660  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 013 | train_loss=0.59587  val_loss=0.58257 | train_MAE=0.6716  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 014 | train_loss=0.58900  val_loss=0.59356 | train_MAE=0.6772  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 015 | train_loss=0.57273  val_loss=0.58647 | train_MAE=0.6810  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 016 | train_loss=0.61231  val_loss=0.61108 | train_MAE=0.6716  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 017 | train_loss=0.57740  val_loss=0.58245 | train_MAE=0.6903  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 018 | train_loss=0.58417  val_loss=0.57367 | train_MAE=0.6866  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 019 | train_loss=0.57712  val_loss=0.58692 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 020 | train_loss=0.59051  val_loss=0.58322 | train_MAE=0.6922  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 021 | train_loss=0.57823  val_loss=0.59068 | train_MAE=0.6735  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 022 | train_loss=0.57463  val_loss=0.59284 | train_MAE=0.7071  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 023 | train_loss=0.57269  val_loss=0.59754 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 024 | train_loss=0.56965  val_loss=0.58432 | train_MAE=0.7071  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 025 | train_loss=0.57134  val_loss=0.59001 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 026 | train_loss=0.55156  val_loss=0.62703 | train_MAE=0.6959  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 027 | train_loss=0.57642  val_loss=0.59608 | train_MAE=0.7015  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 028 | train_loss=0.57606  val_loss=0.57584 | train_MAE=0.6791  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 029 | train_loss=0.58047  val_loss=0.57558 | train_MAE=0.7052  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 030 | train_loss=0.55395  val_loss=0.57475 | train_MAE=0.7164  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 031 | train_loss=0.59603  val_loss=0.57439 | train_MAE=0.7164  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 032 | train_loss=0.58451  val_loss=0.60466 | train_MAE=0.6716  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 033 | train_loss=0.58013  val_loss=0.57846 | train_MAE=0.6978  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 034 | train_loss=0.57797  val_loss=0.59869 | train_MAE=0.6828  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 035 | train_loss=0.58883  val_loss=0.57327 | train_MAE=0.6884  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 036 | train_loss=0.56667  val_loss=0.57511 | train_MAE=0.6978  val_MAE=0.7304 | lr=0.01 | time=0.07s\n",
      "Epoch 037 | train_loss=0.56435  val_loss=0.58243 | train_MAE=0.6940  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 038 | train_loss=0.57435  val_loss=0.57602 | train_MAE=0.6884  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 039 | train_loss=0.55654  val_loss=0.58798 | train_MAE=0.6978  val_MAE=0.7391 | lr=0.01 | time=0.07s\n",
      "Epoch 040 | train_loss=0.55707  val_loss=0.57581 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.01 | time=0.07s\n",
      "Epoch 041 | train_loss=0.54670  val_loss=0.58874 | train_MAE=0.7127  val_MAE=0.7478 | lr=0.01 | time=0.07s\n",
      "Epoch 042 | train_loss=0.57840  val_loss=0.56545 | train_MAE=0.6791  val_MAE=0.7391 | lr=0.01 | time=0.07s\n",
      "Epoch 043 | train_loss=0.56869  val_loss=0.61476 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.01 | time=0.07s\n",
      "Epoch 044 | train_loss=0.54543  val_loss=0.59717 | train_MAE=0.6884  val_MAE=0.7304 | lr=0.01 | time=0.07s\n",
      "Epoch 045 | train_loss=0.53579  val_loss=0.59007 | train_MAE=0.7164  val_MAE=0.7391 | lr=0.01 | time=0.07s\n",
      "Epoch 046 | train_loss=0.53456  val_loss=0.63558 | train_MAE=0.7351  val_MAE=0.7130 | lr=0.01 | time=0.07s\n",
      "Epoch 047 | train_loss=0.56220  val_loss=0.56727 | train_MAE=0.6922  val_MAE=0.7130 | lr=0.01 | time=0.07s\n",
      "Epoch 048 | train_loss=0.55793  val_loss=0.57137 | train_MAE=0.7164  val_MAE=0.7478 | lr=0.01 | time=0.07s\n",
      "Epoch 049 | train_loss=0.54089  val_loss=0.60002 | train_MAE=0.6922  val_MAE=0.7478 | lr=0.01 | time=0.07s\n",
      "Epoch 050 | train_loss=0.56963  val_loss=0.56912 | train_MAE=0.7071  val_MAE=0.7304 | lr=0.01 | time=0.07s\n",
      "Epoch 051 | train_loss=0.54675  val_loss=0.57337 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.01 | time=0.07s\n",
      "Epoch 052 | train_loss=0.55938  val_loss=0.59282 | train_MAE=0.7034  val_MAE=0.7478 | lr=0.01 | time=0.07s\n",
      "Epoch 053 | train_loss=0.56587  val_loss=0.57992 | train_MAE=0.6828  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 054 | train_loss=0.54385  val_loss=0.63980 | train_MAE=0.7090  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 055 | train_loss=0.56678  val_loss=0.57083 | train_MAE=0.7108  val_MAE=0.7652 | lr=0.01 | time=0.08s\n",
      "Epoch 056 | train_loss=0.56227  val_loss=0.59109 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 057 | train_loss=0.55442  val_loss=0.57725 | train_MAE=0.7052  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 058 | train_loss=0.54918  val_loss=0.56847 | train_MAE=0.7201  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 059 | train_loss=0.55399  val_loss=0.58223 | train_MAE=0.6922  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 060 | train_loss=0.55533  val_loss=0.56851 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 061 | train_loss=0.53351  val_loss=0.58395 | train_MAE=0.7201  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 062 | train_loss=0.53817  val_loss=0.60804 | train_MAE=0.7351  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 063 | train_loss=0.55500  val_loss=0.57736 | train_MAE=0.7071  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 064 | train_loss=0.54060  val_loss=0.57076 | train_MAE=0.7239  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 065 | train_loss=0.55304  val_loss=0.59662 | train_MAE=0.6978  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 066 | train_loss=0.55698  val_loss=0.57235 | train_MAE=0.6866  val_MAE=0.7304 | lr=0.01 | time=0.07s\n",
      "Epoch 067 | train_loss=0.55317  val_loss=0.66393 | train_MAE=0.7220  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 068 | train_loss=0.59588  val_loss=0.55697 | train_MAE=0.6772  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 069 | train_loss=0.57682  val_loss=0.60070 | train_MAE=0.7052  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 070 | train_loss=0.56330  val_loss=0.56729 | train_MAE=0.7220  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 071 | train_loss=0.56957  val_loss=0.57237 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 072 | train_loss=0.54942  val_loss=0.59656 | train_MAE=0.7146  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 073 | train_loss=0.54379  val_loss=0.56510 | train_MAE=0.7201  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 074 | train_loss=0.56890  val_loss=0.58099 | train_MAE=0.6903  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 075 | train_loss=0.59370  val_loss=0.62784 | train_MAE=0.6978  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 076 | train_loss=0.57762  val_loss=0.57139 | train_MAE=0.6922  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 077 | train_loss=0.58107  val_loss=0.63329 | train_MAE=0.6903  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 078 | train_loss=0.55577  val_loss=0.57215 | train_MAE=0.7071  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 079 | train_loss=0.54973  val_loss=0.65413 | train_MAE=0.7146  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 080 | train_loss=0.55265  val_loss=0.55313 | train_MAE=0.7369  val_MAE=0.7304 | lr=0.01 | time=0.07s\n",
      "Epoch 081 | train_loss=0.55790  val_loss=0.60839 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 082 | train_loss=0.55429  val_loss=0.55348 | train_MAE=0.6903  val_MAE=0.7478 | lr=0.01 | time=0.07s\n",
      "Epoch 083 | train_loss=0.56944  val_loss=0.55535 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.01 | time=0.07s\n",
      "Epoch 084 | train_loss=0.56319  val_loss=0.58062 | train_MAE=0.6996  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 085 | train_loss=0.56960  val_loss=0.57295 | train_MAE=0.7052  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 086 | train_loss=0.56774  val_loss=0.66047 | train_MAE=0.7108  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 087 | train_loss=0.56150  val_loss=0.55614 | train_MAE=0.6959  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 088 | train_loss=0.54095  val_loss=0.56540 | train_MAE=0.7257  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 089 | train_loss=0.54325  val_loss=0.59259 | train_MAE=0.7146  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 090 | train_loss=0.53875  val_loss=0.57317 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 091 | train_loss=0.53757  val_loss=0.57155 | train_MAE=0.7257  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 092 | train_loss=0.55353  val_loss=0.58145 | train_MAE=0.7034  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 093 | train_loss=0.54999  val_loss=0.57935 | train_MAE=0.7052  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 094 | train_loss=0.56053  val_loss=0.55905 | train_MAE=0.7313  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 095 | train_loss=0.53496  val_loss=0.56073 | train_MAE=0.7276  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 096 | train_loss=0.53412  val_loss=0.59924 | train_MAE=0.6978  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 097 | train_loss=0.57812  val_loss=0.57899 | train_MAE=0.6828  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 098 | train_loss=0.53582  val_loss=0.58701 | train_MAE=0.7463  val_MAE=0.7217 | lr=0.01 | time=0.07s\n",
      "Epoch 099 | train_loss=0.54429  val_loss=0.57663 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 100 | train_loss=0.56771  val_loss=0.60575 | train_MAE=0.6978  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 101 | train_loss=0.56697  val_loss=0.61519 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 102 | train_loss=0.56369  val_loss=0.59900 | train_MAE=0.7090  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 103 | train_loss=0.56979  val_loss=0.57138 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 104 | train_loss=0.56325  val_loss=0.63454 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 105 | train_loss=0.56677  val_loss=0.55083 | train_MAE=0.6810  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 106 | train_loss=0.54712  val_loss=0.62103 | train_MAE=0.6884  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 107 | train_loss=0.54087  val_loss=0.57793 | train_MAE=0.7164  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 108 | train_loss=0.57026  val_loss=0.59244 | train_MAE=0.6903  val_MAE=0.7304 | lr=0.01 | time=0.07s\n",
      "Epoch 109 | train_loss=0.54137  val_loss=0.56901 | train_MAE=0.7071  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 110 | train_loss=0.53026  val_loss=0.60116 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 111 | train_loss=0.54989  val_loss=0.57023 | train_MAE=0.7146  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 112 | train_loss=0.56659  val_loss=0.62657 | train_MAE=0.6922  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 113 | train_loss=0.56175  val_loss=0.54648 | train_MAE=0.7164  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 114 | train_loss=0.53802  val_loss=0.58555 | train_MAE=0.7220  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 115 | train_loss=0.54893  val_loss=0.64291 | train_MAE=0.6884  val_MAE=0.7304 | lr=0.01 | time=0.12s\n",
      "Epoch 116 | train_loss=0.54849  val_loss=0.58512 | train_MAE=0.7146  val_MAE=0.7043 | lr=0.01 | time=0.11s\n",
      "Epoch 117 | train_loss=0.54468  val_loss=0.59640 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 118 | train_loss=0.55898  val_loss=0.58135 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 119 | train_loss=0.52073  val_loss=0.61333 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 120 | train_loss=0.54043  val_loss=0.56125 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 121 | train_loss=0.53995  val_loss=0.62927 | train_MAE=0.7071  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 122 | train_loss=0.57163  val_loss=0.56887 | train_MAE=0.6903  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 123 | train_loss=0.56003  val_loss=0.57269 | train_MAE=0.6903  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 124 | train_loss=0.55921  val_loss=0.55627 | train_MAE=0.7108  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 125 | train_loss=0.56168  val_loss=0.56489 | train_MAE=0.6978  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 126 | train_loss=0.54258  val_loss=0.67139 | train_MAE=0.7127  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 127 | train_loss=0.59163  val_loss=0.53301 | train_MAE=0.7052  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 128 | train_loss=0.58146  val_loss=0.57586 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 129 | train_loss=0.56165  val_loss=0.60081 | train_MAE=0.7052  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 130 | train_loss=0.55056  val_loss=0.57847 | train_MAE=0.6940  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 131 | train_loss=0.54936  val_loss=0.56134 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 132 | train_loss=0.53864  val_loss=0.56817 | train_MAE=0.7108  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 133 | train_loss=0.55334  val_loss=0.55856 | train_MAE=0.7332  val_MAE=0.7217 | lr=0.01 | time=0.07s\n",
      "Epoch 134 | train_loss=0.54875  val_loss=0.57580 | train_MAE=0.7201  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 135 | train_loss=0.55733  val_loss=0.56234 | train_MAE=0.7071  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 136 | train_loss=0.55689  val_loss=0.56414 | train_MAE=0.7052  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 137 | train_loss=0.53315  val_loss=0.54426 | train_MAE=0.7332  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 138 | train_loss=0.55137  val_loss=0.62884 | train_MAE=0.7146  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 139 | train_loss=0.54526  val_loss=0.59197 | train_MAE=0.7015  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 140 | train_loss=0.54329  val_loss=0.61981 | train_MAE=0.6996  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 141 | train_loss=0.53986  val_loss=0.55036 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 142 | train_loss=0.54926  val_loss=0.56750 | train_MAE=0.7108  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 143 | train_loss=0.56070  val_loss=0.62674 | train_MAE=0.6772  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 144 | train_loss=0.54111  val_loss=0.58231 | train_MAE=0.7351  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 145 | train_loss=0.55333  val_loss=0.55249 | train_MAE=0.7071  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 146 | train_loss=0.52118  val_loss=0.58912 | train_MAE=0.7295  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 147 | train_loss=0.54247  val_loss=0.53355 | train_MAE=0.7146  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 148 | train_loss=0.54686  val_loss=0.58049 | train_MAE=0.7052  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 149 | train_loss=0.53879  val_loss=0.53996 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 150 | train_loss=0.53784  val_loss=0.55107 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 151 | train_loss=0.52851  val_loss=0.57695 | train_MAE=0.7351  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 152 | train_loss=0.52437  val_loss=0.57494 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 153 | train_loss=0.52508  val_loss=0.57392 | train_MAE=0.7201  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 154 | train_loss=0.54186  val_loss=0.61320 | train_MAE=0.7071  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 155 | train_loss=0.56073  val_loss=0.61353 | train_MAE=0.6978  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 156 | train_loss=0.56267  val_loss=0.53525 | train_MAE=0.7146  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 157 | train_loss=0.56263  val_loss=0.56619 | train_MAE=0.6903  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 158 | train_loss=0.54238  val_loss=0.55440 | train_MAE=0.7034  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 159 | train_loss=0.54061  val_loss=0.60031 | train_MAE=0.7351  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 160 | train_loss=0.56253  val_loss=0.56976 | train_MAE=0.6866  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 161 | train_loss=0.53257  val_loss=0.59980 | train_MAE=0.7201  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 162 | train_loss=0.54828  val_loss=0.61196 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 163 | train_loss=0.52931  val_loss=0.57412 | train_MAE=0.7257  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 164 | train_loss=0.54588  val_loss=0.58438 | train_MAE=0.6940  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 165 | train_loss=0.55215  val_loss=0.59494 | train_MAE=0.7015  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 166 | train_loss=0.53279  val_loss=0.58863 | train_MAE=0.7257  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 167 | train_loss=0.52046  val_loss=0.61051 | train_MAE=0.7332  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 168 | train_loss=0.52706  val_loss=0.60237 | train_MAE=0.7276  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 169 | train_loss=0.54210  val_loss=0.57491 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 170 | train_loss=0.54767  val_loss=0.57304 | train_MAE=0.6866  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 171 | train_loss=0.52870  val_loss=0.61375 | train_MAE=0.7313  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 172 | train_loss=0.59647  val_loss=0.57871 | train_MAE=0.6922  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 173 | train_loss=0.55441  val_loss=0.62507 | train_MAE=0.7239  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 174 | train_loss=0.59226  val_loss=0.56688 | train_MAE=0.6698  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 175 | train_loss=0.55605  val_loss=0.54053 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 176 | train_loss=0.53473  val_loss=0.56490 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 177 | train_loss=0.54007  val_loss=0.54471 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 178 | train_loss=0.54891  val_loss=0.57144 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 179 | train_loss=0.55743  val_loss=0.62287 | train_MAE=0.6996  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 180 | train_loss=0.55876  val_loss=0.58466 | train_MAE=0.7052  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 181 | train_loss=0.54425  val_loss=0.58456 | train_MAE=0.7407  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 182 | train_loss=0.53423  val_loss=0.54571 | train_MAE=0.7295  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 183 | train_loss=0.53850  val_loss=0.56719 | train_MAE=0.7276  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 184 | train_loss=0.53912  val_loss=0.55766 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 185 | train_loss=0.54090  val_loss=0.57038 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 186 | train_loss=0.52273  val_loss=0.57001 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 187 | train_loss=0.54777  val_loss=0.57825 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 188 | train_loss=0.53649  val_loss=0.60904 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 189 | train_loss=0.55468  val_loss=0.55615 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 190 | train_loss=0.54483  val_loss=0.55786 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 191 | train_loss=0.54333  val_loss=0.59853 | train_MAE=0.7146  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 192 | train_loss=0.56047  val_loss=0.55665 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 193 | train_loss=0.56818  val_loss=0.60453 | train_MAE=0.7090  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 194 | train_loss=0.56002  val_loss=0.58725 | train_MAE=0.6922  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 195 | train_loss=0.54079  val_loss=0.55813 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 196 | train_loss=0.55754  val_loss=0.57154 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 197 | train_loss=0.53666  val_loss=0.55806 | train_MAE=0.7295  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 198 | train_loss=0.51529  val_loss=0.57761 | train_MAE=0.7332  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 199 | train_loss=0.51837  val_loss=0.60547 | train_MAE=0.7369  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 200 | train_loss=0.54755  val_loss=0.57744 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Total training time: 15.82s\n",
      "Test Accuracy: 0.6435\n",
      "\n",
      "Training with hidden_size=256\n",
      "Epoch 001 | train_loss=11.45823  val_loss=1.03749 | train_MAE=0.5392  val_MAE=0.6522 | lr=0.01 | time=1.05s\n",
      "Epoch 002 | train_loss=0.83602  val_loss=0.73725 | train_MAE=0.5858  val_MAE=0.3913 | lr=0.01 | time=0.07s\n",
      "Epoch 003 | train_loss=0.73340  val_loss=0.64705 | train_MAE=0.5504  val_MAE=0.6522 | lr=0.01 | time=0.07s\n",
      "Epoch 004 | train_loss=0.67259  val_loss=0.63268 | train_MAE=0.6343  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 005 | train_loss=0.64561  val_loss=0.59834 | train_MAE=0.6623  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 006 | train_loss=0.64702  val_loss=0.60828 | train_MAE=0.6063  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 007 | train_loss=0.61834  val_loss=0.60720 | train_MAE=0.6660  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 008 | train_loss=0.63096  val_loss=0.58597 | train_MAE=0.6735  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 009 | train_loss=0.62251  val_loss=0.60908 | train_MAE=0.6866  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 010 | train_loss=0.64728  val_loss=0.58767 | train_MAE=0.6642  val_MAE=0.6783 | lr=0.01 | time=0.07s\n",
      "Epoch 011 | train_loss=0.60275  val_loss=0.58037 | train_MAE=0.6810  val_MAE=0.6783 | lr=0.01 | time=0.07s\n",
      "Epoch 012 | train_loss=0.62375  val_loss=0.57163 | train_MAE=0.6679  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 013 | train_loss=0.59910  val_loss=0.57263 | train_MAE=0.6810  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 014 | train_loss=0.60049  val_loss=0.57218 | train_MAE=0.6828  val_MAE=0.6696 | lr=0.01 | time=0.07s\n",
      "Epoch 015 | train_loss=0.59233  val_loss=0.59201 | train_MAE=0.6828  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 016 | train_loss=0.59783  val_loss=0.57896 | train_MAE=0.6679  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 017 | train_loss=0.61258  val_loss=0.58006 | train_MAE=0.6772  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 018 | train_loss=0.60300  val_loss=0.58493 | train_MAE=0.6698  val_MAE=0.7043 | lr=0.01 | time=0.12s\n",
      "Epoch 019 | train_loss=0.60151  val_loss=0.57936 | train_MAE=0.6679  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 020 | train_loss=0.59133  val_loss=0.58124 | train_MAE=0.6847  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 021 | train_loss=0.59270  val_loss=0.59451 | train_MAE=0.6623  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 022 | train_loss=0.59234  val_loss=0.59688 | train_MAE=0.6735  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 023 | train_loss=0.58516  val_loss=0.58385 | train_MAE=0.6772  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 024 | train_loss=0.58693  val_loss=0.59516 | train_MAE=0.6754  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 025 | train_loss=0.57228  val_loss=0.61467 | train_MAE=0.6940  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 026 | train_loss=0.58820  val_loss=0.60155 | train_MAE=0.6978  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 027 | train_loss=0.58290  val_loss=0.59216 | train_MAE=0.6642  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 028 | train_loss=0.57974  val_loss=0.57988 | train_MAE=0.6791  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 029 | train_loss=0.58776  val_loss=0.57412 | train_MAE=0.7146  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 030 | train_loss=0.57196  val_loss=0.61256 | train_MAE=0.6959  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 031 | train_loss=0.56491  val_loss=0.57858 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 032 | train_loss=0.57607  val_loss=0.57185 | train_MAE=0.6884  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 033 | train_loss=0.56560  val_loss=0.58196 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 034 | train_loss=0.55708  val_loss=0.57907 | train_MAE=0.6996  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 035 | train_loss=0.55711  val_loss=0.60511 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 036 | train_loss=0.58070  val_loss=0.57811 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 037 | train_loss=0.57534  val_loss=0.57821 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.01 | time=0.07s\n",
      "Epoch 038 | train_loss=0.55700  val_loss=0.57031 | train_MAE=0.7183  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 039 | train_loss=0.55989  val_loss=0.57794 | train_MAE=0.7164  val_MAE=0.7304 | lr=0.01 | time=0.07s\n",
      "Epoch 040 | train_loss=0.57736  val_loss=0.58592 | train_MAE=0.6810  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 041 | train_loss=0.56413  val_loss=0.78218 | train_MAE=0.7052  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 042 | train_loss=0.58865  val_loss=0.58317 | train_MAE=0.6903  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 043 | train_loss=0.57704  val_loss=0.59127 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 044 | train_loss=0.56760  val_loss=0.59243 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.01 | time=0.07s\n",
      "Epoch 045 | train_loss=0.58417  val_loss=0.58869 | train_MAE=0.6922  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 046 | train_loss=0.60167  val_loss=0.64515 | train_MAE=0.6474  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 047 | train_loss=0.58170  val_loss=0.58002 | train_MAE=0.6642  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 048 | train_loss=0.56105  val_loss=0.61688 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 049 | train_loss=0.58866  val_loss=0.59373 | train_MAE=0.7034  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 050 | train_loss=0.59015  val_loss=0.57010 | train_MAE=0.6903  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 051 | train_loss=0.58444  val_loss=0.55872 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 052 | train_loss=0.54665  val_loss=0.58236 | train_MAE=0.7108  val_MAE=0.7478 | lr=0.01 | time=0.15s\n",
      "Epoch 053 | train_loss=0.56416  val_loss=0.56856 | train_MAE=0.7071  val_MAE=0.7478 | lr=0.01 | time=0.07s\n",
      "Epoch 054 | train_loss=0.57344  val_loss=0.57947 | train_MAE=0.6828  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 055 | train_loss=0.53949  val_loss=0.56784 | train_MAE=0.7090  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 056 | train_loss=0.56231  val_loss=0.57830 | train_MAE=0.7071  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 057 | train_loss=0.55536  val_loss=0.56705 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 058 | train_loss=0.55788  val_loss=0.58404 | train_MAE=0.7034  val_MAE=0.7478 | lr=0.01 | time=0.07s\n",
      "Epoch 059 | train_loss=0.55622  val_loss=0.56371 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.01 | time=0.07s\n",
      "Epoch 060 | train_loss=0.55629  val_loss=0.57740 | train_MAE=0.6940  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 061 | train_loss=0.55154  val_loss=0.57608 | train_MAE=0.7201  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 062 | train_loss=0.55783  val_loss=0.56921 | train_MAE=0.6959  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 063 | train_loss=0.55494  val_loss=0.58454 | train_MAE=0.7015  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 064 | train_loss=0.55607  val_loss=0.58822 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 065 | train_loss=0.57827  val_loss=0.69053 | train_MAE=0.6996  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 066 | train_loss=0.60130  val_loss=0.60164 | train_MAE=0.6623  val_MAE=0.7130 | lr=0.01 | time=0.07s\n",
      "Epoch 067 | train_loss=0.57429  val_loss=0.58741 | train_MAE=0.6810  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 068 | train_loss=0.56616  val_loss=0.60483 | train_MAE=0.6810  val_MAE=0.6783 | lr=0.01 | time=0.07s\n",
      "Epoch 069 | train_loss=0.57220  val_loss=0.58212 | train_MAE=0.6866  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 070 | train_loss=0.58630  val_loss=0.58696 | train_MAE=0.6586  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 071 | train_loss=0.56470  val_loss=0.61063 | train_MAE=0.6959  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 072 | train_loss=0.58273  val_loss=0.59299 | train_MAE=0.6940  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 073 | train_loss=0.58547  val_loss=0.60479 | train_MAE=0.6735  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 074 | train_loss=0.55923  val_loss=0.59971 | train_MAE=0.7015  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 075 | train_loss=0.55356  val_loss=0.64245 | train_MAE=0.7034  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 076 | train_loss=0.55927  val_loss=0.57785 | train_MAE=0.6940  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 077 | train_loss=0.54593  val_loss=0.60895 | train_MAE=0.7090  val_MAE=0.7478 | lr=0.01 | time=0.07s\n",
      "Epoch 078 | train_loss=0.56821  val_loss=0.61352 | train_MAE=0.7164  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 079 | train_loss=0.56647  val_loss=0.60568 | train_MAE=0.6922  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 080 | train_loss=0.56647  val_loss=0.58516 | train_MAE=0.6847  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 081 | train_loss=0.57357  val_loss=0.59898 | train_MAE=0.6772  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 082 | train_loss=0.57724  val_loss=0.59972 | train_MAE=0.6530  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 083 | train_loss=0.55635  val_loss=0.62516 | train_MAE=0.6978  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 084 | train_loss=0.57471  val_loss=0.59633 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 085 | train_loss=0.58051  val_loss=0.58103 | train_MAE=0.6810  val_MAE=0.7130 | lr=0.01 | time=0.12s\n",
      "Epoch 086 | train_loss=0.57760  val_loss=0.61980 | train_MAE=0.6791  val_MAE=0.6957 | lr=0.01 | time=0.14s\n",
      "Epoch 087 | train_loss=0.56296  val_loss=0.60252 | train_MAE=0.6996  val_MAE=0.6783 | lr=0.01 | time=0.09s\n",
      "Epoch 088 | train_loss=0.56900  val_loss=0.60288 | train_MAE=0.6922  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 089 | train_loss=0.58461  val_loss=0.59049 | train_MAE=0.6847  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 090 | train_loss=0.58156  val_loss=0.63861 | train_MAE=0.6847  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 091 | train_loss=0.58737  val_loss=0.59051 | train_MAE=0.6716  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 092 | train_loss=0.55394  val_loss=0.59572 | train_MAE=0.6940  val_MAE=0.6783 | lr=0.01 | time=0.07s\n",
      "Epoch 093 | train_loss=0.57136  val_loss=0.58563 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 094 | train_loss=0.59910  val_loss=0.60202 | train_MAE=0.6772  val_MAE=0.6696 | lr=0.01 | time=0.07s\n",
      "Epoch 095 | train_loss=0.60110  val_loss=0.63564 | train_MAE=0.6549  val_MAE=0.6522 | lr=0.01 | time=0.07s\n",
      "Epoch 096 | train_loss=0.58344  val_loss=0.58646 | train_MAE=0.6660  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 097 | train_loss=0.55975  val_loss=0.62085 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 098 | train_loss=0.56480  val_loss=0.59222 | train_MAE=0.6847  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 099 | train_loss=0.55996  val_loss=0.63877 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 100 | train_loss=0.57607  val_loss=0.58482 | train_MAE=0.6903  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 101 | train_loss=0.57815  val_loss=0.58924 | train_MAE=0.6922  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 102 | train_loss=0.58840  val_loss=0.58383 | train_MAE=0.6866  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 103 | train_loss=0.57472  val_loss=0.57978 | train_MAE=0.6679  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 104 | train_loss=0.57139  val_loss=0.57846 | train_MAE=0.6884  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 105 | train_loss=0.56194  val_loss=0.58666 | train_MAE=0.6716  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 106 | train_loss=0.56204  val_loss=0.57417 | train_MAE=0.6847  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 107 | train_loss=0.56930  val_loss=0.58377 | train_MAE=0.6903  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 108 | train_loss=0.56491  val_loss=0.59702 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 109 | train_loss=0.56675  val_loss=0.61299 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 110 | train_loss=0.57435  val_loss=0.60508 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 111 | train_loss=0.56213  val_loss=0.59040 | train_MAE=0.7090  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 112 | train_loss=0.59010  val_loss=0.59586 | train_MAE=0.6866  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 113 | train_loss=0.56959  val_loss=0.63911 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 114 | train_loss=0.59067  val_loss=0.57306 | train_MAE=0.6791  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 115 | train_loss=0.57664  val_loss=0.60382 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 116 | train_loss=0.56941  val_loss=0.57942 | train_MAE=0.6847  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 117 | train_loss=0.54769  val_loss=0.60448 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 118 | train_loss=0.56961  val_loss=0.59831 | train_MAE=0.6828  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 119 | train_loss=0.56504  val_loss=0.61222 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 120 | train_loss=0.55283  val_loss=0.63351 | train_MAE=0.6810  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 121 | train_loss=0.57466  val_loss=0.59111 | train_MAE=0.6716  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 122 | train_loss=0.55937  val_loss=0.59611 | train_MAE=0.6903  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 123 | train_loss=0.56070  val_loss=0.60329 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 124 | train_loss=0.56399  val_loss=0.59715 | train_MAE=0.6922  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 125 | train_loss=0.55785  val_loss=0.58359 | train_MAE=0.6959  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 126 | train_loss=0.55957  val_loss=0.59784 | train_MAE=0.6754  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 127 | train_loss=0.54420  val_loss=0.61072 | train_MAE=0.6623  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 128 | train_loss=0.55088  val_loss=0.60005 | train_MAE=0.7015  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 129 | train_loss=0.57136  val_loss=0.57157 | train_MAE=0.6884  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 130 | train_loss=0.57186  val_loss=0.58687 | train_MAE=0.6716  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 131 | train_loss=0.57461  val_loss=0.59034 | train_MAE=0.6791  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 132 | train_loss=0.57714  val_loss=0.58615 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 133 | train_loss=0.59768  val_loss=0.61908 | train_MAE=0.6660  val_MAE=0.6522 | lr=0.01 | time=0.07s\n",
      "Epoch 134 | train_loss=0.59283  val_loss=0.61703 | train_MAE=0.6567  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 135 | train_loss=0.55771  val_loss=0.59490 | train_MAE=0.6884  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 136 | train_loss=0.55964  val_loss=0.59543 | train_MAE=0.6903  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 137 | train_loss=0.55877  val_loss=0.59245 | train_MAE=0.6791  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 138 | train_loss=0.57399  val_loss=0.62924 | train_MAE=0.6828  val_MAE=0.6522 | lr=0.01 | time=0.07s\n",
      "Epoch 139 | train_loss=0.57445  val_loss=0.58601 | train_MAE=0.6679  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 140 | train_loss=0.58615  val_loss=0.61318 | train_MAE=0.6735  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 141 | train_loss=0.56422  val_loss=0.59314 | train_MAE=0.6810  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 142 | train_loss=0.56224  val_loss=0.60326 | train_MAE=0.6810  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 143 | train_loss=0.57289  val_loss=0.59608 | train_MAE=0.6847  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 144 | train_loss=0.57981  val_loss=0.62541 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 145 | train_loss=0.57082  val_loss=0.63010 | train_MAE=0.6884  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 146 | train_loss=0.55270  val_loss=0.59800 | train_MAE=0.7239  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 147 | train_loss=0.56883  val_loss=0.59951 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 148 | train_loss=0.55116  val_loss=0.66597 | train_MAE=0.6903  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 149 | train_loss=0.58735  val_loss=0.61620 | train_MAE=0.6959  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 150 | train_loss=0.55407  val_loss=0.69036 | train_MAE=0.6922  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 151 | train_loss=0.57393  val_loss=0.57577 | train_MAE=0.6903  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 152 | train_loss=0.53887  val_loss=0.67735 | train_MAE=0.7257  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 153 | train_loss=0.54779  val_loss=0.58933 | train_MAE=0.7146  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 154 | train_loss=0.54484  val_loss=0.61174 | train_MAE=0.7071  val_MAE=0.7565 | lr=0.01 | time=0.07s\n",
      "Epoch 155 | train_loss=0.56941  val_loss=0.61310 | train_MAE=0.6940  val_MAE=0.7130 | lr=0.01 | time=0.07s\n",
      "Epoch 156 | train_loss=0.58057  val_loss=0.60213 | train_MAE=0.6772  val_MAE=0.6696 | lr=0.01 | time=0.07s\n",
      "Epoch 157 | train_loss=0.56973  val_loss=0.60362 | train_MAE=0.6754  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 158 | train_loss=0.61355  val_loss=0.64138 | train_MAE=0.6866  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 159 | train_loss=0.55516  val_loss=0.59385 | train_MAE=0.6978  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 160 | train_loss=0.57296  val_loss=0.61156 | train_MAE=0.6866  val_MAE=0.6696 | lr=0.01 | time=0.07s\n",
      "Epoch 161 | train_loss=0.56520  val_loss=0.65822 | train_MAE=0.6698  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 162 | train_loss=0.59497  val_loss=0.59329 | train_MAE=0.6679  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 163 | train_loss=0.58607  val_loss=0.61790 | train_MAE=0.6567  val_MAE=0.6609 | lr=0.01 | time=0.07s\n",
      "Epoch 164 | train_loss=0.57071  val_loss=0.63223 | train_MAE=0.6791  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 165 | train_loss=0.55381  val_loss=0.59665 | train_MAE=0.6847  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 166 | train_loss=0.57333  val_loss=0.61087 | train_MAE=0.6810  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 167 | train_loss=0.54608  val_loss=0.64390 | train_MAE=0.6847  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 168 | train_loss=0.59312  val_loss=0.64820 | train_MAE=0.6716  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 169 | train_loss=0.56299  val_loss=0.67242 | train_MAE=0.7015  val_MAE=0.6609 | lr=0.01 | time=0.07s\n",
      "Epoch 170 | train_loss=0.55668  val_loss=0.58006 | train_MAE=0.6978  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 171 | train_loss=0.58660  val_loss=0.59823 | train_MAE=0.6922  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 172 | train_loss=0.59410  val_loss=0.62683 | train_MAE=0.6847  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 173 | train_loss=0.59171  val_loss=0.60024 | train_MAE=0.6884  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 174 | train_loss=0.57185  val_loss=0.61695 | train_MAE=0.6996  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 175 | train_loss=0.54988  val_loss=0.63948 | train_MAE=0.6940  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 176 | train_loss=0.60509  val_loss=0.59833 | train_MAE=0.6810  val_MAE=0.6609 | lr=0.01 | time=0.07s\n",
      "Epoch 177 | train_loss=0.59979  val_loss=0.60900 | train_MAE=0.6343  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 178 | train_loss=0.60366  val_loss=0.62405 | train_MAE=0.6716  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 179 | train_loss=0.61179  val_loss=0.67326 | train_MAE=0.6698  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 180 | train_loss=0.63814  val_loss=0.59489 | train_MAE=0.6679  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 181 | train_loss=0.59602  val_loss=0.59617 | train_MAE=0.6959  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 182 | train_loss=0.61171  val_loss=0.62116 | train_MAE=0.6679  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 183 | train_loss=0.59129  val_loss=0.64453 | train_MAE=0.7090  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 184 | train_loss=0.59118  val_loss=0.59369 | train_MAE=0.6772  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 185 | train_loss=0.60935  val_loss=0.57125 | train_MAE=0.6810  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Epoch 186 | train_loss=0.59305  val_loss=0.57243 | train_MAE=0.6847  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 187 | train_loss=0.56005  val_loss=0.57450 | train_MAE=0.7108  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 188 | train_loss=0.58919  val_loss=0.59776 | train_MAE=0.6884  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 189 | train_loss=0.57368  val_loss=0.55522 | train_MAE=0.6847  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 190 | train_loss=0.55472  val_loss=0.58395 | train_MAE=0.7108  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 191 | train_loss=0.56480  val_loss=0.56892 | train_MAE=0.6959  val_MAE=0.6957 | lr=0.01 | time=0.07s\n",
      "Epoch 192 | train_loss=0.58084  val_loss=0.60589 | train_MAE=0.6903  val_MAE=0.6609 | lr=0.01 | time=0.07s\n",
      "Epoch 193 | train_loss=0.54733  val_loss=0.55623 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 194 | train_loss=0.57864  val_loss=0.62844 | train_MAE=0.6828  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 195 | train_loss=0.59252  val_loss=0.56723 | train_MAE=0.6754  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 196 | train_loss=0.58236  val_loss=0.61441 | train_MAE=0.6810  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 197 | train_loss=0.57931  val_loss=0.57122 | train_MAE=0.7015  val_MAE=0.6870 | lr=0.01 | time=0.07s\n",
      "Epoch 198 | train_loss=0.61590  val_loss=0.57934 | train_MAE=0.6735  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 199 | train_loss=0.57184  val_loss=0.56355 | train_MAE=0.6810  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 200 | train_loss=0.56950  val_loss=0.58823 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.01 | time=0.07s\n",
      "Total training time: 16.46s\n",
      "Test Accuracy: 0.6087\n"
     ]
    }
   ],
   "source": [
    "#same as others\n",
    "print(\"STEP 3: TUNING HIDDEN LAYER SIZE\")\n",
    "\n",
    "\n",
    "hidden_sizes = [32, 64, 128, 256]\n",
    "hidden_results = []\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    print(f\"\\nTraining with hidden_size={hidden_size}\")\n",
    "    \n",
    "    # Create model (using best dropout and lr from previous steps)\n",
    "    model = NeuralNetworkFlexible(hidden_size=hidden_size, dropout=best_dropout).to(device)\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n",
    "    \n",
    "    # Train\n",
    "    history = train_model(model, X_train_dl, X_val_dl, epochs=200)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    total_loss, total_n = 0.0, 0\n",
    "    all_logits, all_true = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xb, yb in X_test_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            batch_loss = loss(logits, yb).item()\n",
    "            total_loss += batch_loss * xb.size(0)\n",
    "            total_n += xb.size(0)\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_true.append(yb.cpu())\n",
    "    \n",
    "    test_loss = total_loss / total_n\n",
    "    logits = torch.cat(all_logits).numpy().ravel()\n",
    "    y_true = torch.cat(all_true).numpy().astype(int)\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    y_pred = (probs >= 0.5).astype(int)\n",
    "    \n",
    "    test_acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    \n",
    "    hidden_results.append({\n",
    "        'Hidden Size': hidden_size,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e89bead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER SIZE TUNING - RESULTS TABLE\n",
      " Hidden Size  Test Accuracy  Precision   Recall  F1 Score\n",
      "          32       0.652174   0.520000 0.317073  0.393939\n",
      "          64       0.686957   0.560976 0.560976  0.560976\n",
      "         128       0.643478   0.500000 0.463415  0.481013\n",
      "         256       0.608696   0.416667 0.243902  0.307692\n",
      "\n",
      " Best Hidden Size: 64 with accuracy 0.6870\n"
     ]
    }
   ],
   "source": [
    "hidden_df = pd.DataFrame(hidden_results)\n",
    "\n",
    "print(\"HIDDEN LAYER SIZE TUNING - RESULTS TABLE\")\n",
    "\n",
    "print(hidden_df.to_string(index=False))\n",
    "\n",
    "best_hidden = hidden_df.loc[hidden_df['Test Accuracy'].idxmax(), 'Hidden Size']\n",
    "print(f\"\\n Best Hidden Size: {best_hidden} with accuracy {hidden_df['Test Accuracy'].max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba94ca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters Found:\n",
      "Dropout Rate: 0.2\n",
      "Learning Rate: 0.01\n",
      "Hidden Layer Size: 64\n",
      "\n",
      "Best Test Accuracy: 0.6870\n",
      "Hyperparameter  Best Value  Best Accuracy\n",
      "       Dropout        0.20       0.643478\n",
      " Learning Rate        0.01       0.669565\n",
      "   Hidden Size       64.00       0.686957\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\nBest Hyperparameters Found:\")\n",
    "print(f\"Dropout Rate: {best_dropout}\")\n",
    "print(f\"Learning Rate: {best_lr}\")\n",
    "print(f\"Hidden Layer Size: {best_hidden}\")\n",
    "print(f\"\\nBest Test Accuracy: {hidden_df['Test Accuracy'].max():.4f}\")\n",
    "\n",
    "# Create comparison table of all hyperparameters tuned\n",
    "\n",
    "comparison_data = {\n",
    "    'Hyperparameter': ['Dropout', 'Learning Rate', 'Hidden Size'],\n",
    "    'Best Value': [best_dropout, best_lr, best_hidden],\n",
    "    'Best Accuracy': [\n",
    "        dropout_df['Test Accuracy'].max(),\n",
    "        lr_df['Test Accuracy'].max(),\n",
    "        hidden_df['Test Accuracy'].max()\n",
    "    ]\n",
    "}\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ed864eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model with best hyperparameters\n",
      "Configuration: dropout=0.2, lr=0.01, hidden_size=64\n",
      "\n",
      "Training base model\n",
      "Epoch 001 | train_loss=1.19390  val_loss=0.67220 | train_MAE=0.5466  val_MAE=0.6348 | lr=0.01 | time=0.16s\n",
      "Epoch 002 | train_loss=0.69889  val_loss=0.65648 | train_MAE=0.6287  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 003 | train_loss=0.65438  val_loss=0.62137 | train_MAE=0.6679  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 004 | train_loss=0.65168  val_loss=0.61025 | train_MAE=0.6399  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 005 | train_loss=0.63005  val_loss=0.60181 | train_MAE=0.6828  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 006 | train_loss=0.63531  val_loss=0.62419 | train_MAE=0.6828  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 007 | train_loss=0.63368  val_loss=0.61429 | train_MAE=0.6604  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 008 | train_loss=0.61004  val_loss=0.58399 | train_MAE=0.6679  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 009 | train_loss=0.60812  val_loss=0.57783 | train_MAE=0.6754  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 010 | train_loss=0.60757  val_loss=0.59304 | train_MAE=0.6866  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 011 | train_loss=0.60928  val_loss=0.59087 | train_MAE=0.6772  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 012 | train_loss=0.60584  val_loss=0.60554 | train_MAE=0.6810  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 013 | train_loss=0.62536  val_loss=0.60858 | train_MAE=0.6604  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 014 | train_loss=0.61361  val_loss=0.58177 | train_MAE=0.6642  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 015 | train_loss=0.62954  val_loss=0.57642 | train_MAE=0.6735  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 016 | train_loss=0.60479  val_loss=0.59928 | train_MAE=0.6660  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 017 | train_loss=0.60802  val_loss=0.59153 | train_MAE=0.6735  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 018 | train_loss=0.58210  val_loss=0.57465 | train_MAE=0.7071  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 019 | train_loss=0.58454  val_loss=0.58296 | train_MAE=0.6810  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 020 | train_loss=0.59020  val_loss=0.56946 | train_MAE=0.6791  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 021 | train_loss=0.59089  val_loss=0.57774 | train_MAE=0.6847  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 022 | train_loss=0.57302  val_loss=0.57605 | train_MAE=0.7127  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 023 | train_loss=0.57713  val_loss=0.57216 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 024 | train_loss=0.58404  val_loss=0.58195 | train_MAE=0.6791  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 025 | train_loss=0.55281  val_loss=0.57939 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 026 | train_loss=0.57732  val_loss=0.57326 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 027 | train_loss=0.57752  val_loss=0.58439 | train_MAE=0.7015  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 028 | train_loss=0.57615  val_loss=0.58068 | train_MAE=0.6791  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 029 | train_loss=0.58450  val_loss=0.57423 | train_MAE=0.6791  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 030 | train_loss=0.57563  val_loss=0.57713 | train_MAE=0.6866  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 031 | train_loss=0.58268  val_loss=0.59864 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 032 | train_loss=0.58936  val_loss=0.57447 | train_MAE=0.6735  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 033 | train_loss=0.60053  val_loss=0.60567 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 034 | train_loss=0.59373  val_loss=0.58560 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 035 | train_loss=0.60052  val_loss=0.57102 | train_MAE=0.6828  val_MAE=0.6957 | lr=0.01 | time=0.10s\n",
      "Epoch 036 | train_loss=0.60250  val_loss=0.59481 | train_MAE=0.6679  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 037 | train_loss=0.58723  val_loss=0.56996 | train_MAE=0.6866  val_MAE=0.6870 | lr=0.01 | time=0.09s\n",
      "Epoch 038 | train_loss=0.56970  val_loss=0.57148 | train_MAE=0.6959  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 039 | train_loss=0.58039  val_loss=0.56043 | train_MAE=0.6772  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 040 | train_loss=0.56553  val_loss=0.55793 | train_MAE=0.6922  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 041 | train_loss=0.57788  val_loss=0.59050 | train_MAE=0.6810  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 042 | train_loss=0.58641  val_loss=0.56228 | train_MAE=0.6959  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 043 | train_loss=0.56326  val_loss=0.58999 | train_MAE=0.7015  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 044 | train_loss=0.58931  val_loss=0.56981 | train_MAE=0.6716  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 045 | train_loss=0.55552  val_loss=0.58343 | train_MAE=0.6959  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 046 | train_loss=0.58567  val_loss=0.56072 | train_MAE=0.6884  val_MAE=0.7565 | lr=0.01 | time=0.09s\n",
      "Epoch 047 | train_loss=0.57963  val_loss=0.56187 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 048 | train_loss=0.57015  val_loss=0.57213 | train_MAE=0.6791  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 049 | train_loss=0.56517  val_loss=0.58825 | train_MAE=0.6716  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 050 | train_loss=0.56491  val_loss=0.57713 | train_MAE=0.6884  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 051 | train_loss=0.54232  val_loss=0.58452 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 052 | train_loss=0.54270  val_loss=0.57241 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 053 | train_loss=0.55503  val_loss=0.57089 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 054 | train_loss=0.54594  val_loss=0.58065 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 055 | train_loss=0.55977  val_loss=0.58284 | train_MAE=0.6959  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 056 | train_loss=0.54661  val_loss=0.56515 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 057 | train_loss=0.54231  val_loss=0.58048 | train_MAE=0.7201  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 058 | train_loss=0.55213  val_loss=0.59780 | train_MAE=0.7127  val_MAE=0.6870 | lr=0.01 | time=0.09s\n",
      "Epoch 059 | train_loss=0.55725  val_loss=0.56229 | train_MAE=0.6847  val_MAE=0.7391 | lr=0.01 | time=0.11s\n",
      "Epoch 060 | train_loss=0.55439  val_loss=0.57170 | train_MAE=0.7090  val_MAE=0.7739 | lr=0.01 | time=0.09s\n",
      "Epoch 061 | train_loss=0.53269  val_loss=0.58297 | train_MAE=0.7146  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 062 | train_loss=0.53298  val_loss=0.56832 | train_MAE=0.7164  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 063 | train_loss=0.55712  val_loss=0.60155 | train_MAE=0.7015  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 064 | train_loss=0.55899  val_loss=0.56106 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.01 | time=0.15s\n",
      "Epoch 065 | train_loss=0.56156  val_loss=0.58030 | train_MAE=0.6903  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 066 | train_loss=0.56719  val_loss=0.57154 | train_MAE=0.6660  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 067 | train_loss=0.55686  val_loss=0.57767 | train_MAE=0.7146  val_MAE=0.7652 | lr=0.01 | time=0.08s\n",
      "Epoch 068 | train_loss=0.53963  val_loss=0.56548 | train_MAE=0.7108  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 069 | train_loss=0.53404  val_loss=0.56025 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 070 | train_loss=0.55186  val_loss=0.55686 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 071 | train_loss=0.58446  val_loss=0.57975 | train_MAE=0.6828  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 072 | train_loss=0.56729  val_loss=0.57104 | train_MAE=0.7295  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 073 | train_loss=0.55496  val_loss=0.55593 | train_MAE=0.6940  val_MAE=0.7478 | lr=0.01 | time=0.09s\n",
      "Epoch 074 | train_loss=0.54982  val_loss=0.57671 | train_MAE=0.6884  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 075 | train_loss=0.53454  val_loss=0.56915 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 076 | train_loss=0.54321  val_loss=0.57565 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 077 | train_loss=0.55258  val_loss=0.57141 | train_MAE=0.7052  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 078 | train_loss=0.55086  val_loss=0.59694 | train_MAE=0.6866  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 079 | train_loss=0.55921  val_loss=0.56756 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 080 | train_loss=0.54808  val_loss=0.56130 | train_MAE=0.7257  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 081 | train_loss=0.53779  val_loss=0.57211 | train_MAE=0.7239  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 082 | train_loss=0.55263  val_loss=0.57966 | train_MAE=0.7183  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 083 | train_loss=0.53393  val_loss=0.54780 | train_MAE=0.7407  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 084 | train_loss=0.54892  val_loss=0.58940 | train_MAE=0.7015  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 085 | train_loss=0.54741  val_loss=0.57226 | train_MAE=0.7015  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 086 | train_loss=0.54830  val_loss=0.56524 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 087 | train_loss=0.53680  val_loss=0.59166 | train_MAE=0.7034  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 088 | train_loss=0.55675  val_loss=0.56578 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 089 | train_loss=0.54989  val_loss=0.56005 | train_MAE=0.7463  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 090 | train_loss=0.56817  val_loss=0.56521 | train_MAE=0.7090  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 091 | train_loss=0.55307  val_loss=0.55623 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 092 | train_loss=0.54638  val_loss=0.55971 | train_MAE=0.7052  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 093 | train_loss=0.55349  val_loss=0.55503 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 094 | train_loss=0.54259  val_loss=0.56130 | train_MAE=0.7127  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 095 | train_loss=0.54990  val_loss=0.54775 | train_MAE=0.6903  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 096 | train_loss=0.55741  val_loss=0.56113 | train_MAE=0.7108  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 097 | train_loss=0.55880  val_loss=0.56807 | train_MAE=0.6978  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 098 | train_loss=0.52920  val_loss=0.54791 | train_MAE=0.7388  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 099 | train_loss=0.55931  val_loss=0.58451 | train_MAE=0.6978  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 100 | train_loss=0.54496  val_loss=0.54799 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 101 | train_loss=0.55362  val_loss=0.56864 | train_MAE=0.7052  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 102 | train_loss=0.54972  val_loss=0.55872 | train_MAE=0.7127  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 103 | train_loss=0.53899  val_loss=0.54585 | train_MAE=0.7034  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 104 | train_loss=0.53533  val_loss=0.55337 | train_MAE=0.7351  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 105 | train_loss=0.57796  val_loss=0.57893 | train_MAE=0.7015  val_MAE=0.6870 | lr=0.01 | time=0.09s\n",
      "Epoch 106 | train_loss=0.56777  val_loss=0.55675 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 107 | train_loss=0.55268  val_loss=0.55329 | train_MAE=0.7071  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 108 | train_loss=0.57012  val_loss=0.57291 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 109 | train_loss=0.55205  val_loss=0.57145 | train_MAE=0.6903  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 110 | train_loss=0.53170  val_loss=0.55886 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 111 | train_loss=0.55629  val_loss=0.57045 | train_MAE=0.7052  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 112 | train_loss=0.52640  val_loss=0.58404 | train_MAE=0.7183  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 113 | train_loss=0.56052  val_loss=0.57357 | train_MAE=0.7034  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 114 | train_loss=0.55426  val_loss=0.55844 | train_MAE=0.7052  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 115 | train_loss=0.54936  val_loss=0.57523 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 116 | train_loss=0.53633  val_loss=0.56982 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 117 | train_loss=0.54439  val_loss=0.57826 | train_MAE=0.7164  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 118 | train_loss=0.53523  val_loss=0.55680 | train_MAE=0.7444  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 119 | train_loss=0.54595  val_loss=0.57550 | train_MAE=0.6847  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 120 | train_loss=0.54144  val_loss=0.57800 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 121 | train_loss=0.51757  val_loss=0.59013 | train_MAE=0.7127  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 122 | train_loss=0.55799  val_loss=0.59660 | train_MAE=0.6922  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 123 | train_loss=0.54041  val_loss=0.55273 | train_MAE=0.7015  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 124 | train_loss=0.51502  val_loss=0.57784 | train_MAE=0.7332  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 125 | train_loss=0.53734  val_loss=0.55782 | train_MAE=0.7239  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 126 | train_loss=0.53030  val_loss=0.55779 | train_MAE=0.7239  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 127 | train_loss=0.51470  val_loss=0.56859 | train_MAE=0.7369  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 128 | train_loss=0.55908  val_loss=0.57206 | train_MAE=0.6978  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 129 | train_loss=0.55373  val_loss=0.57420 | train_MAE=0.6996  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 130 | train_loss=0.55468  val_loss=0.57764 | train_MAE=0.7108  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 131 | train_loss=0.53127  val_loss=0.56896 | train_MAE=0.7295  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 132 | train_loss=0.52309  val_loss=0.57966 | train_MAE=0.7481  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 133 | train_loss=0.55608  val_loss=0.58293 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 134 | train_loss=0.54287  val_loss=0.55434 | train_MAE=0.7164  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 135 | train_loss=0.56849  val_loss=0.56617 | train_MAE=0.6996  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 136 | train_loss=0.54537  val_loss=0.56853 | train_MAE=0.7127  val_MAE=0.6870 | lr=0.01 | time=0.09s\n",
      "Epoch 137 | train_loss=0.53692  val_loss=0.56312 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 138 | train_loss=0.53684  val_loss=0.56002 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 139 | train_loss=0.54569  val_loss=0.54616 | train_MAE=0.7015  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 140 | train_loss=0.52336  val_loss=0.53758 | train_MAE=0.7313  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 141 | train_loss=0.54582  val_loss=0.55866 | train_MAE=0.7127  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 142 | train_loss=0.51369  val_loss=0.54753 | train_MAE=0.7257  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 143 | train_loss=0.55110  val_loss=0.58090 | train_MAE=0.7351  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 144 | train_loss=0.55968  val_loss=0.55308 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 145 | train_loss=0.55056  val_loss=0.53889 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 146 | train_loss=0.54105  val_loss=0.57443 | train_MAE=0.7313  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 147 | train_loss=0.53068  val_loss=0.55415 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 148 | train_loss=0.54023  val_loss=0.59556 | train_MAE=0.7127  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 149 | train_loss=0.52440  val_loss=0.56442 | train_MAE=0.7332  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 150 | train_loss=0.54205  val_loss=0.54495 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 151 | train_loss=0.53390  val_loss=0.55960 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 152 | train_loss=0.52036  val_loss=0.56646 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 153 | train_loss=0.53986  val_loss=0.54803 | train_MAE=0.6847  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 154 | train_loss=0.52602  val_loss=0.55176 | train_MAE=0.7369  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 155 | train_loss=0.53383  val_loss=0.56449 | train_MAE=0.7407  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 156 | train_loss=0.52097  val_loss=0.54823 | train_MAE=0.7276  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 157 | train_loss=0.53539  val_loss=0.56370 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 158 | train_loss=0.53442  val_loss=0.57027 | train_MAE=0.7276  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 159 | train_loss=0.50933  val_loss=0.56128 | train_MAE=0.7313  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 160 | train_loss=0.53520  val_loss=0.57377 | train_MAE=0.7146  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 161 | train_loss=0.51537  val_loss=0.56175 | train_MAE=0.7425  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 162 | train_loss=0.53342  val_loss=0.54724 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 163 | train_loss=0.51619  val_loss=0.56081 | train_MAE=0.7220  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 164 | train_loss=0.52921  val_loss=0.55776 | train_MAE=0.7425  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 165 | train_loss=0.53251  val_loss=0.56514 | train_MAE=0.7425  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 166 | train_loss=0.53501  val_loss=0.56257 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 167 | train_loss=0.52389  val_loss=0.55425 | train_MAE=0.7332  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 168 | train_loss=0.52364  val_loss=0.59230 | train_MAE=0.7201  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 169 | train_loss=0.51971  val_loss=0.56332 | train_MAE=0.7332  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 170 | train_loss=0.55179  val_loss=0.56929 | train_MAE=0.6847  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 171 | train_loss=0.51942  val_loss=0.56665 | train_MAE=0.7593  val_MAE=0.7043 | lr=0.01 | time=0.25s\n",
      "Epoch 172 | train_loss=0.54396  val_loss=0.58381 | train_MAE=0.7108  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 173 | train_loss=0.53068  val_loss=0.55709 | train_MAE=0.7146  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 174 | train_loss=0.53290  val_loss=0.54816 | train_MAE=0.7351  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 175 | train_loss=0.53201  val_loss=0.56386 | train_MAE=0.7108  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 176 | train_loss=0.53531  val_loss=0.56458 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 177 | train_loss=0.53077  val_loss=0.55686 | train_MAE=0.7407  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 178 | train_loss=0.54207  val_loss=0.56921 | train_MAE=0.7276  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 179 | train_loss=0.53313  val_loss=0.54907 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 180 | train_loss=0.53376  val_loss=0.55203 | train_MAE=0.7257  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 181 | train_loss=0.53410  val_loss=0.56889 | train_MAE=0.7276  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 182 | train_loss=0.52475  val_loss=0.57067 | train_MAE=0.7407  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 183 | train_loss=0.55128  val_loss=0.55611 | train_MAE=0.6884  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 184 | train_loss=0.52219  val_loss=0.54272 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 185 | train_loss=0.52182  val_loss=0.54960 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 186 | train_loss=0.52462  val_loss=0.55645 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 187 | train_loss=0.51688  val_loss=0.56282 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 188 | train_loss=0.50887  val_loss=0.55186 | train_MAE=0.7295  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 189 | train_loss=0.51873  val_loss=0.56936 | train_MAE=0.7201  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 190 | train_loss=0.54013  val_loss=0.55872 | train_MAE=0.7351  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 191 | train_loss=0.56308  val_loss=0.54831 | train_MAE=0.7276  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 192 | train_loss=0.52269  val_loss=0.57391 | train_MAE=0.7052  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 193 | train_loss=0.52563  val_loss=0.55335 | train_MAE=0.7276  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 194 | train_loss=0.52327  val_loss=0.58740 | train_MAE=0.7276  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 195 | train_loss=0.55495  val_loss=0.55580 | train_MAE=0.7388  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 196 | train_loss=0.53245  val_loss=0.57143 | train_MAE=0.7313  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 197 | train_loss=0.52755  val_loss=0.59139 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 198 | train_loss=0.52127  val_loss=0.59431 | train_MAE=0.7313  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 199 | train_loss=0.53760  val_loss=0.57816 | train_MAE=0.7015  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 200 | train_loss=0.53864  val_loss=0.56550 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Total training time: 16.75s\n",
      "\n",
      "Evaluating base model\n",
      "\n",
      "Base Model Results:\n",
      "  Test Accuracy: 0.6522\n",
      "  Precision: 0.5161\n",
      "  Recall: 0.3902\n",
      "  F1 Score: 0.4444\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Base model with best hyperparameters\")\n",
    "\n",
    "print(f\"Configuration: dropout={best_dropout}, lr={best_lr}, hidden_size={best_hidden}\")\n",
    "\n",
    "# Create base model with tuned hyperparameters\n",
    "base_model = NeuralNetworkFlexible(\n",
    "    hidden_size=best_hidden, \n",
    "    dropout=best_dropout\n",
    ").to(device)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(base_model.parameters(), lr=best_lr)\n",
    "\n",
    "# Train base model\n",
    "print(\"\\nTraining base model\")\n",
    "base_history = train_model(base_model, X_train_dl, X_val_dl, epochs=200)\n",
    "\n",
    "# Evaluate base model\n",
    "print(\"\\nEvaluating base model\")\n",
    "base_model.eval()\n",
    "total_loss, total_n = 0.0, 0\n",
    "all_logits, all_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in X_test_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = base_model(xb)\n",
    "        batch_loss = loss(logits, yb).item()\n",
    "        total_loss += batch_loss * xb.size(0)\n",
    "        total_n += xb.size(0)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_true.append(yb.cpu())\n",
    "\n",
    "base_test_loss = total_loss / total_n\n",
    "logits = torch.cat(all_logits).numpy().ravel()\n",
    "base_y_true = torch.cat(all_true).numpy().astype(int)\n",
    "base_probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "base_y_pred = (base_probs >= 0.5).astype(int)\n",
    "\n",
    "base_test_acc = accuracy_score(base_y_true, base_y_pred)\n",
    "base_prec, base_rec, base_f1, _ = precision_recall_fscore_support(\n",
    "    base_y_true, base_y_pred, average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "print(f\"\\nBase Model Results:\")\n",
    "print(f\"  Test Accuracy: {base_test_acc:.4f}\")\n",
    "print(f\"  Precision: {base_prec:.4f}\")\n",
    "print(f\"  Recall: {base_rec:.4f}\")\n",
    "print(f\"  F1 Score: {base_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef89deee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVEMENT METHOD 1: EARLY STOPPING\n",
      "\n",
      "Training with early stopping (patience=20)...\n",
      "EarlyStopping counter: 1/20\n",
      "EarlyStopping counter: 2/20\n",
      "EarlyStopping counter: 1/20\n",
      "EarlyStopping counter: 2/20\n",
      "EarlyStopping counter: 3/20\n",
      "EarlyStopping counter: 4/20\n",
      "EarlyStopping counter: 1/20\n",
      "EarlyStopping counter: 2/20\n",
      "EarlyStopping counter: 3/20\n",
      "Epoch 020 | train_loss=0.59472 val_loss=0.57797 | train_acc=0.6642 val_acc=0.7217\n",
      "EarlyStopping counter: 4/20\n",
      "EarlyStopping counter: 5/20\n",
      "EarlyStopping counter: 6/20\n",
      "EarlyStopping counter: 7/20\n",
      "EarlyStopping counter: 1/20\n",
      "EarlyStopping counter: 2/20\n",
      "EarlyStopping counter: 3/20\n",
      "EarlyStopping counter: 4/20\n",
      "EarlyStopping counter: 5/20\n",
      "EarlyStopping counter: 6/20\n",
      "EarlyStopping counter: 1/20\n",
      "EarlyStopping counter: 2/20\n",
      "EarlyStopping counter: 3/20\n",
      "EarlyStopping counter: 4/20\n",
      "EarlyStopping counter: 5/20\n",
      "EarlyStopping counter: 1/20\n",
      "Epoch 040 | train_loss=0.57114 val_loss=0.56699 | train_acc=0.7034 val_acc=0.7391\n",
      "EarlyStopping counter: 1/20\n",
      "EarlyStopping counter: 2/20\n",
      "EarlyStopping counter: 3/20\n",
      "EarlyStopping counter: 4/20\n",
      "EarlyStopping counter: 5/20\n",
      "EarlyStopping counter: 1/20\n",
      "EarlyStopping counter: 2/20\n",
      "EarlyStopping counter: 3/20\n",
      "EarlyStopping counter: 4/20\n",
      "EarlyStopping counter: 5/20\n",
      "EarlyStopping counter: 6/20\n",
      "EarlyStopping counter: 7/20\n",
      "EarlyStopping counter: 8/20\n",
      "EarlyStopping counter: 9/20\n",
      "EarlyStopping counter: 10/20\n",
      "EarlyStopping counter: 11/20\n",
      "EarlyStopping counter: 12/20\n",
      "EarlyStopping counter: 13/20\n",
      "EarlyStopping counter: 14/20\n",
      "Epoch 060 | train_loss=0.58034 val_loss=0.57907 | train_acc=0.7071 val_acc=0.7304\n",
      "EarlyStopping counter: 15/20\n",
      "EarlyStopping counter: 16/20\n",
      "EarlyStopping counter: 17/20\n",
      "EarlyStopping counter: 18/20\n",
      "EarlyStopping counter: 19/20\n",
      "EarlyStopping counter: 20/20\n",
      "\n",
      "Early stopping triggered at epoch 65\n",
      "Total training time: 5.49s\n",
      "\n",
      "Early Stopping Results:\n",
      "  Test Accuracy: 0.6435\n",
      "  Precision: 0.5000\n",
      "  Recall: 0.3659\n",
      "  F1 Score: 0.4225, Epochs Trained: 65\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"IMPROVEMENT METHOD 1: EARLY STOPPING\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=20, min_delta=1e-6, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.verbose = verbose\n",
    "        self.best_model = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            \n",
    "            print(f'EarlyStopping counter: {self.counter}/{self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            self.counter = 0\n",
    "\n",
    "# Modified training function with early stopping\n",
    "def train_model_with_early_stopping(model, train_dl, val_dl, loss_fn, optimizer, \n",
    "                                     epochs=200, patience=20):\n",
    "    history = {\n",
    "        \"train_loss\": [], \"val_loss\": [], \n",
    "        \"train_acc\": [], \"val_acc\": [], \n",
    "        \"epoch_time_sec\": []\n",
    "    }\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = epoch_step(train_dl, model, loss_fn, optimizer=optimizer)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc = epoch_step(val_dl, model, loss_fn, optimizer=None)\n",
    "        \n",
    "        epoch_time = time.time() - t0\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"epoch_time_sec\"].append(epoch_time)\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch:03d} | train_loss={train_loss:.5f} val_loss={val_loss:.5f} | \"\n",
    "                  f\"train_acc={train_acc:.4f} val_acc={val_acc:.4f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"\\nEarly stopping triggered at epoch {epoch}\")\n",
    "            model.load_state_dict({k: v.to(device) for k, v in early_stopping.best_model.items()})\n",
    "            break\n",
    "    \n",
    "    print(f\"Total training time: {sum(history['epoch_time_sec']):.2f}s\")\n",
    "    return history\n",
    "\n",
    "# Create model with early stopping\n",
    "model_es = NeuralNetworkFlexible(hidden_size=best_hidden, dropout=best_dropout).to(device)\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_es.parameters(), lr=best_lr)\n",
    "\n",
    "print(\"\\nTraining with early stopping (patience=20)...\")\n",
    "es_history = train_model_with_early_stopping(model_es, X_train_dl, X_val_dl, loss, optimizer, \n",
    "                                             epochs=200, patience=20)\n",
    "\n",
    "# Evaluate\n",
    "model_es.eval()\n",
    "total_loss, total_n = 0.0, 0\n",
    "all_logits, all_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in X_test_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model_es(xb)\n",
    "        batch_loss = loss(logits, yb).item()\n",
    "        total_loss += batch_loss * xb.size(0)\n",
    "        total_n += xb.size(0)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_true.append(yb.cpu())\n",
    "\n",
    "es_test_loss = total_loss / total_n\n",
    "logits = torch.cat(all_logits).numpy().ravel()\n",
    "es_y_true = torch.cat(all_true).numpy().astype(int)\n",
    "es_probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "es_y_pred = (es_probs >= 0.5).astype(int)\n",
    "\n",
    "es_test_acc = accuracy_score(es_y_true, es_y_pred)\n",
    "es_prec, es_rec, es_f1, _ = precision_recall_fscore_support(\n",
    "    es_y_true, es_y_pred, average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "print(f\"\\nEarly Stopping Results:\")\n",
    "print(f\"  Test Accuracy: {es_test_acc:.4f}\")\n",
    "print(f\"  Precision: {es_prec:.4f}\")\n",
    "print(f\"  Recall: {es_rec:.4f}\")\n",
    "print(f\"  F1 Score: {es_f1:.4f}, Epochs Trained: {len(es_history['train_loss'])}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d318095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVEMENT METHOD 2: LEARNING RATE SCHEDULER\n",
      "\n",
      "Training with learning rate scheduler\n",
      "Scheduler: ReduceLROnPlateau (factor=0.5, patience=10)\n",
      "Epoch 020 | train_loss=0.58885 val_loss=0.60263 | train_acc=0.6754 val_acc=0.7217 | lr=0.010000\n",
      "Epoch 040 | train_loss=0.55687 val_loss=0.58283 | train_acc=0.7108 val_acc=0.7478 | lr=0.005000\n",
      "Epoch 060 | train_loss=0.52396 val_loss=0.61556 | train_acc=0.7034 val_acc=0.7217 | lr=0.001250\n",
      "Epoch 080 | train_loss=0.50703 val_loss=0.63458 | train_acc=0.7313 val_acc=0.7130 | lr=0.000313\n",
      "Epoch 100 | train_loss=0.50391 val_loss=0.63434 | train_acc=0.7295 val_acc=0.7304 | lr=0.000156\n",
      "Epoch 120 | train_loss=0.50641 val_loss=0.63659 | train_acc=0.7519 val_acc=0.7217 | lr=0.000039\n",
      "Epoch 140 | train_loss=0.50694 val_loss=0.63623 | train_acc=0.7425 val_acc=0.7130 | lr=0.000010\n",
      "Epoch 160 | train_loss=0.50071 val_loss=0.63599 | train_acc=0.7425 val_acc=0.7217 | lr=0.000002\n",
      "Epoch 180 | train_loss=0.51592 val_loss=0.63586 | train_acc=0.7295 val_acc=0.7217 | lr=0.000001\n",
      "Epoch 200 | train_loss=0.49465 val_loss=0.63584 | train_acc=0.7593 val_acc=0.7217 | lr=0.000000\n",
      "Total training time: 16.67s\n",
      "\n",
      "Learning Rate Scheduler Results:\n",
      "  Test Accuracy: 0.6783\n",
      "  Precision: 0.5909\n",
      "  Recall: 0.3171\n",
      "  F1 Score: 0.4127, Training Time: 16.67s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"IMPROVEMENT METHOD 2: LEARNING RATE SCHEDULER\")\n",
    "\n",
    "\n",
    "# Modified training function with scheduler\n",
    "def train_model_with_scheduler(model, train_dl, val_dl, loss_fn, optimizer, \n",
    "                               scheduler, epochs=200):\n",
    "    history = {\n",
    "        \"train_loss\": [], \"val_loss\": [], \n",
    "        \"train_acc\": [], \"val_acc\": [], \n",
    "        \"epoch_time_sec\": [], \"lr\": []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = epoch_step(train_dl, model, loss_fn, optimizer=optimizer)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc = epoch_step(val_dl, model, loss_fn, optimizer=None)\n",
    "        \n",
    "        # Step scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        epoch_time = time.time() - t0\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"epoch_time_sec\"].append(epoch_time)\n",
    "        history[\"lr\"].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch:03d} | train_loss={train_loss:.5f} val_loss={val_loss:.5f} | \"\n",
    "                  f\"train_acc={train_acc:.4f} val_acc={val_acc:.4f} | lr={history['lr'][-1]:.6f}\")\n",
    "    \n",
    "    print(f\"Total training time: {sum(history['epoch_time_sec']):.2f}s\")\n",
    "    return history\n",
    "\n",
    "# Create model with scheduler\n",
    "model_sched = NeuralNetworkFlexible(hidden_size=best_hidden, dropout=best_dropout).to(device)\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_sched.parameters(), lr=best_lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=10\n",
    ")\n",
    "\n",
    "print(\"\\nTraining with learning rate scheduler\")\n",
    "print(\"Scheduler: ReduceLROnPlateau (factor=0.5, patience=10)\")\n",
    "sched_history = train_model_with_scheduler(model_sched, X_train_dl, X_val_dl, loss, optimizer, \n",
    "                                          scheduler, epochs=200)\n",
    "\n",
    "# Evaluate\n",
    "model_sched.eval()\n",
    "total_loss, total_n = 0.0, 0\n",
    "all_logits, all_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in X_test_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model_sched(xb)\n",
    "        batch_loss = loss(logits, yb).item()\n",
    "        total_loss += batch_loss * xb.size(0)\n",
    "        total_n += xb.size(0)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_true.append(yb.cpu())\n",
    "\n",
    "sched_test_loss = total_loss / total_n\n",
    "logits = torch.cat(all_logits).numpy().ravel()\n",
    "sched_y_true = torch.cat(all_true).numpy().astype(int)\n",
    "sched_probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "sched_y_pred = (sched_probs >= 0.5).astype(int)\n",
    "\n",
    "sched_test_acc = accuracy_score(sched_y_true, sched_y_pred)\n",
    "sched_prec, sched_rec, sched_f1, _ = precision_recall_fscore_support(\n",
    "    sched_y_true, sched_y_pred, average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "print(f\"\\nLearning Rate Scheduler Results:\")\n",
    "print(f\"  Test Accuracy: {sched_test_acc:.4f}\")\n",
    "print(f\"  Precision: {sched_prec:.4f}\")\n",
    "print(f\"  Recall: {sched_rec:.4f}\")\n",
    "print(f\"  F1 Score: {sched_f1:.4f}, Training Time: {sum(sched_history['epoch_time_sec']):.2f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2aae610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVEMENT METHOD 3: BATCH NORMALIZATION\n",
      "\n",
      "Training with batch normalization\n",
      "Epoch 001 | train_loss=0.63677  val_loss=0.81015 | train_MAE=0.6138  val_MAE=0.3565 | lr=0.01 | time=0.92s\n",
      "Epoch 002 | train_loss=0.56303  val_loss=0.65192 | train_MAE=0.7164  val_MAE=0.6348 | lr=0.01 | time=0.09s\n",
      "Epoch 003 | train_loss=0.55469  val_loss=0.48911 | train_MAE=0.7239  val_MAE=0.7826 | lr=0.01 | time=0.10s\n",
      "Epoch 004 | train_loss=0.54720  val_loss=0.47095 | train_MAE=0.7239  val_MAE=0.7565 | lr=0.01 | time=0.09s\n",
      "Epoch 005 | train_loss=0.52977  val_loss=0.44702 | train_MAE=0.7519  val_MAE=0.7826 | lr=0.01 | time=0.09s\n",
      "Epoch 006 | train_loss=0.52278  val_loss=0.45184 | train_MAE=0.7295  val_MAE=0.7739 | lr=0.01 | time=0.09s\n",
      "Epoch 007 | train_loss=0.51567  val_loss=0.49986 | train_MAE=0.7351  val_MAE=0.7478 | lr=0.01 | time=0.10s\n",
      "Epoch 008 | train_loss=0.52161  val_loss=0.45552 | train_MAE=0.7388  val_MAE=0.7739 | lr=0.01 | time=0.09s\n",
      "Epoch 009 | train_loss=0.51290  val_loss=0.45834 | train_MAE=0.7668  val_MAE=0.7478 | lr=0.01 | time=0.09s\n",
      "Epoch 010 | train_loss=0.48887  val_loss=0.45683 | train_MAE=0.7556  val_MAE=0.7913 | lr=0.01 | time=0.10s\n",
      "Epoch 011 | train_loss=0.49242  val_loss=0.46513 | train_MAE=0.7425  val_MAE=0.7826 | lr=0.01 | time=0.09s\n",
      "Epoch 012 | train_loss=0.51625  val_loss=0.43862 | train_MAE=0.7332  val_MAE=0.7739 | lr=0.01 | time=0.09s\n",
      "Epoch 013 | train_loss=0.51845  val_loss=0.44460 | train_MAE=0.7425  val_MAE=0.7913 | lr=0.01 | time=0.09s\n",
      "Epoch 014 | train_loss=0.51414  val_loss=0.44181 | train_MAE=0.7519  val_MAE=0.8174 | lr=0.01 | time=0.09s\n",
      "Epoch 015 | train_loss=0.50767  val_loss=0.47319 | train_MAE=0.7388  val_MAE=0.7826 | lr=0.01 | time=0.09s\n",
      "Epoch 016 | train_loss=0.49502  val_loss=0.50601 | train_MAE=0.7612  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 017 | train_loss=0.51869  val_loss=0.46482 | train_MAE=0.7463  val_MAE=0.7826 | lr=0.01 | time=0.09s\n",
      "Epoch 018 | train_loss=0.49373  val_loss=0.46034 | train_MAE=0.7575  val_MAE=0.7913 | lr=0.01 | time=0.09s\n",
      "Epoch 019 | train_loss=0.50668  val_loss=0.47972 | train_MAE=0.7500  val_MAE=0.7565 | lr=0.01 | time=0.10s\n",
      "Epoch 020 | train_loss=0.49455  val_loss=0.51188 | train_MAE=0.7556  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 021 | train_loss=0.49445  val_loss=0.46650 | train_MAE=0.7724  val_MAE=0.7565 | lr=0.01 | time=0.10s\n",
      "Epoch 022 | train_loss=0.47826  val_loss=0.48194 | train_MAE=0.7556  val_MAE=0.7739 | lr=0.01 | time=0.12s\n",
      "Epoch 023 | train_loss=0.49077  val_loss=0.45783 | train_MAE=0.7743  val_MAE=0.7652 | lr=0.01 | time=0.10s\n",
      "Epoch 024 | train_loss=0.48685  val_loss=0.47421 | train_MAE=0.7668  val_MAE=0.7478 | lr=0.01 | time=0.10s\n",
      "Epoch 025 | train_loss=0.48496  val_loss=0.50476 | train_MAE=0.7687  val_MAE=0.7478 | lr=0.01 | time=0.09s\n",
      "Epoch 026 | train_loss=0.49743  val_loss=0.45195 | train_MAE=0.7500  val_MAE=0.7826 | lr=0.01 | time=0.09s\n",
      "Epoch 027 | train_loss=0.47807  val_loss=0.47680 | train_MAE=0.7705  val_MAE=0.7565 | lr=0.01 | time=0.11s\n",
      "Epoch 028 | train_loss=0.46945  val_loss=0.47398 | train_MAE=0.7724  val_MAE=0.7565 | lr=0.01 | time=0.10s\n",
      "Epoch 029 | train_loss=0.49127  val_loss=0.50453 | train_MAE=0.7705  val_MAE=0.7478 | lr=0.01 | time=0.10s\n",
      "Epoch 030 | train_loss=0.49948  val_loss=0.53723 | train_MAE=0.7724  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 031 | train_loss=0.49991  val_loss=0.52631 | train_MAE=0.7556  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 032 | train_loss=0.49618  val_loss=0.50468 | train_MAE=0.7537  val_MAE=0.7478 | lr=0.01 | time=0.10s\n",
      "Epoch 033 | train_loss=0.49139  val_loss=0.45979 | train_MAE=0.7295  val_MAE=0.7739 | lr=0.01 | time=0.10s\n",
      "Epoch 034 | train_loss=0.47350  val_loss=0.50528 | train_MAE=0.7743  val_MAE=0.7478 | lr=0.01 | time=0.10s\n",
      "Epoch 035 | train_loss=0.48437  val_loss=0.49824 | train_MAE=0.7649  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 036 | train_loss=0.48127  val_loss=0.46581 | train_MAE=0.7500  val_MAE=0.7565 | lr=0.01 | time=0.10s\n",
      "Epoch 037 | train_loss=0.47342  val_loss=0.49024 | train_MAE=0.7425  val_MAE=0.7652 | lr=0.01 | time=0.10s\n",
      "Epoch 038 | train_loss=0.50390  val_loss=0.49832 | train_MAE=0.7593  val_MAE=0.7478 | lr=0.01 | time=0.10s\n",
      "Epoch 039 | train_loss=0.47981  val_loss=0.52584 | train_MAE=0.7799  val_MAE=0.7478 | lr=0.01 | time=0.10s\n",
      "Epoch 040 | train_loss=0.50106  val_loss=0.50956 | train_MAE=0.7631  val_MAE=0.7130 | lr=0.01 | time=0.12s\n",
      "Epoch 041 | train_loss=0.50587  val_loss=0.48913 | train_MAE=0.7519  val_MAE=0.7565 | lr=0.01 | time=0.10s\n",
      "Epoch 042 | train_loss=0.47927  val_loss=0.49561 | train_MAE=0.7892  val_MAE=0.7478 | lr=0.01 | time=0.10s\n",
      "Epoch 043 | train_loss=0.49038  val_loss=0.49874 | train_MAE=0.7500  val_MAE=0.7478 | lr=0.01 | time=0.11s\n",
      "Epoch 044 | train_loss=0.47044  val_loss=0.53311 | train_MAE=0.7631  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 045 | train_loss=0.48265  val_loss=0.51547 | train_MAE=0.7500  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 046 | train_loss=0.45861  val_loss=0.49510 | train_MAE=0.7649  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 047 | train_loss=0.50957  val_loss=0.50789 | train_MAE=0.7519  val_MAE=0.7391 | lr=0.01 | time=0.16s\n",
      "Epoch 048 | train_loss=0.49583  val_loss=0.50066 | train_MAE=0.7537  val_MAE=0.7478 | lr=0.01 | time=0.10s\n",
      "Epoch 049 | train_loss=0.48272  val_loss=0.49691 | train_MAE=0.7463  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 050 | train_loss=0.47387  val_loss=0.50300 | train_MAE=0.7687  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 051 | train_loss=0.47563  val_loss=0.53398 | train_MAE=0.7612  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 052 | train_loss=0.48429  val_loss=0.50517 | train_MAE=0.7705  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 053 | train_loss=0.45170  val_loss=0.51350 | train_MAE=0.7780  val_MAE=0.7391 | lr=0.01 | time=0.11s\n",
      "Epoch 054 | train_loss=0.45419  val_loss=0.54066 | train_MAE=0.7631  val_MAE=0.7478 | lr=0.01 | time=0.11s\n",
      "Epoch 055 | train_loss=0.47768  val_loss=0.53612 | train_MAE=0.7612  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 056 | train_loss=0.47088  val_loss=0.55786 | train_MAE=0.7854  val_MAE=0.7130 | lr=0.01 | time=0.10s\n",
      "Epoch 057 | train_loss=0.48066  val_loss=0.51838 | train_MAE=0.7799  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 058 | train_loss=0.46384  val_loss=0.47489 | train_MAE=0.7780  val_MAE=0.7565 | lr=0.01 | time=0.09s\n",
      "Epoch 059 | train_loss=0.49117  val_loss=0.49363 | train_MAE=0.7649  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 060 | train_loss=0.47923  val_loss=0.49170 | train_MAE=0.7500  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 061 | train_loss=0.48254  val_loss=0.49455 | train_MAE=0.7500  val_MAE=0.7478 | lr=0.01 | time=0.10s\n",
      "Epoch 062 | train_loss=0.47971  val_loss=0.52807 | train_MAE=0.7817  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 063 | train_loss=0.49178  val_loss=0.51560 | train_MAE=0.7631  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 064 | train_loss=0.44986  val_loss=0.52295 | train_MAE=0.7854  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 065 | train_loss=0.47074  val_loss=0.50814 | train_MAE=0.7724  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 066 | train_loss=0.47915  val_loss=0.50687 | train_MAE=0.7612  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 067 | train_loss=0.47272  val_loss=0.52333 | train_MAE=0.7631  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 068 | train_loss=0.46482  val_loss=0.57799 | train_MAE=0.7743  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 069 | train_loss=0.46345  val_loss=0.60214 | train_MAE=0.7799  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 070 | train_loss=0.47880  val_loss=0.52603 | train_MAE=0.7649  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 071 | train_loss=0.47744  val_loss=0.49871 | train_MAE=0.7724  val_MAE=0.7478 | lr=0.01 | time=0.09s\n",
      "Epoch 072 | train_loss=0.46343  val_loss=0.52202 | train_MAE=0.7799  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 073 | train_loss=0.49076  val_loss=0.53360 | train_MAE=0.7575  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 074 | train_loss=0.47808  val_loss=0.53706 | train_MAE=0.7761  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 075 | train_loss=0.48025  val_loss=0.53272 | train_MAE=0.7743  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 076 | train_loss=0.47218  val_loss=0.56379 | train_MAE=0.7854  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 077 | train_loss=0.48950  val_loss=0.51737 | train_MAE=0.7500  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 078 | train_loss=0.47949  val_loss=0.60004 | train_MAE=0.7612  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 079 | train_loss=0.47929  val_loss=0.56636 | train_MAE=0.7854  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 080 | train_loss=0.48922  val_loss=0.52693 | train_MAE=0.7687  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 081 | train_loss=0.49523  val_loss=0.48945 | train_MAE=0.7463  val_MAE=0.7478 | lr=0.01 | time=0.09s\n",
      "Epoch 082 | train_loss=0.47760  val_loss=0.52667 | train_MAE=0.7743  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 083 | train_loss=0.46759  val_loss=0.54142 | train_MAE=0.7668  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 084 | train_loss=0.46455  val_loss=0.53563 | train_MAE=0.7631  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 085 | train_loss=0.46299  val_loss=0.54383 | train_MAE=0.7799  val_MAE=0.7478 | lr=0.01 | time=0.09s\n",
      "Epoch 086 | train_loss=0.48490  val_loss=0.54616 | train_MAE=0.7631  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 087 | train_loss=0.46270  val_loss=0.54047 | train_MAE=0.7854  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 088 | train_loss=0.47335  val_loss=0.54444 | train_MAE=0.7649  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 089 | train_loss=0.45857  val_loss=0.56830 | train_MAE=0.7724  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 090 | train_loss=0.47585  val_loss=0.56521 | train_MAE=0.7631  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 091 | train_loss=0.45944  val_loss=0.57462 | train_MAE=0.7836  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 092 | train_loss=0.46794  val_loss=0.55761 | train_MAE=0.7892  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 093 | train_loss=0.46488  val_loss=0.55589 | train_MAE=0.7705  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 094 | train_loss=0.46897  val_loss=0.54938 | train_MAE=0.7724  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 095 | train_loss=0.48154  val_loss=0.51928 | train_MAE=0.7724  val_MAE=0.7565 | lr=0.01 | time=0.09s\n",
      "Epoch 096 | train_loss=0.45653  val_loss=0.47880 | train_MAE=0.7724  val_MAE=0.7739 | lr=0.01 | time=0.09s\n",
      "Epoch 097 | train_loss=0.47485  val_loss=0.48604 | train_MAE=0.7687  val_MAE=0.7565 | lr=0.01 | time=0.10s\n",
      "Epoch 098 | train_loss=0.45870  val_loss=0.55303 | train_MAE=0.7724  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 099 | train_loss=0.47785  val_loss=0.59425 | train_MAE=0.7537  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 100 | train_loss=0.47433  val_loss=0.51301 | train_MAE=0.7836  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 101 | train_loss=0.47142  val_loss=0.51787 | train_MAE=0.7724  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 102 | train_loss=0.45281  val_loss=0.61481 | train_MAE=0.7854  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 103 | train_loss=0.47582  val_loss=0.56234 | train_MAE=0.7687  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 104 | train_loss=0.45401  val_loss=0.55561 | train_MAE=0.7724  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 105 | train_loss=0.47004  val_loss=0.59920 | train_MAE=0.7724  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 106 | train_loss=0.46474  val_loss=0.60753 | train_MAE=0.7817  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 107 | train_loss=0.44636  val_loss=0.56265 | train_MAE=0.7873  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 108 | train_loss=0.46049  val_loss=0.57001 | train_MAE=0.7668  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 109 | train_loss=0.46368  val_loss=0.60418 | train_MAE=0.7761  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 110 | train_loss=0.44308  val_loss=0.60736 | train_MAE=0.7724  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 111 | train_loss=0.46916  val_loss=0.58567 | train_MAE=0.7649  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 112 | train_loss=0.44694  val_loss=0.54583 | train_MAE=0.7612  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 113 | train_loss=0.47478  val_loss=0.48812 | train_MAE=0.7854  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 114 | train_loss=0.45675  val_loss=0.50471 | train_MAE=0.7743  val_MAE=0.7478 | lr=0.01 | time=0.09s\n",
      "Epoch 115 | train_loss=0.47218  val_loss=0.54650 | train_MAE=0.7687  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 116 | train_loss=0.45747  val_loss=0.61643 | train_MAE=0.7724  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 117 | train_loss=0.46189  val_loss=0.61504 | train_MAE=0.7705  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 118 | train_loss=0.45768  val_loss=0.57849 | train_MAE=0.7724  val_MAE=0.6957 | lr=0.01 | time=0.10s\n",
      "Epoch 119 | train_loss=0.46086  val_loss=0.58334 | train_MAE=0.7799  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 120 | train_loss=0.44304  val_loss=0.57462 | train_MAE=0.8060  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 121 | train_loss=0.43783  val_loss=0.58350 | train_MAE=0.8004  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 122 | train_loss=0.46636  val_loss=0.59791 | train_MAE=0.7724  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 123 | train_loss=0.47366  val_loss=0.55881 | train_MAE=0.7724  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 124 | train_loss=0.46488  val_loss=0.58076 | train_MAE=0.7780  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 125 | train_loss=0.43428  val_loss=0.57737 | train_MAE=0.7854  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 126 | train_loss=0.46390  val_loss=0.55456 | train_MAE=0.7705  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 127 | train_loss=0.43083  val_loss=0.58124 | train_MAE=0.7854  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 128 | train_loss=0.45006  val_loss=0.59698 | train_MAE=0.7668  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 129 | train_loss=0.46792  val_loss=0.57562 | train_MAE=0.7687  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 130 | train_loss=0.46718  val_loss=0.54477 | train_MAE=0.7780  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 131 | train_loss=0.46840  val_loss=0.57110 | train_MAE=0.7631  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 132 | train_loss=0.45988  val_loss=0.55416 | train_MAE=0.7724  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 133 | train_loss=0.45601  val_loss=0.55746 | train_MAE=0.7649  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 134 | train_loss=0.45785  val_loss=0.66185 | train_MAE=0.7612  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 135 | train_loss=0.46113  val_loss=0.65527 | train_MAE=0.7743  val_MAE=0.6957 | lr=0.01 | time=0.10s\n",
      "Epoch 136 | train_loss=0.44172  val_loss=0.58741 | train_MAE=0.7743  val_MAE=0.7130 | lr=0.01 | time=0.10s\n",
      "Epoch 137 | train_loss=0.47597  val_loss=0.55841 | train_MAE=0.7799  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 138 | train_loss=0.45863  val_loss=0.57367 | train_MAE=0.7761  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 139 | train_loss=0.46561  val_loss=0.66014 | train_MAE=0.7612  val_MAE=0.7043 | lr=0.01 | time=0.10s\n",
      "Epoch 140 | train_loss=0.47020  val_loss=0.61446 | train_MAE=0.7724  val_MAE=0.7043 | lr=0.01 | time=0.10s\n",
      "Epoch 141 | train_loss=0.45597  val_loss=0.56043 | train_MAE=0.7780  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 142 | train_loss=0.45285  val_loss=0.64808 | train_MAE=0.7631  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 143 | train_loss=0.45216  val_loss=0.70839 | train_MAE=0.7649  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 144 | train_loss=0.46009  val_loss=0.66890 | train_MAE=0.7817  val_MAE=0.6957 | lr=0.01 | time=0.10s\n",
      "Epoch 145 | train_loss=0.46028  val_loss=0.67082 | train_MAE=0.7799  val_MAE=0.6957 | lr=0.01 | time=0.10s\n",
      "Epoch 146 | train_loss=0.44305  val_loss=0.69595 | train_MAE=0.7836  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 147 | train_loss=0.46613  val_loss=0.56420 | train_MAE=0.7817  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 148 | train_loss=0.44297  val_loss=0.53956 | train_MAE=0.7873  val_MAE=0.7478 | lr=0.01 | time=0.10s\n",
      "Epoch 149 | train_loss=0.46647  val_loss=0.60934 | train_MAE=0.7705  val_MAE=0.6957 | lr=0.01 | time=0.10s\n",
      "Epoch 150 | train_loss=0.45161  val_loss=0.65254 | train_MAE=0.7780  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 151 | train_loss=0.47255  val_loss=0.57485 | train_MAE=0.7687  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 152 | train_loss=0.44034  val_loss=0.57860 | train_MAE=0.7892  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 153 | train_loss=0.46889  val_loss=0.58664 | train_MAE=0.7761  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 154 | train_loss=0.46137  val_loss=0.60447 | train_MAE=0.7743  val_MAE=0.7130 | lr=0.01 | time=0.10s\n",
      "Epoch 155 | train_loss=0.43711  val_loss=0.65948 | train_MAE=0.7910  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 156 | train_loss=0.45182  val_loss=0.73679 | train_MAE=0.7761  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 157 | train_loss=0.46490  val_loss=0.73320 | train_MAE=0.7799  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 158 | train_loss=0.45519  val_loss=0.65040 | train_MAE=0.7687  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 159 | train_loss=0.45834  val_loss=0.59913 | train_MAE=0.7668  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 160 | train_loss=0.43731  val_loss=0.65639 | train_MAE=0.7799  val_MAE=0.6870 | lr=0.01 | time=0.09s\n",
      "Epoch 161 | train_loss=0.43390  val_loss=0.65279 | train_MAE=0.7892  val_MAE=0.7043 | lr=0.01 | time=0.10s\n",
      "Epoch 162 | train_loss=0.43990  val_loss=0.68680 | train_MAE=0.7743  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 163 | train_loss=0.45260  val_loss=0.62324 | train_MAE=0.7761  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 164 | train_loss=0.46936  val_loss=0.58220 | train_MAE=0.7799  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 165 | train_loss=0.44782  val_loss=0.60951 | train_MAE=0.7724  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 166 | train_loss=0.44469  val_loss=0.60307 | train_MAE=0.7593  val_MAE=0.7304 | lr=0.01 | time=0.10s\n",
      "Epoch 167 | train_loss=0.45785  val_loss=0.55761 | train_MAE=0.7948  val_MAE=0.7478 | lr=0.01 | time=0.10s\n",
      "Epoch 168 | train_loss=0.44910  val_loss=0.59145 | train_MAE=0.7817  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 169 | train_loss=0.44015  val_loss=0.67934 | train_MAE=0.7892  val_MAE=0.6957 | lr=0.01 | time=0.10s\n",
      "Epoch 170 | train_loss=0.44529  val_loss=0.68414 | train_MAE=0.7780  val_MAE=0.7043 | lr=0.01 | time=0.10s\n",
      "Epoch 171 | train_loss=0.44125  val_loss=0.58523 | train_MAE=0.7910  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 172 | train_loss=0.43355  val_loss=0.64543 | train_MAE=0.7817  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 173 | train_loss=0.48104  val_loss=0.65838 | train_MAE=0.7668  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 174 | train_loss=0.45203  val_loss=0.58507 | train_MAE=0.7780  val_MAE=0.6957 | lr=0.01 | time=0.10s\n",
      "Epoch 175 | train_loss=0.45082  val_loss=0.58705 | train_MAE=0.7799  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 176 | train_loss=0.43524  val_loss=0.61023 | train_MAE=0.7892  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 177 | train_loss=0.43379  val_loss=0.70928 | train_MAE=0.7854  val_MAE=0.6870 | lr=0.01 | time=0.09s\n",
      "Epoch 178 | train_loss=0.44260  val_loss=0.72140 | train_MAE=0.7649  val_MAE=0.6783 | lr=0.01 | time=0.09s\n",
      "Epoch 179 | train_loss=0.45092  val_loss=0.77178 | train_MAE=0.7687  val_MAE=0.6783 | lr=0.01 | time=0.09s\n",
      "Epoch 180 | train_loss=0.43699  val_loss=0.73029 | train_MAE=0.7854  val_MAE=0.6870 | lr=0.01 | time=0.09s\n",
      "Epoch 181 | train_loss=0.44354  val_loss=0.70280 | train_MAE=0.7705  val_MAE=0.7043 | lr=0.01 | time=0.10s\n",
      "Epoch 182 | train_loss=0.46147  val_loss=0.60777 | train_MAE=0.7817  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 183 | train_loss=0.45206  val_loss=0.63160 | train_MAE=0.7556  val_MAE=0.7043 | lr=0.01 | time=0.10s\n",
      "Epoch 184 | train_loss=0.43577  val_loss=0.59636 | train_MAE=0.7854  val_MAE=0.7130 | lr=0.01 | time=0.18s\n",
      "Epoch 185 | train_loss=0.42444  val_loss=0.68987 | train_MAE=0.7966  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 186 | train_loss=0.44261  val_loss=0.68040 | train_MAE=0.7780  val_MAE=0.6870 | lr=0.01 | time=0.09s\n",
      "Epoch 187 | train_loss=0.44328  val_loss=0.65225 | train_MAE=0.7948  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 188 | train_loss=0.45425  val_loss=0.56149 | train_MAE=0.7705  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 189 | train_loss=0.46080  val_loss=0.52696 | train_MAE=0.7743  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 190 | train_loss=0.46056  val_loss=0.57524 | train_MAE=0.7817  val_MAE=0.7043 | lr=0.01 | time=0.10s\n",
      "Epoch 191 | train_loss=0.44627  val_loss=0.64623 | train_MAE=0.7761  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 192 | train_loss=0.44036  val_loss=0.65981 | train_MAE=0.7910  val_MAE=0.7130 | lr=0.01 | time=0.10s\n",
      "Epoch 193 | train_loss=0.44385  val_loss=0.65946 | train_MAE=0.7668  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 194 | train_loss=0.48146  val_loss=0.66135 | train_MAE=0.7836  val_MAE=0.7043 | lr=0.01 | time=0.10s\n",
      "Epoch 195 | train_loss=0.45175  val_loss=0.63065 | train_MAE=0.7761  val_MAE=0.7043 | lr=0.01 | time=0.11s\n",
      "Epoch 196 | train_loss=0.44522  val_loss=0.65116 | train_MAE=0.7761  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 197 | train_loss=0.44449  val_loss=0.57787 | train_MAE=0.8022  val_MAE=0.7043 | lr=0.01 | time=0.10s\n",
      "Epoch 198 | train_loss=0.44945  val_loss=0.61586 | train_MAE=0.7761  val_MAE=0.7043 | lr=0.01 | time=0.10s\n",
      "Epoch 199 | train_loss=0.44318  val_loss=0.66043 | train_MAE=0.7705  val_MAE=0.6957 | lr=0.01 | time=0.09s\n",
      "Epoch 200 | train_loss=0.46133  val_loss=0.60003 | train_MAE=0.7854  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Total training time: 20.18s\n",
      "\n",
      "Batch Normalization Results:\n",
      "  Test Accuracy: 0.6870\n",
      "  Precision: 0.5714\n",
      "  Recall: 0.4878\n",
      "  F1 Score: 0.5263\n",
      "  Training Time: 20.18s, Improvement over base: +3.48%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"IMPROVEMENT METHOD 3: BATCH NORMALIZATION\")\n",
    "\n",
    "\n",
    "# Create model with batch normalization\n",
    "model_bn = NeuralNetworkFlexible(\n",
    "    hidden_size=best_hidden, \n",
    "    dropout=best_dropout,\n",
    "    use_batchnorm=True\n",
    ").to(device)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_bn.parameters(), lr=best_lr)\n",
    "\n",
    "print(\"\\nTraining with batch normalization\")\n",
    "bn_history = train_model(model_bn, X_train_dl, X_val_dl, epochs=200)\n",
    "\n",
    "# Evaluate\n",
    "model_bn.eval()\n",
    "total_loss, total_n = 0.0, 0\n",
    "all_logits, all_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in X_test_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model_bn(xb)\n",
    "        batch_loss = loss(logits, yb).item()\n",
    "        total_loss += batch_loss * xb.size(0)\n",
    "        total_n += xb.size(0)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_true.append(yb.cpu())\n",
    "\n",
    "bn_test_loss = total_loss / total_n\n",
    "logits = torch.cat(all_logits).numpy().ravel()\n",
    "bn_y_true = torch.cat(all_true).numpy().astype(int)\n",
    "bn_probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "bn_y_pred = (bn_probs >= 0.5).astype(int)\n",
    "\n",
    "bn_test_acc = accuracy_score(bn_y_true, bn_y_pred)\n",
    "bn_prec, bn_rec, bn_f1, _ = precision_recall_fscore_support(\n",
    "    bn_y_true, bn_y_pred, average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "print(f\"\\nBatch Normalization Results:\")\n",
    "print(f\"  Test Accuracy: {bn_test_acc:.4f}\")\n",
    "print(f\"  Precision: {bn_prec:.4f}\")\n",
    "print(f\"  Recall: {bn_rec:.4f}\")\n",
    "print(f\"  F1 Score: {bn_f1:.4f}\")\n",
    "print(f\"  Training Time: {sum(bn_history['epoch_time_sec']):.2f}s, Improvement over base: {(bn_test_acc - base_test_acc)*100:+.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6550bdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVEMENT METHOD 4: CLASS WEIGHTING\n",
      "Class distribution in training set:\n",
      "  Class 0: 349 samples (65.1%)\n",
      "  Class 1: 187 samples (34.9%)\n",
      "\n",
      "Calculated positive class weight: 1.8663\n",
      "\n",
      "Training with class weighting\n",
      "Epoch 001 | train_loss=1.99345  val_loss=0.66304 | train_MAE=0.5541  val_MAE=0.6348 | lr=0.01 | time=0.09s\n",
      "Epoch 002 | train_loss=0.68629  val_loss=0.66575 | train_MAE=0.6045  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 003 | train_loss=0.66493  val_loss=0.64015 | train_MAE=0.6493  val_MAE=0.6435 | lr=0.01 | time=0.08s\n",
      "Epoch 004 | train_loss=0.65414  val_loss=0.62290 | train_MAE=0.6418  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 005 | train_loss=0.64522  val_loss=0.62377 | train_MAE=0.6474  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 006 | train_loss=0.63612  val_loss=0.60499 | train_MAE=0.6437  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 007 | train_loss=0.64000  val_loss=0.60608 | train_MAE=0.6399  val_MAE=0.6522 | lr=0.01 | time=0.10s\n",
      "Epoch 008 | train_loss=0.61824  val_loss=0.60251 | train_MAE=0.6474  val_MAE=0.6522 | lr=0.01 | time=0.09s\n",
      "Epoch 009 | train_loss=0.62739  val_loss=0.61068 | train_MAE=0.6530  val_MAE=0.6522 | lr=0.01 | time=0.08s\n",
      "Epoch 010 | train_loss=0.64415  val_loss=0.60482 | train_MAE=0.6474  val_MAE=0.6522 | lr=0.01 | time=0.09s\n",
      "Epoch 011 | train_loss=0.62798  val_loss=0.59132 | train_MAE=0.6474  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 012 | train_loss=0.61763  val_loss=0.60572 | train_MAE=0.6679  val_MAE=0.6870 | lr=0.01 | time=0.09s\n",
      "Epoch 013 | train_loss=0.63633  val_loss=0.61076 | train_MAE=0.6586  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 014 | train_loss=0.61190  val_loss=0.56868 | train_MAE=0.6623  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 015 | train_loss=0.61274  val_loss=0.57822 | train_MAE=0.6604  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 016 | train_loss=0.60546  val_loss=0.58577 | train_MAE=0.6642  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 017 | train_loss=0.59549  val_loss=0.56630 | train_MAE=0.6884  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 018 | train_loss=0.59499  val_loss=0.57849 | train_MAE=0.6698  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 019 | train_loss=0.60716  val_loss=0.58481 | train_MAE=0.6660  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 020 | train_loss=0.61728  val_loss=0.57863 | train_MAE=0.6642  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 021 | train_loss=0.58795  val_loss=0.56768 | train_MAE=0.6828  val_MAE=0.7217 | lr=0.01 | time=0.10s\n",
      "Epoch 022 | train_loss=0.59627  val_loss=0.57777 | train_MAE=0.6791  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 023 | train_loss=0.57723  val_loss=0.55914 | train_MAE=0.6959  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 024 | train_loss=0.59633  val_loss=0.57919 | train_MAE=0.6772  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 025 | train_loss=0.58871  val_loss=0.58219 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 026 | train_loss=0.58815  val_loss=0.58200 | train_MAE=0.6754  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 027 | train_loss=0.58117  val_loss=0.56642 | train_MAE=0.6828  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 028 | train_loss=0.58365  val_loss=0.57787 | train_MAE=0.7034  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 029 | train_loss=0.58825  val_loss=0.57516 | train_MAE=0.6716  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 030 | train_loss=0.58446  val_loss=0.56261 | train_MAE=0.7146  val_MAE=0.7478 | lr=0.01 | time=0.09s\n",
      "Epoch 031 | train_loss=0.56767  val_loss=0.57969 | train_MAE=0.6959  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 032 | train_loss=0.56174  val_loss=0.57360 | train_MAE=0.6940  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 033 | train_loss=0.60164  val_loss=0.57793 | train_MAE=0.6716  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 034 | train_loss=0.58751  val_loss=0.57696 | train_MAE=0.6847  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 035 | train_loss=0.57108  val_loss=0.58362 | train_MAE=0.7052  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 036 | train_loss=0.57136  val_loss=0.54645 | train_MAE=0.7034  val_MAE=0.7739 | lr=0.01 | time=0.08s\n",
      "Epoch 037 | train_loss=0.57396  val_loss=0.57056 | train_MAE=0.6959  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 038 | train_loss=0.56042  val_loss=0.56273 | train_MAE=0.7034  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 039 | train_loss=0.58170  val_loss=0.57678 | train_MAE=0.6922  val_MAE=0.6696 | lr=0.01 | time=0.08s\n",
      "Epoch 040 | train_loss=0.59692  val_loss=0.56705 | train_MAE=0.7052  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 041 | train_loss=0.58300  val_loss=0.58836 | train_MAE=0.6978  val_MAE=0.6783 | lr=0.01 | time=0.08s\n",
      "Epoch 042 | train_loss=0.57655  val_loss=0.57481 | train_MAE=0.7164  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 043 | train_loss=0.56234  val_loss=0.56987 | train_MAE=0.6959  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 044 | train_loss=0.54713  val_loss=0.58641 | train_MAE=0.7090  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 045 | train_loss=0.57110  val_loss=0.57669 | train_MAE=0.6922  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 046 | train_loss=0.56978  val_loss=0.60422 | train_MAE=0.6922  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 047 | train_loss=0.56149  val_loss=0.56630 | train_MAE=0.6978  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 048 | train_loss=0.56626  val_loss=0.57218 | train_MAE=0.6940  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 049 | train_loss=0.58256  val_loss=0.56875 | train_MAE=0.6679  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 050 | train_loss=0.56148  val_loss=0.57685 | train_MAE=0.6828  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 051 | train_loss=0.56058  val_loss=0.60943 | train_MAE=0.6903  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 052 | train_loss=0.55531  val_loss=0.57689 | train_MAE=0.7015  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 053 | train_loss=0.54164  val_loss=0.60277 | train_MAE=0.7239  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 054 | train_loss=0.55334  val_loss=0.57243 | train_MAE=0.7090  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 055 | train_loss=0.55860  val_loss=0.59277 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 056 | train_loss=0.56761  val_loss=0.57136 | train_MAE=0.6940  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 057 | train_loss=0.57692  val_loss=0.58570 | train_MAE=0.6772  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 058 | train_loss=0.54803  val_loss=0.57857 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 059 | train_loss=0.54815  val_loss=0.57310 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 060 | train_loss=0.55776  val_loss=0.57866 | train_MAE=0.6940  val_MAE=0.7391 | lr=0.01 | time=0.10s\n",
      "Epoch 061 | train_loss=0.55227  val_loss=0.58926 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 062 | train_loss=0.53710  val_loss=0.56870 | train_MAE=0.7164  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 063 | train_loss=0.55163  val_loss=0.61380 | train_MAE=0.7052  val_MAE=0.7043 | lr=0.01 | time=0.15s\n",
      "Epoch 064 | train_loss=0.54909  val_loss=0.57537 | train_MAE=0.7015  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 065 | train_loss=0.57295  val_loss=0.56750 | train_MAE=0.6959  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 066 | train_loss=0.56126  val_loss=0.57119 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 067 | train_loss=0.56597  val_loss=0.57787 | train_MAE=0.6866  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 068 | train_loss=0.55899  val_loss=0.60265 | train_MAE=0.7034  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 069 | train_loss=0.57081  val_loss=0.57927 | train_MAE=0.6996  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 070 | train_loss=0.55486  val_loss=0.56905 | train_MAE=0.7127  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 071 | train_loss=0.55265  val_loss=0.58053 | train_MAE=0.7183  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 072 | train_loss=0.54362  val_loss=0.56706 | train_MAE=0.7164  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 073 | train_loss=0.55185  val_loss=0.59074 | train_MAE=0.7127  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 074 | train_loss=0.54129  val_loss=0.58636 | train_MAE=0.6903  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 075 | train_loss=0.53112  val_loss=0.57812 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 076 | train_loss=0.56887  val_loss=0.58071 | train_MAE=0.7015  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 077 | train_loss=0.56183  val_loss=0.59858 | train_MAE=0.6716  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 078 | train_loss=0.53469  val_loss=0.59362 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.01 | time=0.09s\n",
      "Epoch 079 | train_loss=0.54004  val_loss=0.60398 | train_MAE=0.7351  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 080 | train_loss=0.53749  val_loss=0.58964 | train_MAE=0.7090  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 081 | train_loss=0.54273  val_loss=0.58232 | train_MAE=0.7071  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 082 | train_loss=0.52734  val_loss=0.63140 | train_MAE=0.7295  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 083 | train_loss=0.58788  val_loss=0.56326 | train_MAE=0.6903  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 084 | train_loss=0.55665  val_loss=0.55104 | train_MAE=0.7201  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 085 | train_loss=0.54565  val_loss=0.59130 | train_MAE=0.6996  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 086 | train_loss=0.54578  val_loss=0.58501 | train_MAE=0.7034  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 087 | train_loss=0.55349  val_loss=0.58734 | train_MAE=0.7127  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 088 | train_loss=0.54505  val_loss=0.57557 | train_MAE=0.7015  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 089 | train_loss=0.55120  val_loss=0.59476 | train_MAE=0.7127  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 090 | train_loss=0.55565  val_loss=0.59539 | train_MAE=0.6884  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 091 | train_loss=0.56534  val_loss=0.56784 | train_MAE=0.7090  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 092 | train_loss=0.53063  val_loss=0.64925 | train_MAE=0.7481  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 093 | train_loss=0.54364  val_loss=0.55043 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 094 | train_loss=0.53880  val_loss=0.56284 | train_MAE=0.7276  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 095 | train_loss=0.55028  val_loss=0.55569 | train_MAE=0.6847  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 096 | train_loss=0.51925  val_loss=0.67145 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 097 | train_loss=0.55792  val_loss=0.56852 | train_MAE=0.6978  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 098 | train_loss=0.53941  val_loss=0.57311 | train_MAE=0.7351  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 099 | train_loss=0.54941  val_loss=0.56548 | train_MAE=0.6940  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 100 | train_loss=0.54309  val_loss=0.56569 | train_MAE=0.7052  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 101 | train_loss=0.52795  val_loss=0.57443 | train_MAE=0.7444  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 102 | train_loss=0.52798  val_loss=0.59694 | train_MAE=0.7108  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 103 | train_loss=0.55816  val_loss=0.57873 | train_MAE=0.7164  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 104 | train_loss=0.54230  val_loss=0.58767 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 105 | train_loss=0.55905  val_loss=0.56731 | train_MAE=0.6922  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 106 | train_loss=0.54848  val_loss=0.57637 | train_MAE=0.7257  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 107 | train_loss=0.53556  val_loss=0.58340 | train_MAE=0.7239  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 108 | train_loss=0.52632  val_loss=0.61898 | train_MAE=0.7090  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 109 | train_loss=0.53726  val_loss=0.59615 | train_MAE=0.7071  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 110 | train_loss=0.54753  val_loss=0.57955 | train_MAE=0.6978  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 111 | train_loss=0.52260  val_loss=0.54385 | train_MAE=0.7276  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 112 | train_loss=0.58831  val_loss=0.61091 | train_MAE=0.6791  val_MAE=0.6609 | lr=0.01 | time=0.08s\n",
      "Epoch 113 | train_loss=0.57313  val_loss=0.54775 | train_MAE=0.6978  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 114 | train_loss=0.54186  val_loss=0.57003 | train_MAE=0.7407  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 115 | train_loss=0.52736  val_loss=0.56681 | train_MAE=0.7425  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 116 | train_loss=0.55735  val_loss=0.54929 | train_MAE=0.7090  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 117 | train_loss=0.55520  val_loss=0.59589 | train_MAE=0.7015  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 118 | train_loss=0.54889  val_loss=0.55643 | train_MAE=0.7090  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 119 | train_loss=0.53973  val_loss=0.55727 | train_MAE=0.6978  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 120 | train_loss=0.53973  val_loss=0.56843 | train_MAE=0.7164  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 121 | train_loss=0.52699  val_loss=0.56867 | train_MAE=0.7295  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 122 | train_loss=0.53335  val_loss=0.59962 | train_MAE=0.7201  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 123 | train_loss=0.55889  val_loss=0.57577 | train_MAE=0.6866  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 124 | train_loss=0.54059  val_loss=0.57063 | train_MAE=0.6996  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 125 | train_loss=0.52427  val_loss=0.58798 | train_MAE=0.7257  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 126 | train_loss=0.52829  val_loss=0.56444 | train_MAE=0.7146  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 127 | train_loss=0.53936  val_loss=0.56391 | train_MAE=0.7220  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 128 | train_loss=0.53412  val_loss=0.58401 | train_MAE=0.7201  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 129 | train_loss=0.52658  val_loss=0.56746 | train_MAE=0.7220  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 130 | train_loss=0.53003  val_loss=0.56374 | train_MAE=0.6903  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 131 | train_loss=0.55740  val_loss=0.57080 | train_MAE=0.7090  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 132 | train_loss=0.55671  val_loss=0.57400 | train_MAE=0.7052  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 133 | train_loss=0.52741  val_loss=0.61458 | train_MAE=0.7313  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 134 | train_loss=0.56884  val_loss=0.54750 | train_MAE=0.6978  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 135 | train_loss=0.54586  val_loss=0.55044 | train_MAE=0.6959  val_MAE=0.7391 | lr=0.01 | time=0.09s\n",
      "Epoch 136 | train_loss=0.54288  val_loss=0.56860 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 137 | train_loss=0.54034  val_loss=0.57484 | train_MAE=0.7015  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 138 | train_loss=0.54219  val_loss=0.56626 | train_MAE=0.7332  val_MAE=0.7217 | lr=0.01 | time=0.09s\n",
      "Epoch 139 | train_loss=0.54155  val_loss=0.56788 | train_MAE=0.7183  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 140 | train_loss=0.52885  val_loss=0.57254 | train_MAE=0.7201  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 141 | train_loss=0.55491  val_loss=0.55676 | train_MAE=0.7034  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 142 | train_loss=0.52744  val_loss=0.56568 | train_MAE=0.7388  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 143 | train_loss=0.53725  val_loss=0.63377 | train_MAE=0.7052  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 144 | train_loss=0.53628  val_loss=0.57657 | train_MAE=0.7034  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 145 | train_loss=0.52522  val_loss=0.61043 | train_MAE=0.7090  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 146 | train_loss=0.53747  val_loss=0.62076 | train_MAE=0.7127  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 147 | train_loss=0.51478  val_loss=0.56919 | train_MAE=0.7276  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 148 | train_loss=0.53135  val_loss=0.61337 | train_MAE=0.7313  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 149 | train_loss=0.53242  val_loss=0.57674 | train_MAE=0.7146  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 150 | train_loss=0.55023  val_loss=0.56636 | train_MAE=0.7146  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 151 | train_loss=0.53231  val_loss=0.55854 | train_MAE=0.7220  val_MAE=0.7043 | lr=0.01 | time=0.09s\n",
      "Epoch 152 | train_loss=0.52312  val_loss=0.56086 | train_MAE=0.7313  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 153 | train_loss=0.52379  val_loss=0.55469 | train_MAE=0.7463  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 154 | train_loss=0.53505  val_loss=0.57122 | train_MAE=0.7239  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 155 | train_loss=0.52425  val_loss=0.58340 | train_MAE=0.7276  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 156 | train_loss=0.52507  val_loss=0.57324 | train_MAE=0.7407  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 157 | train_loss=0.53059  val_loss=0.57781 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 158 | train_loss=0.51788  val_loss=0.59098 | train_MAE=0.7388  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 159 | train_loss=0.51193  val_loss=0.56481 | train_MAE=0.7313  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 160 | train_loss=0.53493  val_loss=0.62441 | train_MAE=0.7071  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 161 | train_loss=0.56477  val_loss=0.56542 | train_MAE=0.7090  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 162 | train_loss=0.52679  val_loss=0.58515 | train_MAE=0.7332  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 163 | train_loss=0.51297  val_loss=0.55770 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 164 | train_loss=0.55155  val_loss=0.57536 | train_MAE=0.7313  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 165 | train_loss=0.53188  val_loss=0.57291 | train_MAE=0.6940  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 166 | train_loss=0.51064  val_loss=0.58618 | train_MAE=0.7369  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 167 | train_loss=0.54123  val_loss=0.54261 | train_MAE=0.7276  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 168 | train_loss=0.53497  val_loss=0.56460 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 169 | train_loss=0.54285  val_loss=0.55629 | train_MAE=0.7164  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 170 | train_loss=0.53043  val_loss=0.60936 | train_MAE=0.7257  val_MAE=0.6870 | lr=0.01 | time=0.08s\n",
      "Epoch 171 | train_loss=0.54311  val_loss=0.58056 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 172 | train_loss=0.54705  val_loss=0.59964 | train_MAE=0.7201  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 173 | train_loss=0.53286  val_loss=0.58813 | train_MAE=0.7201  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 174 | train_loss=0.53045  val_loss=0.59427 | train_MAE=0.7425  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 175 | train_loss=0.52963  val_loss=0.55460 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 176 | train_loss=0.51426  val_loss=0.57813 | train_MAE=0.7313  val_MAE=0.6957 | lr=0.01 | time=0.08s\n",
      "Epoch 177 | train_loss=0.53259  val_loss=0.64301 | train_MAE=0.7108  val_MAE=0.7043 | lr=0.01 | time=0.08s\n",
      "Epoch 178 | train_loss=0.53405  val_loss=0.54268 | train_MAE=0.7108  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 179 | train_loss=0.53012  val_loss=0.55400 | train_MAE=0.7388  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 180 | train_loss=0.53666  val_loss=0.53955 | train_MAE=0.7015  val_MAE=0.7478 | lr=0.01 | time=0.08s\n",
      "Epoch 181 | train_loss=0.53305  val_loss=0.55375 | train_MAE=0.7388  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 182 | train_loss=0.53229  val_loss=0.54274 | train_MAE=0.7481  val_MAE=0.7565 | lr=0.01 | time=0.08s\n",
      "Epoch 183 | train_loss=0.54334  val_loss=0.56792 | train_MAE=0.7201  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 184 | train_loss=0.54078  val_loss=0.55590 | train_MAE=0.6922  val_MAE=0.7304 | lr=0.01 | time=0.09s\n",
      "Epoch 185 | train_loss=0.53099  val_loss=0.54447 | train_MAE=0.7313  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 186 | train_loss=0.51430  val_loss=0.54539 | train_MAE=0.7369  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 187 | train_loss=0.51093  val_loss=0.54766 | train_MAE=0.7313  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 188 | train_loss=0.54259  val_loss=0.55970 | train_MAE=0.7127  val_MAE=0.7130 | lr=0.01 | time=0.08s\n",
      "Epoch 189 | train_loss=0.56284  val_loss=0.55145 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 190 | train_loss=0.53566  val_loss=0.56844 | train_MAE=0.7388  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 191 | train_loss=0.53798  val_loss=0.55254 | train_MAE=0.6978  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 192 | train_loss=0.53504  val_loss=0.56299 | train_MAE=0.7239  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 193 | train_loss=0.51851  val_loss=0.55076 | train_MAE=0.7481  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 194 | train_loss=0.53986  val_loss=0.57115 | train_MAE=0.7257  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 195 | train_loss=0.51425  val_loss=0.55660 | train_MAE=0.7295  val_MAE=0.7391 | lr=0.01 | time=0.08s\n",
      "Epoch 196 | train_loss=0.52520  val_loss=0.56935 | train_MAE=0.7220  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 197 | train_loss=0.52960  val_loss=0.57564 | train_MAE=0.7183  val_MAE=0.7217 | lr=0.01 | time=0.08s\n",
      "Epoch 198 | train_loss=0.52833  val_loss=0.58678 | train_MAE=0.7201  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 199 | train_loss=0.52887  val_loss=0.60336 | train_MAE=0.7052  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Epoch 200 | train_loss=0.51382  val_loss=0.58054 | train_MAE=0.7257  val_MAE=0.7304 | lr=0.01 | time=0.08s\n",
      "Total training time: 16.58s\n",
      "\n",
      "Class Weighting Results:\n",
      "  Test Accuracy: 0.6609\n",
      "  Precision: 0.5333\n",
      "  Recall: 0.3902\n",
      "  F1 Score: 0.4507\n",
      "  Training Time: 16.58s, Improvement over base: +0.87%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"IMPROVEMENT METHOD 4: CLASS WEIGHTING\")\n",
    "\n",
    "\n",
    "# Calculate class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "pos_weight = torch.tensor([class_weights[1]/class_weights[0]], \n",
    "                          dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"Class distribution in training set:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    print(f\"  Class {int(cls)}: {cnt} samples ({cnt/len(y_train)*100:.1f}%)\")\n",
    "print(f\"\\nCalculated positive class weight: {pos_weight.item():.4f}\")\n",
    "\n",
    "# Create model with class weighting\n",
    "model_cw = NeuralNetworkFlexible(hidden_size=best_hidden, dropout=best_dropout).to(device)\n",
    "loss_weighted = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model_cw.parameters(), lr=best_lr)\n",
    "\n",
    "print(\"\\nTraining with class weighting\")\n",
    "cw_history = train_model(model_cw, X_train_dl, X_val_dl, epochs=200)\n",
    "\n",
    "# Evaluate\n",
    "model_cw.eval()\n",
    "total_loss, total_n = 0.0, 0\n",
    "all_logits, all_true = [], []\n",
    "\n",
    "# Use regular loss for evaluation\n",
    "loss_eval = nn.BCEWithLogitsLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in X_test_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model_cw(xb)\n",
    "        batch_loss = loss_eval(logits, yb).item()\n",
    "        total_loss += batch_loss * xb.size(0)\n",
    "        total_n += xb.size(0)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_true.append(yb.cpu())\n",
    "\n",
    "cw_test_loss = total_loss / total_n\n",
    "logits = torch.cat(all_logits).numpy().ravel()\n",
    "cw_y_true = torch.cat(all_true).numpy().astype(int)\n",
    "cw_probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "cw_y_pred = (cw_probs >= 0.5).astype(int)\n",
    "\n",
    "cw_test_acc = accuracy_score(cw_y_true, cw_y_pred)\n",
    "cw_prec, cw_rec, cw_f1, _ = precision_recall_fscore_support(\n",
    "    cw_y_true, cw_y_pred, average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "print(f\"\\nClass Weighting Results:\")\n",
    "print(f\"  Test Accuracy: {cw_test_acc:.4f}\")\n",
    "print(f\"  Precision: {cw_prec:.4f}\")\n",
    "print(f\"  Recall: {cw_rec:.4f}\")\n",
    "print(f\"  F1 Score: {cw_f1:.4f}\")\n",
    "print(f\"  Training Time: {sum(cw_history['epoch_time_sec']):.2f}s, Improvement over base: {(cw_test_acc - base_test_acc)*100:+.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d7e236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARISON OF ALL IMPROVEMENT METHODS\n",
      "             Method  Test Accuracy  Precision   Recall  F1 Score  Training Time (s)\n",
      "         Base Model       0.652174   0.516129 0.390244  0.444444          16.753195\n",
      "     Early Stopping       0.643478   0.500000 0.365854  0.422535           5.493108\n",
      "       LR Scheduler       0.678261   0.590909 0.317073  0.412698          16.668611\n",
      "Batch Normalization       0.686957   0.571429 0.487805  0.526316          20.181058\n",
      "    Class Weighting       0.660870   0.533333 0.390244  0.450704          16.583222\n",
      "\n",
      " Best Method: Batch Normalization with accuracy 0.6870\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(\"COMPARISON OF ALL IMPROVEMENT METHODS\")\n",
    "\n",
    "\n",
    "methods_comparison = pd.DataFrame({\n",
    "    'Method': ['Base Model', 'Early Stopping', 'LR Scheduler', 'Batch Normalization', 'Class Weighting'],\n",
    "    'Test Accuracy': [base_test_acc, es_test_acc, sched_test_acc, bn_test_acc, cw_test_acc],\n",
    "    'Precision': [base_prec, es_prec, sched_prec, bn_prec, cw_prec],\n",
    "    'Recall': [base_rec, es_rec, sched_rec, bn_rec, cw_rec],\n",
    "    'F1 Score': [base_f1, es_f1, sched_f1, bn_f1, cw_f1],\n",
    "    'Training Time (s)': [\n",
    "        sum(base_history['epoch_time_sec']),\n",
    "        sum(es_history['epoch_time_sec']),\n",
    "        sum(sched_history['epoch_time_sec']),\n",
    "        sum(bn_history['epoch_time_sec']),\n",
    "        sum(cw_history['epoch_time_sec'])\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(methods_comparison.to_string(index=False))\n",
    "\n",
    "# Find best method\n",
    "best_method_idx = methods_comparison['Test Accuracy'].idxmax()\n",
    "best_method_name = methods_comparison.loc[best_method_idx, 'Method']\n",
    "best_method_acc = methods_comparison.loc[best_method_idx, 'Test Accuracy']\n",
    "\n",
    "print(f\"\\n Best Method: {best_method_name} with accuracy {best_method_acc:.4f}\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[0].bar(range(len(methods_comparison)), methods_comparison['Test Accuracy'])\n",
    "axes[0].set_xlabel('Method')\n",
    "axes[0].set_ylabel('Test Accuracy')\n",
    "axes[0].set_title('Test Accuracy Comparison')\n",
    "axes[0].set_xticks(range(len(methods_comparison)))\n",
    "axes[0].set_xticklabels(methods_comparison['Method'], rotation=45, ha='right')\n",
    "\n",
    "\n",
    "\n",
    "# Training time comparison\n",
    "axes[1].bar(range(len(methods_comparison)), methods_comparison['Training Time (s)'])\n",
    "axes[1].set_xlabel('Method')\n",
    "axes[1].set_ylabel('Training Time (seconds)')\n",
    "axes[1].set_title('Training Time Comparison')\n",
    "axes[1].set_xticks(range(len(methods_comparison)))\n",
    "axes[1].set_xticklabels(methods_comparison['Method'], rotation=45, ha='right')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628fe790",
   "metadata": {},
   "source": [
    "Pretty much all the models increase the accuracy of the model except early stopping, that decreases it by a bit. Batch Normaliztion ends up being the best accuracy out of it all, but at the same time has the highest training time. It depends on the user of the model the balance they want within their model. Early Stopping has the worst performance but takes the least amount of time, so if early stopping meets a threshold someone has for their model accuracy, it might be the best option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02e67b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_bn.state_dict(), \"a2_part2_weights_JadenPeacock.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67201522",
   "metadata": {},
   "source": [
    "References:\n",
    "https://www.geeksforgeeks.org/deep-learning/what-is-batch-normalization-in-deep-learning/\n",
    "\n",
    "https://www.geeksforgeeks.org/machine-learning/regularization-by-early-stopping/\n",
    "\n",
    "https://docs.pytorch.org/tutorials/recipes/recipes/tuning_guide.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012a9da",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
